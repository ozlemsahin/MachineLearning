{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1.14 versiyonunu kullan diyor, sonrasında runtime restart yap\n",
        "!pip3 install tensorflow==1.14\n",
        "!pip3 install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VGcgGaZ8VRmw",
        "outputId": "00259cfc-0d2e-4d88-db72-e82de0f22e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 46 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.5.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewFOz0kJOEwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6325a7ce-301d-4362-88c9-f22c31c2e06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.0\n",
            "1.19.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone bert github\n",
        "!git clone https://github.com/google-research/bert.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtQoTixmPZD6",
        "outputId": "98209898-637b-4ac3-aa63-7074b52c7737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 328.28 KiB | 4.16 MiB/s, done.\n",
            "Resolving deltas: 100% (182/182), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twxOWPjlV3Tn",
        "outputId": "c1b54f3f-c601-45de-f486-38fa95ae683e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download a model from this github\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYgalLgmPpBB",
        "outputId": "7c1b1e9e-afe2-47a7-bc58-c414b90f2db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-03 14:22:51--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 172.217.214.128, 172.253.119.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1247797031 (1.2G) [application/zip]\n",
            "Saving to: ‘uncased_L-24_H-1024_A-16.zip’\n",
            "\n",
            "uncased_L-24_H-1024 100%[===================>]   1.16G   197MB/s    in 6.0s    \n",
            "\n",
            "2022-07-03 14:22:57 (199 MB/s) - ‘uncased_L-24_H-1024_A-16.zip’ saved [1247797031/1247797031]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip uncased_L-24_H-1024_A-16.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuFdFBdoQqua",
        "outputId": "355234f6-fc7e-44af-91bd-afa91e860c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  uncased_L-24_H-1024_A-16.zip\n",
            "   creating: uncased_L-24_H-1024_A-16/\n",
            "  inflating: uncased_L-24_H-1024_A-16/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-24_H-1024_A-16/vocab.txt  \n",
            "  inflating: uncased_L-24_H-1024_A-16/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-24_H-1024_A-16/bert_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the SQUAD train and dev dataset\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loEJBl6hQ4lk",
        "outputId": "002d6e91-1969-486d-c3e3-5edb0d1207c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-03 14:23:14--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M   176MB/s    in 0.2s    \n",
            "\n",
            "2022-07-03 14:23:14 (176 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2022-07-03 14:23:14--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-07-03 14:23:14 (57.7 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys"
      ],
      "metadata": {
        "id": "vJdSA3ozRMS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assert controls if it exists. \n",
        "#you need to write , reason \n",
        "# we want to find tpu address from google by remote procedure call\n",
        "\n",
        "#assert 'COLAB_TPU_ADDR' in os.environ, 'Error'\n",
        "TPU_ADDRESS = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "print(\"tpu address is : \" + TPU_ADDRESS)\n"
      ],
      "metadata": {
        "id": "2lvwkBaLRW9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6025e592-96d4-4ebb-db8b-690d540c273b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpu address is : grpc://10.98.247.146:8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorlerle calısan gpu = tpu\n",
        "# tpu adress = memory adres demek\n",
        "# GOOGLE COLAB'IN BIZE AYIRDIGI TPU BURASI MINIK DIYE SADECE FINE TUNING YAPICAZ\n",
        "# GOOGLE CLOUD DAHA BUYUK DIYE EGITIMI ORADA YAPICAZ\n",
        "\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is => ', TPU_ADDRESS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpsTqJzcWYTX",
        "outputId": "0c0a6997-a5b2-4334-f715-72acf8b058a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU address is =>  grpc://10.85.218.250:8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kendimizi tanıtıyoruz\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# tensorflow session'da bu tpu'yu kullanıcam diyecegiz\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "\n",
        "  # kullanabilecegimiz tpu core'larını goruyoruz göruyoruz mesela burada 8 core\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # adc = application default credential\n",
        "  # adc.json dosyasına atıyoruz şifreleri ki kendisi girip istedigini bulsun api şifreleri & google sifresi\n",
        "  # service account yaratıyoruz google cloud service uzerinden ki gerekli işlemleri yerimize yapabilsin\n",
        "  with open(\"/content/adc.json\", \"r\") as f:\n",
        "    auth_info = json.load(f)\n",
        "  \n",
        "  tf.contrib.cloud.configure_gcs(session, credentials = auth_info)\n",
        "\n",
        "# google cloud storage hesabı actık\n",
        "# service account actık\n",
        "# sifreler için key olusturduk ve contentse ekledik\n",
        "# storage acıcaz (bucket)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJd6zecEWlYR",
        "outputId": "f1715c14-c31b-4d6f-9bd8-f1f7368f13ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5667897891345386121),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4912195845990712402),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13900047798297851546),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17194907764190644021),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6979741159441875185),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14010098009274361084),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 146131183324708420),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16669436514199794724),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13369709537939618858),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 567424336353328932),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11221153759758795711)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = \"ozlemsahin\"\n",
        "output_name = \"BertBucket\" #my folder name for this project\n",
        "bucket_dir_name = \"gs://{}\".format(bucket_name) #gs = google storage\n",
        "output_dir_name = \"gs://{}/{}\".format(bucket_name,output_name)\n",
        "\n",
        "tf.gfile.MakeDirs(output_dir_name)  #gfile file system'a ulasmak için olan input output"
      ],
      "metadata": {
        "id": "XHxhHy_miw4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move folder to my folder in google cloud storage bucket\n",
        "# gsuitl = upload download edit move objects in bucket\n",
        "!gsutil mv /content/bert/uncased_L-24_H-1024_A-16/ $output_dir_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HrblxTUkqbY",
        "outputId": "84d3cb58-bf29-4f58-9d5a-384841fbdddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file:///content/bert/uncased_L-24_H-1024_A-16/bert_config.json [Content-Type=application/json]...\n",
            "/ [0 files][    0.0 B/  314.0 B]                                                \r/ [1 files][  314.0 B/  314.0 B]                                                \rRemoving file:///content/bert/uncased_L-24_H-1024_A-16/bert_config.json...\n",
            "Copying file:///content/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.meta [Content-Type=application/octet-stream]...\n",
            "Removing file:///content/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.meta...\n",
            "Copying file:///content/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.index [Content-Type=application/octet-stream]...\n",
            "Removing file:///content/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.index...\n",
            "Copying file:///content/bert/uncased_L-24_H-1024_A-16/vocab.txt [Content-Type=text/plain]...\n",
            "Removing file:///content/bert/uncased_L-24_H-1024_A-16/vocab.txt...\n",
            "\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying file:///content/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Removing file:///content/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001...\n",
            "\n",
            "Operation completed over 5 objects/1.2 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.pywrap_tensorflow_internal import CheckpointReader\n",
        "# bir model eğitmek için tensorflow'a vermemiz gereken bazı bilgiler\n",
        "# ve belirlememiz gereken parametreler var. Bunları da bizim model indirirken modeli\n",
        "# hazırlayanların olusturdugu bir .py dosyasını calıstırarak ve istenen inputları vererek halledebiliriz\n",
        "\n",
        "# \\ demek bu line devam ediyor demek \n",
        "#datasetten okurken her okumada max 128 \n",
        "#daha once egitilmiş model verdigimiz icin dusuk olabilir e=exponential\n",
        "!python set_essential_params.py \\\n",
        "  --vocab_file=$output_dir_name/uncased_L-24_H-1024_A-16/vocab.txt \\\n",
        "  --bert_config_file=$output_dir_name/uncased_L-24_H-1024_A-16/bert_config.json \\\n",
        "  --init_checkpoint=$output_dir_name/uncased_L-24_H-1024_A-16/bert_model.ckpt \\\n",
        "  --do_train=True \\\n",
        "  --train_file=train-v2.0.json \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file=predict-v2.0.json \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name=$TPU_ADDRESS \\\n",
        "  --output_dir=$output_dir_name \\\n",
        "  --train_batch_size=24\\\n",
        "  --learning_rate=3e-5\\\n",
        "  --num_train_epochs=2.0 \\\n",
        "  --max_seq_length=384 \\\n",
        "  --doc_stride=128 \\\n",
        "  --version_2_with_negative=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxD09ZfxmPET",
        "outputId": "91a8fc94-efa7-4422-a905-db139501a9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "#Note :stil bozmadan yapıstırmak için ctrl shift v\n",
        "!touch input_file.json"
      ],
      "metadata": {
        "id": "FpKtShcPx5pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile input_file.json\n",
        "{\n",
        "    \"version\": \"v2.0\",\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"title\": \"bert-on-squad-test-dataset\",\n",
        "            \"paragraphs\": [\n",
        "                {\n",
        "                    \"qas\": [\n",
        "                        {\n",
        "                            \"question\": \"Who is current CEO?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9628\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"Who founded google?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9629\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"when did IPO take place?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b962a\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"context\": \"Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock. They incorporated Google as a privately held company on September 4, 1998. An initial public offering (IPO) took place on August 19, 2004, and Google moved to its headquarters in Mountain View, California, nicknamed the Googleplex. In August 2015, Google announced plans to reorganize its various interests as a conglomerate called Alphabet Inc. Google is Alphabet's leading subsidiary and will continue to be the umbrella company for Alphabet's Internet interests. Sundar Pichai was appointed CEO of Google, replacing Larry Page who became the CEO of Alphabet.\"                \n",
        "                 }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrvOScpT-Zfs",
        "outputId": "06f9d615-8e7b-4db6-cd8d-e5d1d4f0cbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting input_file.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"output_dir_name: \" +output_dir_name)\n",
        "print(\"bucket_dir_name: \"+bucket_dir_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzHzECFMBS9u",
        "outputId": "36eab199-8816-417e-82aa-aad1e43f58e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_dir_name: gs://ozlemsahin/BertBucket\n",
            "bucket_dir_name: gs://ozlemsahin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python set_essential_params.py \\\n",
        "  --vocab_file=$output_dir_name/uncased_L-24_H-1024_A-16/vocab.txt \\\n",
        "  --bert_config_file=$output_dir_name/uncased_L-24_H-1024_A-16/bert_config.json \\\n",
        "  --init_checkpoint=$output_dir_name/uncased_L-24_H-1024_A-16/model.ckpt-10859 \\\n",
        "  --do_train=False \\\n",
        "  --max_query_length=30  \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file=input_file.json \\\n",
        "  --predict_batch_size=8 \\\n",
        "  --n_best_size=3 \\\n",
        "  --max_seq_length=384 \\\n",
        "  --doc_stride=128 \\\n",
        "  --output_dir=output/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FykuPTuN-eWf",
        "outputId": "4ab5b2f4-8f5c-45c0-9cdd-aad717741e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1283: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0703 18:01:20.796831 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0703 18:01:20.797097 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0703 18:01:20.797344 140529127511936 deprecation_wrapper.py:119] From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0703 18:01:21.531468 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0703 18:01:23.100963 140529127511936 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcf47e097a0>) includes params argument, but params are not passed to Estimator.\n",
            "W0703 18:01:23.102845 140529127511936 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcf47e097a0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcf3db70290>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0703 18:01:23.103730 140529127511936 estimator.py:209] Using config: {'_model_dir': 'output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcf3db70290>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0703 18:01:23.104026 140529127511936 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0703 18:01:23.104245 140529127511936 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From set_essential_params.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0703 18:01:23.104393 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0703 18:01:23.105317 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0703 18:01:23.108898 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:01:23.109018 140529127511936 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000000\n",
            "I0703 18:01:23.109082 140529127511936 set_essential_params.py:432] unique_id: 1000000000\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:01:23.109148 140529127511936 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:01:23.109200 140529127511936 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who is current ceo ? [SEP] google was founded in 1998 by larry page and sergey br ##in while they were ph . d . students at stanford university in california . together they own about 14 percent of its shares and control 56 percent of the stock ##holder voting power through super ##vot ##ing stock . they incorporated google as a privately held company on september 4 , 1998 . an initial public offering ( ip ##o ) took place on august 19 , 2004 , and google moved to its headquarters in mountain view , california , nicknamed the google ##plex . in august 2015 , google announced plans to re ##org ##ani ##ze its various interests as a conglomerate called alphabet inc . google is alphabet ' s leading subsidiary and will continue to be the umbrella company for alphabet ' s internet interests . sun ##dar pic ##hai was appointed ceo of google , replacing larry page who became the ceo of alphabet . [SEP]\n",
            "I0703 18:01:23.109301 140529127511936 set_essential_params.py:436] tokens: [CLS] who is current ceo ? [SEP] google was founded in 1998 by larry page and sergey br ##in while they were ph . d . students at stanford university in california . together they own about 14 percent of its shares and control 56 percent of the stock ##holder voting power through super ##vot ##ing stock . they incorporated google as a privately held company on september 4 , 1998 . an initial public offering ( ip ##o ) took place on august 19 , 2004 , and google moved to its headquarters in mountain view , california , nicknamed the google ##plex . in august 2015 , google announced plans to re ##org ##ani ##ze its various interests as a conglomerate called alphabet inc . google is alphabet ' s leading subsidiary and will continue to be the umbrella company for alphabet ' s internet interests . sun ##dar pic ##hai was appointed ceo of google , replacing larry page who became the ceo of alphabet . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:9 17:10 18:10 19:11 20:12 21:13 22:14 23:14 24:14 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:33 46:34 47:35 48:36 49:36 50:37 51:38 52:39 53:40 54:40 55:40 56:41 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:48 65:49 66:50 67:51 68:52 69:52 70:53 71:53 72:54 73:55 74:56 75:57 76:58 77:58 78:58 79:58 80:59 81:60 82:61 83:62 84:63 85:63 86:64 87:64 88:65 89:66 90:67 91:68 92:69 93:70 94:71 95:72 96:73 97:73 98:74 99:74 100:75 101:76 102:77 103:77 104:77 105:78 106:79 107:80 108:80 109:81 110:82 111:83 112:84 113:85 114:85 115:85 116:85 117:86 118:87 119:88 120:89 121:90 122:91 123:92 124:93 125:94 126:94 127:95 128:96 129:97 130:97 131:97 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:109 145:109 146:110 147:111 148:111 149:112 150:112 151:113 152:113 153:114 154:115 155:116 156:117 157:118 158:118 159:119 160:120 161:121 162:122 163:123 164:124 165:125 166:126 167:127 168:127\n",
            "I0703 18:01:23.109424 140529127511936 set_essential_params.py:438] token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:9 17:10 18:10 19:11 20:12 21:13 22:14 23:14 24:14 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:33 46:34 47:35 48:36 49:36 50:37 51:38 52:39 53:40 54:40 55:40 56:41 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:48 65:49 66:50 67:51 68:52 69:52 70:53 71:53 72:54 73:55 74:56 75:57 76:58 77:58 78:58 79:58 80:59 81:60 82:61 83:62 84:63 85:63 86:64 87:64 88:65 89:66 90:67 91:68 92:69 93:70 94:71 95:72 96:73 97:73 98:74 99:74 100:75 101:76 102:77 103:77 104:77 105:78 106:79 107:80 108:80 109:81 110:82 111:83 112:84 113:85 114:85 115:85 116:85 117:86 118:87 119:88 120:89 121:90 122:91 123:92 124:93 125:94 126:94 127:95 128:96 129:97 130:97 131:97 132:98 133:99 134:100 135:101 136:102 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:109 145:109 146:110 147:111 148:111 149:112 150:112 151:113 152:113 153:114 154:115 155:116 156:117 157:118 158:118 159:119 160:120 161:121 162:122 163:123 164:124 165:125 166:126 167:127 168:127\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True\n",
            "I0703 18:01:23.109530 140529127511936 set_essential_params.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 2783 5766 1029 102 8224 2001 2631 1999 2687 2011 6554 3931 1998 22703 7987 2378 2096 2027 2020 6887 1012 1040 1012 2493 2012 8422 2118 1999 2662 1012 2362 2027 2219 2055 2403 3867 1997 2049 6661 1998 2491 5179 3867 1997 1996 4518 14528 6830 2373 2083 3565 22994 2075 4518 1012 2027 5100 8224 2004 1037 9139 2218 2194 2006 2244 1018 1010 2687 1012 2019 3988 2270 5378 1006 12997 2080 1007 2165 2173 2006 2257 2539 1010 2432 1010 1998 8224 2333 2000 2049 4075 1999 3137 3193 1010 2662 1010 9919 1996 8224 19386 1012 1999 2257 2325 1010 8224 2623 3488 2000 2128 21759 7088 4371 2049 2536 5426 2004 1037 22453 2170 12440 4297 1012 8224 2003 12440 1005 1055 2877 7506 1998 2097 3613 2000 2022 1996 12977 2194 2005 12440 1005 1055 4274 5426 1012 3103 7662 27263 10932 2001 2805 5766 1997 8224 1010 6419 6554 3931 2040 2150 1996 5766 1997 12440 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.109705 140529127511936 set_essential_params.py:442] input_ids: 101 2040 2003 2783 5766 1029 102 8224 2001 2631 1999 2687 2011 6554 3931 1998 22703 7987 2378 2096 2027 2020 6887 1012 1040 1012 2493 2012 8422 2118 1999 2662 1012 2362 2027 2219 2055 2403 3867 1997 2049 6661 1998 2491 5179 3867 1997 1996 4518 14528 6830 2373 2083 3565 22994 2075 4518 1012 2027 5100 8224 2004 1037 9139 2218 2194 2006 2244 1018 1010 2687 1012 2019 3988 2270 5378 1006 12997 2080 1007 2165 2173 2006 2257 2539 1010 2432 1010 1998 8224 2333 2000 2049 4075 1999 3137 3193 1010 2662 1010 9919 1996 8224 19386 1012 1999 2257 2325 1010 8224 2623 3488 2000 2128 21759 7088 4371 2049 2536 5426 2004 1037 22453 2170 12440 4297 1012 8224 2003 12440 1005 1055 2877 7506 1998 2097 3613 2000 2022 1996 12977 2194 2005 12440 1005 1055 4274 5426 1012 3103 7662 27263 10932 2001 2805 5766 1997 8224 1010 6419 6554 3931 2040 2150 1996 5766 1997 12440 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.109854 140529127511936 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.109992 140529127511936 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:01:23.200217 140529127511936 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000001\n",
            "I0703 18:01:23.200440 140529127511936 set_essential_params.py:432] unique_id: 1000000001\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:01:23.200515 140529127511936 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:01:23.200571 140529127511936 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who founded google ? [SEP] google was founded in 1998 by larry page and sergey br ##in while they were ph . d . students at stanford university in california . together they own about 14 percent of its shares and control 56 percent of the stock ##holder voting power through super ##vot ##ing stock . they incorporated google as a privately held company on september 4 , 1998 . an initial public offering ( ip ##o ) took place on august 19 , 2004 , and google moved to its headquarters in mountain view , california , nicknamed the google ##plex . in august 2015 , google announced plans to re ##org ##ani ##ze its various interests as a conglomerate called alphabet inc . google is alphabet ' s leading subsidiary and will continue to be the umbrella company for alphabet ' s internet interests . sun ##dar pic ##hai was appointed ceo of google , replacing larry page who became the ceo of alphabet . [SEP]\n",
            "I0703 18:01:23.200678 140529127511936 set_essential_params.py:436] tokens: [CLS] who founded google ? [SEP] google was founded in 1998 by larry page and sergey br ##in while they were ph . d . students at stanford university in california . together they own about 14 percent of its shares and control 56 percent of the stock ##holder voting power through super ##vot ##ing stock . they incorporated google as a privately held company on september 4 , 1998 . an initial public offering ( ip ##o ) took place on august 19 , 2004 , and google moved to its headquarters in mountain view , california , nicknamed the google ##plex . in august 2015 , google announced plans to re ##org ##ani ##ze its various interests as a conglomerate called alphabet inc . google is alphabet ' s leading subsidiary and will continue to be the umbrella company for alphabet ' s internet interests . sun ##dar pic ##hai was appointed ceo of google , replacing larry page who became the ceo of alphabet . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:6 13:7 14:8 15:9 16:10 17:10 18:11 19:12 20:13 21:14 22:14 23:14 24:14 25:15 26:16 27:17 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:36 49:37 50:38 51:39 52:40 53:40 54:40 55:41 56:41 57:42 58:43 59:44 60:45 61:46 62:47 63:48 64:49 65:50 66:51 67:52 68:52 69:53 70:53 71:54 72:55 73:56 74:57 75:58 76:58 77:58 78:58 79:59 80:60 81:61 82:62 83:63 84:63 85:64 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:73 97:74 98:74 99:75 100:76 101:77 102:77 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:85 113:85 114:85 115:85 116:86 117:87 118:88 119:89 120:90 121:91 122:92 123:93 124:94 125:94 126:95 127:96 128:97 129:97 130:97 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:105 139:106 140:107 141:108 142:109 143:109 144:109 145:110 146:111 147:111 148:112 149:112 150:113 151:113 152:114 153:115 154:116 155:117 156:118 157:118 158:119 159:120 160:121 161:122 162:123 163:124 164:125 165:126 166:127 167:127\n",
            "I0703 18:01:23.200788 140529127511936 set_essential_params.py:438] token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:6 13:7 14:8 15:9 16:10 17:10 18:11 19:12 20:13 21:14 22:14 23:14 24:14 25:15 26:16 27:17 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:36 49:37 50:38 51:39 52:40 53:40 54:40 55:41 56:41 57:42 58:43 59:44 60:45 61:46 62:47 63:48 64:49 65:50 66:51 67:52 68:52 69:53 70:53 71:54 72:55 73:56 74:57 75:58 76:58 77:58 78:58 79:59 80:60 81:61 82:62 83:63 84:63 85:64 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:73 97:74 98:74 99:75 100:76 101:77 102:77 103:77 104:78 105:79 106:80 107:80 108:81 109:82 110:83 111:84 112:85 113:85 114:85 115:85 116:86 117:87 118:88 119:89 120:90 121:91 122:92 123:93 124:94 125:94 126:95 127:96 128:97 129:97 130:97 131:98 132:99 133:100 134:101 135:102 136:103 137:104 138:105 139:106 140:107 141:108 142:109 143:109 144:109 145:110 146:111 147:111 148:112 149:112 150:113 151:113 152:114 153:115 154:116 155:117 156:118 157:118 158:119 159:120 160:121 161:122 162:123 163:124 164:125 165:126 166:127 167:127\n",
            "INFO:tensorflow:token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True\n",
            "I0703 18:01:23.200892 140529127511936 set_essential_params.py:440] token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 8224 1029 102 8224 2001 2631 1999 2687 2011 6554 3931 1998 22703 7987 2378 2096 2027 2020 6887 1012 1040 1012 2493 2012 8422 2118 1999 2662 1012 2362 2027 2219 2055 2403 3867 1997 2049 6661 1998 2491 5179 3867 1997 1996 4518 14528 6830 2373 2083 3565 22994 2075 4518 1012 2027 5100 8224 2004 1037 9139 2218 2194 2006 2244 1018 1010 2687 1012 2019 3988 2270 5378 1006 12997 2080 1007 2165 2173 2006 2257 2539 1010 2432 1010 1998 8224 2333 2000 2049 4075 1999 3137 3193 1010 2662 1010 9919 1996 8224 19386 1012 1999 2257 2325 1010 8224 2623 3488 2000 2128 21759 7088 4371 2049 2536 5426 2004 1037 22453 2170 12440 4297 1012 8224 2003 12440 1005 1055 2877 7506 1998 2097 3613 2000 2022 1996 12977 2194 2005 12440 1005 1055 4274 5426 1012 3103 7662 27263 10932 2001 2805 5766 1997 8224 1010 6419 6554 3931 2040 2150 1996 5766 1997 12440 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.201068 140529127511936 set_essential_params.py:442] input_ids: 101 2040 2631 8224 1029 102 8224 2001 2631 1999 2687 2011 6554 3931 1998 22703 7987 2378 2096 2027 2020 6887 1012 1040 1012 2493 2012 8422 2118 1999 2662 1012 2362 2027 2219 2055 2403 3867 1997 2049 6661 1998 2491 5179 3867 1997 1996 4518 14528 6830 2373 2083 3565 22994 2075 4518 1012 2027 5100 8224 2004 1037 9139 2218 2194 2006 2244 1018 1010 2687 1012 2019 3988 2270 5378 1006 12997 2080 1007 2165 2173 2006 2257 2539 1010 2432 1010 1998 8224 2333 2000 2049 4075 1999 3137 3193 1010 2662 1010 9919 1996 8224 19386 1012 1999 2257 2325 1010 8224 2623 3488 2000 2128 21759 7088 4371 2049 2536 5426 2004 1037 22453 2170 12440 4297 1012 8224 2003 12440 1005 1055 2877 7506 1998 2097 3613 2000 2022 1996 12977 2194 2005 12440 1005 1055 4274 5426 1012 3103 7662 27263 10932 2001 2805 5766 1997 8224 1010 6419 6554 3931 2040 2150 1996 5766 1997 12440 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.201225 140529127511936 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.201365 140529127511936 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:01:23.205092 140529127511936 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000002\n",
            "I0703 18:01:23.205254 140529127511936 set_essential_params.py:432] unique_id: 1000000002\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:01:23.205330 140529127511936 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:01:23.205437 140529127511936 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when did ip ##o take place ? [SEP] google was founded in 1998 by larry page and sergey br ##in while they were ph . d . students at stanford university in california . together they own about 14 percent of its shares and control 56 percent of the stock ##holder voting power through super ##vot ##ing stock . they incorporated google as a privately held company on september 4 , 1998 . an initial public offering ( ip ##o ) took place on august 19 , 2004 , and google moved to its headquarters in mountain view , california , nicknamed the google ##plex . in august 2015 , google announced plans to re ##org ##ani ##ze its various interests as a conglomerate called alphabet inc . google is alphabet ' s leading subsidiary and will continue to be the umbrella company for alphabet ' s internet interests . sun ##dar pic ##hai was appointed ceo of google , replacing larry page who became the ceo of alphabet . [SEP]\n",
            "I0703 18:01:23.205553 140529127511936 set_essential_params.py:436] tokens: [CLS] when did ip ##o take place ? [SEP] google was founded in 1998 by larry page and sergey br ##in while they were ph . d . students at stanford university in california . together they own about 14 percent of its shares and control 56 percent of the stock ##holder voting power through super ##vot ##ing stock . they incorporated google as a privately held company on september 4 , 1998 . an initial public offering ( ip ##o ) took place on august 19 , 2004 , and google moved to its headquarters in mountain view , california , nicknamed the google ##plex . in august 2015 , google announced plans to re ##org ##ani ##ze its various interests as a conglomerate called alphabet inc . google is alphabet ' s leading subsidiary and will continue to be the umbrella company for alphabet ' s internet interests . sun ##dar pic ##hai was appointed ceo of google , replacing larry page who became the ceo of alphabet . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:10 21:11 22:12 23:13 24:14 25:14 26:14 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:33 48:34 49:35 50:36 51:36 52:37 53:38 54:39 55:40 56:40 57:40 58:41 59:41 60:42 61:43 62:44 63:45 64:46 65:47 66:48 67:49 68:50 69:51 70:52 71:52 72:53 73:53 74:54 75:55 76:56 77:57 78:58 79:58 80:58 81:58 82:59 83:60 84:61 85:62 86:63 87:63 88:64 89:64 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:73 100:74 101:74 102:75 103:76 104:77 105:77 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:85 116:85 117:85 118:85 119:86 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:94 128:94 129:95 130:96 131:97 132:97 133:97 134:98 135:99 136:100 137:101 138:102 139:103 140:104 141:105 142:106 143:107 144:108 145:109 146:109 147:109 148:110 149:111 150:111 151:112 152:112 153:113 154:113 155:114 156:115 157:116 158:117 159:118 160:118 161:119 162:120 163:121 164:122 165:123 166:124 167:125 168:126 169:127 170:127\n",
            "I0703 18:01:23.205672 140529127511936 set_essential_params.py:438] token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:10 21:11 22:12 23:13 24:14 25:14 26:14 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:33 48:34 49:35 50:36 51:36 52:37 53:38 54:39 55:40 56:40 57:40 58:41 59:41 60:42 61:43 62:44 63:45 64:46 65:47 66:48 67:49 68:50 69:51 70:52 71:52 72:53 73:53 74:54 75:55 76:56 77:57 78:58 79:58 80:58 81:58 82:59 83:60 84:61 85:62 86:63 87:63 88:64 89:64 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:73 100:74 101:74 102:75 103:76 104:77 105:77 106:77 107:78 108:79 109:80 110:80 111:81 112:82 113:83 114:84 115:85 116:85 117:85 118:85 119:86 120:87 121:88 122:89 123:90 124:91 125:92 126:93 127:94 128:94 129:95 130:96 131:97 132:97 133:97 134:98 135:99 136:100 137:101 138:102 139:103 140:104 141:105 142:106 143:107 144:108 145:109 146:109 147:109 148:110 149:111 150:111 151:112 152:112 153:113 154:113 155:114 156:115 157:116 158:117 159:118 160:118 161:119 162:120 163:121 164:122 165:123 166:124 167:125 168:126 169:127 170:127\n",
            "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True\n",
            "I0703 18:01:23.296640 140529127511936 set_essential_params.py:440] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 12997 2080 2202 2173 1029 102 8224 2001 2631 1999 2687 2011 6554 3931 1998 22703 7987 2378 2096 2027 2020 6887 1012 1040 1012 2493 2012 8422 2118 1999 2662 1012 2362 2027 2219 2055 2403 3867 1997 2049 6661 1998 2491 5179 3867 1997 1996 4518 14528 6830 2373 2083 3565 22994 2075 4518 1012 2027 5100 8224 2004 1037 9139 2218 2194 2006 2244 1018 1010 2687 1012 2019 3988 2270 5378 1006 12997 2080 1007 2165 2173 2006 2257 2539 1010 2432 1010 1998 8224 2333 2000 2049 4075 1999 3137 3193 1010 2662 1010 9919 1996 8224 19386 1012 1999 2257 2325 1010 8224 2623 3488 2000 2128 21759 7088 4371 2049 2536 5426 2004 1037 22453 2170 12440 4297 1012 8224 2003 12440 1005 1055 2877 7506 1998 2097 3613 2000 2022 1996 12977 2194 2005 12440 1005 1055 4274 5426 1012 3103 7662 27263 10932 2001 2805 5766 1997 8224 1010 6419 6554 3931 2040 2150 1996 5766 1997 12440 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.297100 140529127511936 set_essential_params.py:442] input_ids: 101 2043 2106 12997 2080 2202 2173 1029 102 8224 2001 2631 1999 2687 2011 6554 3931 1998 22703 7987 2378 2096 2027 2020 6887 1012 1040 1012 2493 2012 8422 2118 1999 2662 1012 2362 2027 2219 2055 2403 3867 1997 2049 6661 1998 2491 5179 3867 1997 1996 4518 14528 6830 2373 2083 3565 22994 2075 4518 1012 2027 5100 8224 2004 1037 9139 2218 2194 2006 2244 1018 1010 2687 1012 2019 3988 2270 5378 1006 12997 2080 1007 2165 2173 2006 2257 2539 1010 2432 1010 1998 8224 2333 2000 2049 4075 1999 3137 3193 1010 2662 1010 9919 1996 8224 19386 1012 1999 2257 2325 1010 8224 2623 3488 2000 2128 21759 7088 4371 2049 2536 5426 2004 1037 22453 2170 12440 4297 1012 8224 2003 12440 1005 1055 2877 7506 1998 2097 3613 2000 2022 1996 12977 2194 2005 12440 1005 1055 4274 5426 1012 3103 7662 27263 10932 2001 2805 5766 1997 8224 1010 6419 6554 3931 2040 2150 1996 5766 1997 12440 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.297450 140529127511936 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:01:23.297747 140529127511936 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "I0703 18:01:23.298898 140529127511936 set_essential_params.py:1240] ***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 3\n",
            "I0703 18:01:23.299065 140529127511936 set_essential_params.py:1241]   Num orig examples = 3\n",
            "INFO:tensorflow:  Num split examples = 3\n",
            "I0703 18:01:23.299216 140529127511936 set_essential_params.py:1242]   Num split examples = 3\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0703 18:01:23.299349 140529127511936 set_essential_params.py:1243]   Batch size = 8\n",
            "WARNING:tensorflow:From set_essential_params.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0703 18:01:23.299582 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:Could not find trained model in model_dir: output/, running initialization to predict.\n",
            "I0703 18:01:23.300016 140529127511936 estimator.py:612] Could not find trained model in model_dir: output/, running initialization to predict.\n",
            "WARNING:tensorflow:From set_essential_params.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0703 18:01:23.320774 140529127511936 deprecation.py:323] From set_essential_params.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0703 18:01:23.321047 140529127511936 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From set_essential_params.py:703: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0703 18:01:23.322635 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:703: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:710: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0703 18:01:23.326175 140529127511936 deprecation.py:323] From set_essential_params.py:710: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0703 18:01:23.342248 140529127511936 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0703 18:01:23.342557 140529127511936 tpu_estimator.py:2965] Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0703 18:01:23.342940 140529127511936 set_essential_params.py:598] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 384)\n",
            "I0703 18:01:23.343115 140529127511936 set_essential_params.py:600]   name = input_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 384)\n",
            "I0703 18:01:23.343269 140529127511936 set_essential_params.py:600]   name = input_mask, shape = (?, 384)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 384)\n",
            "I0703 18:01:23.343430 140529127511936 set_essential_params.py:600]   name = segment_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
            "I0703 18:01:23.343569 140529127511936 set_essential_params.py:600]   name = unique_ids, shape = (?,)\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0703 18:01:23.346907 140529127511936 deprecation_wrapper.py:119] From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0703 18:01:23.348535 140529127511936 deprecation_wrapper.py:119] From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0703 18:01:23.380055 140529127511936 deprecation_wrapper.py:119] From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0703 18:01:23.451982 140529127511936 deprecation.py:323] From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.480878 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.508542 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.536509 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0f9d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d1267d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d1267d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.594941 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d1267d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d1267d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f090>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.646752 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f090>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f0d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.682791 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d13f0d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.738107 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.765148 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.795435 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cfe2450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0a40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0a40d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.848768 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0a40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d0a40d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.899119 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.939491 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cef4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cef4050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:23.992050 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cef4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cef4050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.019745 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.047228 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d00e110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.098353 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf09dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf09dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.144304 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf09dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf09dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ce31ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ce31ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.289297 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ce31ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ce31ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.350639 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.378128 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cceba90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd8510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd8510>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.405935 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd8510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd8510>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd6290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd6290>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.458122 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd6290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbd6290>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126790>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.504985 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126790>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5a890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.544280 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5a890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.602641 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.630816 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb774d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca21610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca21610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.658247 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca21610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca21610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb36650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb36650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.709916 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb36650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb36650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf14d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf14d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.760946 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf14d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf14d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.803016 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d126c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c892cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c892cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.861958 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c892cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c892cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.889487 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.917598 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c86ce50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5dd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:24.969047 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cd5dd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.016295 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c956450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c956450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.051980 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c956450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c956450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6ae8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6ae8d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.108023 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6ae8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6ae8d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.139332 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.167756 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c6b6bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c770cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c770cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.218573 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c770cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c770cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c926c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c926c10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.262890 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c926c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c926c10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb091d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb091d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.297122 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb091d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cb091d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.353720 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.380673 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.407962 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.463767 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3e2ec950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3e2ec950>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.509778 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3e2ec950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3e2ec950>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c866810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c866810>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.545034 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c866810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c866810>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.596133 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c479f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c479f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.629766 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c479f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c479f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf6bb90e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf6bb90e90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.657522 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf6bb90e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf6bb90e90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c4eb390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c4eb390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.709738 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c4eb390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c4eb390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.760607 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c8684d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c8684d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.913900 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c8684d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c8684d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.967181 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:25.994668 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.025093 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c8110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbfa710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbfa710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.088046 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbfa710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cbfa710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.135731 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf6aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf6aad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.171389 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf6aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3cf6aad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.224956 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.252382 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.280167 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c5e4e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c06ced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c06ced0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.336042 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c06ced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c06ced0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c9e3f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c9e3f10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.381885 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c9e3f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c9e3f10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c6950>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.416961 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c2c6950>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.473527 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.502923 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.531343 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c1b3dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bf57550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bf57550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.583759 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bf57550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bf57550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.633831 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233b50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.682725 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233b50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.737199 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.763667 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.793052 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.845642 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bc8b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bc8b1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.890084 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bc8b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bc8b1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c10c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c10c550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.924437 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c10c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c10c550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:26.980948 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.007508 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.034892 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c868dd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacbf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacbf50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.085523 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacbf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacbf50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bdc5a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bdc5a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.134097 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bdc5a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bdc5a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.172133 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8a37d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8a37d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.226086 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8a37d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8a37d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c271c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c271c50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.260389 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c271c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c271c50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b7f93d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b7f93d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.287431 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b7f93d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b7f93d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.338839 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.384350 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bcf3ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.419823 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ca3fd50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6ee190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6ee190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.472681 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6ee190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6ee190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.500697 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.533529 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c0204d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.590438 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacb290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacb290>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.636921 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacb290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3bacb290>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b965e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b965e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.679828 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b965e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b965e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.873960 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.903328 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.942791 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b534210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b59cfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b59cfd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:27.994556 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b59cfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b59cfd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6eced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6eced0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.043342 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6eced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b6eced0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8636d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8636d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.079635 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8636d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b8636d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.133838 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.168819 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3c0450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3c0450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.196000 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3c0450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3c0450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3f2b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3f2b90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.248259 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3f2b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b3f2b90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.293915 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b75f310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.328105 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.381427 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.408344 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.436985 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b2ab710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b1ba150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b1ba150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.494569 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b1ba150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b1ba150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.543908 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3c233910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b579ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b579ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.578346 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b579ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b579ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b001710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b001710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.631294 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b001710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b001710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.658414 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.691934 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b05a450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b0032d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b0032d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.750244 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b0032d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b0032d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b5fa210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b5fa210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.797534 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b5fa210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b5fa210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b57d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b57d910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.833230 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b57d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b57d910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ad61a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ad61a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.886943 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ad61a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ad61a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ae77c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ae77c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.915808 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ae77c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ae77c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3aea4390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3aea4390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.944891 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3aea4390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3aea4390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af70cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af70cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:28.997035 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af70cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af70cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af95cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af95cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.046500 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af95cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af95cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af8f450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af8f450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.084666 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af8f450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3af8f450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ace84d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ace84d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.140919 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ace84d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ace84d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac114d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac114d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.168013 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac114d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac114d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3abfc610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3abfc610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.195985 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3abfc610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3abfc610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.247966 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3add8a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3add8a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.295369 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3add8a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3add8a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b213f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b213f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.331061 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b213f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3b213f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a9f0ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a9f0ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.389621 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a9f0ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a9f0ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.416156 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.444326 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab49fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab25ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab25ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.497245 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab25ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ab25ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.546930 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3ac17a10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.582129 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.638554 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.682489 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.718751 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a8171d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a92d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a92d910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.771875 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a92d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3a92d910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.819884 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3adb6450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3acfca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3acfca10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:29.857277 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3acfca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3acfca10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d183ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d183ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:01:30.201599 140529127511936 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d183ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcf3d183ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From set_essential_params.py:632: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0703 18:01:31.494205 140529127511936 deprecation_wrapper.py:119] From set_essential_params.py:632: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0703 18:01:33.699037 140529127511936 set_essential_params.py:634] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.699313 140529127511936 set_essential_params.py:640]   name = bert/embeddings/word_embeddings:0, shape = (30522, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.699496 140529127511936 set_essential_params.py:640]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.699710 140529127511936 set_essential_params.py:640]   name = bert/embeddings/position_embeddings:0, shape = (512, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.699840 140529127511936 set_essential_params.py:640]   name = bert/embeddings/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.699958 140529127511936 set_essential_params.py:640]   name = bert/embeddings/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700072 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700194 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700306 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700437 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700558 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700676 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700788 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.700903 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701012 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701121 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701230 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701345 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701471 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701601 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701714 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.701944 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.702257 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.702455 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.702681 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.702860 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703016 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703163 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703299 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703462 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703602 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703733 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703859 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.703999 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704130 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704263 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704392 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704547 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704674 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704809 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.704936 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705070 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705196 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705328 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705475 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705618 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705746 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.705875 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706010 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706146 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706271 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706423 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706559 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706683 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706807 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.706938 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707062 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707190 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707311 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707476 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707610 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707741 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.707867 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.759961 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.760321 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.760541 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.760685 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.760834 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.760975 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.761133 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.761287 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.761454 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.761607 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.761782 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.761937 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.762100 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.762311 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.762504 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.762663 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.762819 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.762978 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.763168 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.763337 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.763513 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.763651 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.763787 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.763927 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.764075 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.764231 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.764382 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.764549 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.764703 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.764843 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765001 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765137 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765294 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765449 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765609 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765752 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.765897 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766036 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766179 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766323 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766494 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766635 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766788 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.766936 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767088 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767237 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767387 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767548 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767688 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767823 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.767965 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768103 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768264 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768418 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768561 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768698 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768845 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.768982 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769103 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769187 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769263 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769330 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769418 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769511 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769579 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769644 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769734 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769801 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769871 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.769938 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.770002 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.771471 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.771725 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.771859 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.771983 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.772097 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.772230 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.772338 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.772495 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.772903 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.863985 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.864247 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.864430 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.864565 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.864696 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.864817 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.864934 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.865051 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.865212 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.865365 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.865578 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.865743 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.865910 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.866068 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.866248 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.866420 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.866585 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.866743 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.866910 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.867068 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.867246 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.867420 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.867585 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.867748 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.867919 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.868078 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.868257 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.868427 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.868578 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.868717 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.868881 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869037 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869202 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869357 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869528 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869670 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869813 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.869951 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.870103 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.870284 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.870474 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.870639 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.870810 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.870968 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.871125 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.871278 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.871439 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.871592 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.871740 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.871882 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.872040 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.872214 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.872385 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.872563 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.872719 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.872865 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.873024 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.873191 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.873362 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.873536 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.873709 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.873863 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874020 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874176 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874327 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874487 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874650 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874802 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.874957 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.875108 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.875292 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_12/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.875453 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.875620 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.875769 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.875931 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.876080 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.876252 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.876417 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.876584 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.876740 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.876893 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.877044 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.877219 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.877378 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.877567 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.877730 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.877889 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_13/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.878047 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.878229 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.878387 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.878572 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.878859 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879036 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879204 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879356 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879515 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879660 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879804 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.879955 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.880104 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.880269 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.880429 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.880592 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_14/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.880751 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.880920 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.881081 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.881261 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.881434 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.881607 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.881767 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.881936 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.882095 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.882262 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.882432 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.882595 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.882740 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.882889 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883035 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883188 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_15/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883334 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883511 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883660 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883821 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.883970 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.884124 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.884284 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.884452 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.884608 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.884759 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.884902 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.885067 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.885231 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.885411 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.885576 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.885730 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_16/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.885884 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.886053 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.886221 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.886388 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.886564 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.886735 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.886897 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887066 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887228 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887370 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887530 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887692 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887840 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.887992 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.888139 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.888292 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_17/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.888468 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.888637 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.888796 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.888965 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.889125 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.889308 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.889486 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.889660 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.889820 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.889979 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.890156 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.890337 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.890520 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.890694 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.890841 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.890985 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_18/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.891131 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.891300 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.891465 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.891623 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.891773 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.891933 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.892079 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.892283 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.892449 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.892603 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.892746 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.892894 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893035 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893201 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893346 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893502 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_19/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893644 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893798 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.893933 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894079 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894230 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894382 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894542 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894695 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894835 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.894972 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.895112 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.895302 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.895466 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.895618 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.895762 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.895898 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_20/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896032 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896199 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896342 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896515 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896654 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896804 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.896941 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897086 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897240 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897377 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897539 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897688 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897830 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.897975 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.898109 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.898261 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_21/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.898396 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.898566 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.898701 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.898853 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899009 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899184 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899342 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899528 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899685 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899839 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.899989 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.900163 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.900326 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.900500 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.900649 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.900801 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_22/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.900951 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.901113 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.901283 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.901454 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.901597 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.901747 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.901888 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902032 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902184 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902326 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902483 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902639 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902777 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.902928 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.903063 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.903222 140529127511936 set_essential_params.py:640]   name = bert/encoder/layer_23/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.903358 140529127511936 set_essential_params.py:640]   name = bert/pooler/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.903532 140529127511936 set_essential_params.py:640]   name = bert/pooler/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.903677 140529127511936 set_essential_params.py:640]   name = cls/squad/output_weights:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "I0703 18:01:33.903825 140529127511936 set_essential_params.py:640]   name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0703 18:01:33.904610 140529127511936 estimator.py:1147] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0703 18:01:34.266977 140529127511936 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0703 18:01:35.077644 140529127511936 monitored_session.py:240] Graph was finalized.\n",
            "2022-07-03 18:01:35.081105: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-07-03 18:01:35.157360: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-07-03 18:01:35.159891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b7a1c0 executing computations on platform Host. Devices:\n",
            "2022-07-03 18:01:35.159955: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2022-07-03 18:01:36.007380: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0703 18:05:03.348259 140529127511936 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0703 18:05:03.436183 140529127511936 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Processing example: 0\n",
            "I0703 18:05:25.243690 140529127511936 set_essential_params.py:1259] Processing example: 0\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0703 18:05:25.382880 140529127511936 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0703 18:05:25.383182 140529127511936 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:Writing predictions to: output/predictions.json\n",
            "I0703 18:05:25.383378 140529127511936 set_essential_params.py:745] Writing predictions to: output/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: output/nbest_predictions.json\n",
            "I0703 18:05:25.383496 140529127511936 set_essential_params.py:746] Writing nbest to: output/nbest_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict again\n",
        "\n",
        "%%writefile input_file3.json\n",
        "{\n",
        "    \"version\": \"v2.0\",\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"title\": \"bert-on-squad-siemens-test-dataset\",\n",
        "            \"paragraphs\": [\n",
        "                {\n",
        "                    \"qas\": [\n",
        "                        {\n",
        "                            \"question\": \"Who is the current CEO of siemens?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9628\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"Who founded siemens?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9629\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"when was siemens founded?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9630\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"when did siemens opened up its first workshop?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9631\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"when was the last CEO change in siemens?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9632\",\n",
        "                            \"is_impossible\": \"\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"context\": \"Siemens & Halske was founded by Werner von Siemens and Johann Georg Halske on 1 October 1847. Based on the telegraph, their invention used a needle to point to the sequence of letters, instead of using Morse code. The company, then called Telegraphen-Bauanstalt von Siemens & Halske, opened its first workshop on 12 October 1847. Roland Busch was appointed CEO of siemens on February 3, 2021. In 1848, the company built the first long-distance telegraph line in Europe; 500 km from Berlin to Frankfurt am Main. In 1850, the founder's younger brother, Carl Wilhelm Siemens, later Sir William Siemens, started to represent the company in London. The London agency became a branch office in 1858. In the 1850s, the company was involved in building long-distance telegraph networks in Russia. In 1855, a company branch headed by another brother, Carl Heinrich von Siemens, opened in St Petersburg, Russia. In 1867, Siemens completed the monumental Indo-European telegraph line stretching over 11,000 km from London to Calcutta. First electric locomotive, built in 1879 by company founder Werner von Siemens. In 1867, Werner von Siemens described a dynamo without permanent magnets. A similar system was also independently invented by Ányos Jedlik and Charles Wheatstone, but Siemens became the first company to build such devices. In 1881, a Siemens AC Alternator driven by a watermill was used to power the world's first electric street lighting in the town of Godalming, United Kingdom. The company continued to grow and diversified into electric trains and light bulbs. In 1885, Siemens sold one of its generators to George Westinghouse, thereby enabling Westinghouse to begin experimenting with AC networks in Pittsburgh, Pennsylvania. In 1887, Siemens opened its first office in Japan. In 1890, the founder retired and left the running of the company to his brother Carl and sons Arnold and Wilhelm. In 1892, Siemens were contracted to construct the Hobart electric tramway in Tasmania, Australia as they increased their markets. The system opened in 1893 and became the first complete electric tram network in the Southern Hemisphere. Siemens & Halske (S & H) was incorporated in 1897, and then merged parts of its activities with Schuckert & Co., Nuremberg in 1903 to become Siemens-Schuckert. In 1907, Siemens (Siemens & Halske and Siemens-Schuckert) had 34,324 employees and was the seventh-largest company in the German empire by number of employees. In 1919, S & H and two other companies jointly formed the Osram lightbulb company. British Siemens advertisement from the 1920s era. During the 1920s and 1930s, S & H started to manufacture radios, television sets, and electron microscopes. In 1932, Reiniger, Gebbert & Schall (Erlangen), Phönix AG (Rudolstadt) and Siemens-Reiniger-Veifa mbH (Berlin) merged to form the Siemens-Reiniger-Werke AG (SRW), the third of the so-called parent companies that merged in 1966 to form the present-day Siemens AG. In the 1920s, Siemens constructed the Ardnacrusha Hydro Power station on the River Shannon in the then Irish Free State, and it was a world first for its design. The company is remembered for its desire to raise the wages of its under-paid workers only to be overruled by the Cumann na nGaedheal government. Siemens (at the time: Siemens-Schuckert) exploited the forced labour of deported people in extermination camps. The company owned a plant in Auschwitz concentration camp. Siemens Factory and Ravensbrück concentration camp. Siemens exploited the forced labour of women in the concentration camp of Ravensbrück. The factory was located in front of the camp. During the final years of World War II, numerous plants and factories in Berlin and other major cities were destroyed by Allied air raids. To prevent further losses, manufacturing was therefore moved to alternative places and regions not affected by the air war. The goal was to secure continued production of important war-related and everyday goods. According to records, Siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945. In 1972, Siemens sued German satirist F.C. Delius for his satirical history of the company, Unsere Siemen swelt, and it was determined much of the book contained false claims although the trial itself publicized Siemens' history in Nazi Germany. The company supplied electrical parts to Nazi concentration camps and death camps. The factories had poor working conditions, where malnutrition and death were common. Also, the scholarship has shown that the camp factories were created, run, and supplied by the SS, in conjunction with company officials, sometimes high-level officials. In the 1950s, and from their new base in Bavaria, S&H started to manufacture computers, semiconductor devices, washing machines, and pacemakers. In 1966, Siemens & Halske (S&H, founded in 1847), Siemens-Schuckertwerke (SSW, founded in 1903) and Siemens-Reiniger-Werke (SRW, founded in 1932) merged to form Siemens AG. In 1969, Siemens formed Kraftwerk Union with AEG by pooling their nuclear power businesses. A 1973 Siemens electron microscope on display at the Musée des Arts et Métiers in Paris. The company's first digital telephone exchange was produced in 1980. In 1988, Siemens and GEC acquired the UK defence and technology company Plessey. Plessey's holdings were split, and Siemens took over the avionics, radar and traffic control businesses—as Siemens Plessey. In 1977, Advanced Micro Devices (AMD) entered into a joint venture with Siemens, which wanted to enhance its technology expertise and enter the American market. Siemens purchased 20% of AMD's stock, giving the company an infusion of cash to increase its product lines. The two companies also jointly established Advanced Micro Computers (AMC), located in Silicon Valley and in Germany, allowing AMD to enter the microcomputer development and manufacturing field, in particular based on AMD's second-source Zilog Z8000 microprocessors. When the two companies' vision for Advanced Micro Computers diverged, AMD bought out Siemens' stake in the American division in 1979. AMD closed Advanced Micro Computers in late 1981 after switching focus to manufacturing second-source Intel x86 microprocessors. In 1985, Siemens bought Allis-Chalmers' interest in the partnership company Siemens-Allis (formed 1978) which supplied electrical control equipment. It was incorporated into Siemens' Energy and Automation division. In 1987, Siemens reintegrated Kraftwerk Union, the unit overseeing nuclear power business. In 1989, Siemens bought the solar photovoltaic business, including 3 solar module manufacturing plants, from industry pioneer ARCO Solar, owned by oil firm ARCO. In 1991, Siemens acquired Nixdorf Computer AG and renamed it Siemens Nixdorf Informationssysteme AG, in order to produce personal computers. In October 1991, Siemens acquired the Industrial Systems Division of Texas Instruments, Inc, based in Johnson City, Tennessee. This division was organized as Siemens Industrial Automation, Inc., and was later absorbed by Siemens Energy and Automation, Inc. In 1992, Siemens bought out IBM's half of ROLM (Siemens had bought into ROLM five years earlier), thus creating SiemensROLM Communications; eventually dropping ROLM from the name later in the 1990s. In 1993–1994, Siemens C651 electric trains for Singapore's Mass Rapid Transit (MRT) system were built in Austria. In 1997, Siemens agreed to sell the defence arm of Siemens Plessey to British Aerospace (BAe) and a German aerospace company, DaimlerChrysler Aerospace. BAe and DASA acquired the British and German divisions of the operation respectively. In October 1997, Siemens Financial Services (SFS) was founded to act as a competence center for financing issues and as a manager of financial risks within Siemens. In 1998, Siemens acquired Westinghouse Power Generation for more than $1.5 billion from the CBS Corporation and moving Siemens from third to second in the world power generation market. In 1999, Siemens' semiconductor operations were spun off into a new company called Infineon Technologies. Its Electromechanical Components operations were converted into a legally independent company: Siemens Electromechanical Components GmbH & Co. KG, (which, later that year, was sold to Tyco International Ltd for approximately $1.1 billion. In the same year, Siemens Nixdorf Informationssysteme AG became part of Fujitsu Siemens Computers AG, with its retail banking technology group becoming Wincor Nixdorf. In 2000, Shared Medical Systems Corporation was acquired by the Siemens' Medical Engineering Group, eventually becoming part of Siemens Medical Solutions. Also in 2000, Atecs-Mannesman was acquired by Siemens, The sale was finalised in April 2001 with 50% of the shares acquired, acquisition, Mannesmann VDO AG merged into Siemens Automotive forming Siemens VDO Automotive AG, Atecs Mannesmann Dematic Systems merged into Siemens Production and Logistics forming Siemens Dematic AG, Mannesmann Demag Delaval merged into the Power Generation division of Siemens AG. Other parts of the company were acquired by Robert Bosch GmbH at the same time. Also, Moore Products Co. of Spring House, PA USA was acquired by Siemens Energy & Automation, Inc.\"                \n",
        "                 }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIjh6h1ZLFE3",
        "outputId": "d6c3a442-b03d-4ade-beef-4a5c83e23582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing input_file3.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python set_essential_params.py \\\n",
        "  --vocab_file=$output_dir_name/uncased_L-24_H-1024_A-16/vocab.txt \\\n",
        "  --bert_config_file=$output_dir_name/uncased_L-24_H-1024_A-16/bert_config.json \\\n",
        "  --init_checkpoint=$output_dir_name/uncased_L-24_H-1024_A-16/model.ckpt-10859 \\\n",
        "  --do_train=False \\\n",
        "  --max_query_length=30  \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file=input_file2.json \\\n",
        "  --predict_batch_size=8 \\\n",
        "  --n_best_size=3 \\\n",
        "  --max_seq_length=384 \\\n",
        "  --doc_stride=128 \\\n",
        "  --output_dir=output2/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKPMd2PeQOow",
        "outputId": "18b9883e-9d23-4fe6-d63e-f82a4e91ad22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1283: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0703 18:11:58.283105 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0703 18:11:58.283420 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0703 18:11:58.283673 139789930788736 deprecation_wrapper.py:119] From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0703 18:11:58.695298 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0703 18:11:59.959490 139789930788736 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f232c51e7a0>) includes params argument, but params are not passed to Estimator.\n",
            "W0703 18:11:59.961386 139789930788736 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f232c51e7a0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'output2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2322279490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0703 18:11:59.962264 139789930788736 estimator.py:209] Using config: {'_model_dir': 'output2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2322279490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0703 18:11:59.962598 139789930788736 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0703 18:11:59.962851 139789930788736 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From set_essential_params.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0703 18:11:59.963041 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0703 18:11:59.968544 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0703 18:12:00.000568 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.000858 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000000\n",
            "I0703 18:12:00.000978 139789930788736 set_essential_params.py:432] unique_id: 1000000000\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.001065 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:12:00.001161 139789930788736 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his [SEP]\n",
            "I0703 18:12:00.001379 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:12 25:13 26:14 27:15 28:16 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:33 49:34 50:35 51:36 52:37 53:37 54:38 55:39 56:39 57:40 58:41 59:42 60:42 61:42 62:42 63:42 64:42 65:42 66:43 67:44 68:45 69:46 70:46 71:46 72:47 73:48 74:49 75:50 76:51 77:52 78:53 79:54 80:54 81:55 82:56 83:57 84:58 85:59 86:60 87:61 88:62 89:63 90:64 91:64 92:65 93:65 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:72 102:73 103:73 104:73 105:74 106:75 107:76 108:77 109:77 110:78 111:79 112:80 113:81 114:82 115:83 116:84 117:85 118:85 119:86 120:87 121:87 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:94 133:95 134:96 135:97 136:98 137:98 138:99 139:100 140:101 141:102 142:103 143:104 144:105 145:105 146:106 147:107 148:108 149:109 150:110 151:111 152:112 153:113 154:114 155:114 156:115 157:116 158:117 159:117 160:118 161:119 162:120 163:121 164:122 165:123 166:124 167:124 168:124 169:125 170:126 171:127 172:128 173:128 174:129 175:130 176:130 177:131 178:132 179:133 180:134 181:135 182:136 183:137 184:137 185:138 186:139 187:140 188:141 189:141 190:142 191:143 192:144 193:145 194:145 195:146 196:146 197:147 198:148 199:148 200:149 201:150 202:151 203:152 204:153 205:153 206:153 207:154 208:155 209:156 210:157 211:158 212:158 213:158 214:159 215:160 216:161 217:162 218:163 219:163 220:164 221:165 222:166 223:166 224:167 225:168 226:169 227:170 228:171 229:172 230:173 231:174 232:175 233:175 234:176 235:177 236:177 237:178 238:179 239:180 240:181 241:182 242:183 243:184 244:185 245:186 246:186 247:186 248:187 249:188 250:189 251:190 252:191 253:192 254:193 255:194 256:195 257:195 258:196 259:196 260:197 261:198 262:199 263:199 264:199 265:200 266:201 267:202 268:203 269:204 270:205 271:206 272:207 273:208 274:209 275:209 276:210 277:211 278:211 279:212 280:213 281:214 282:215 283:215 284:216 285:217 286:218 287:219 288:219 289:220 290:221 291:222 292:223 293:224 294:225 295:225 296:225 297:226 298:227 299:228 300:229 301:230 302:231 303:232 304:233 305:234 306:234 307:234 308:234 309:235 310:236 311:236 312:237 313:238 314:239 315:240 316:241 317:242 318:243 319:244 320:245 321:246 322:247 323:248 324:249 325:249 326:250 327:251 328:251 329:252 330:253 331:254 332:255 333:256 334:257 335:258 336:259 337:260 338:260 339:260 340:260 341:261 342:262 343:263 344:263 345:263 346:264 347:265 348:266 349:267 350:268 351:269 352:270 353:271 354:271 355:272 356:272 357:273 358:274 359:274 360:275 361:276 362:277 363:278 364:279 365:280 366:281 367:281 368:282 369:283 370:283 371:284 372:285 373:286 374:287 375:288 376:289 377:290 378:291 379:292 380:293 381:294 382:295\n",
            "I0703 18:12:00.001621 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:0 11:1 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:12 25:13 26:14 27:15 28:16 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:32 48:33 49:34 50:35 51:36 52:37 53:37 54:38 55:39 56:39 57:40 58:41 59:42 60:42 61:42 62:42 63:42 64:42 65:42 66:43 67:44 68:45 69:46 70:46 71:46 72:47 73:48 74:49 75:50 76:51 77:52 78:53 79:54 80:54 81:55 82:56 83:57 84:58 85:59 86:60 87:61 88:62 89:63 90:64 91:64 92:65 93:65 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:72 102:73 103:73 104:73 105:74 106:75 107:76 108:77 109:77 110:78 111:79 112:80 113:81 114:82 115:83 116:84 117:85 118:85 119:86 120:87 121:87 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:94 133:95 134:96 135:97 136:98 137:98 138:99 139:100 140:101 141:102 142:103 143:104 144:105 145:105 146:106 147:107 148:108 149:109 150:110 151:111 152:112 153:113 154:114 155:114 156:115 157:116 158:117 159:117 160:118 161:119 162:120 163:121 164:122 165:123 166:124 167:124 168:124 169:125 170:126 171:127 172:128 173:128 174:129 175:130 176:130 177:131 178:132 179:133 180:134 181:135 182:136 183:137 184:137 185:138 186:139 187:140 188:141 189:141 190:142 191:143 192:144 193:145 194:145 195:146 196:146 197:147 198:148 199:148 200:149 201:150 202:151 203:152 204:153 205:153 206:153 207:154 208:155 209:156 210:157 211:158 212:158 213:158 214:159 215:160 216:161 217:162 218:163 219:163 220:164 221:165 222:166 223:166 224:167 225:168 226:169 227:170 228:171 229:172 230:173 231:174 232:175 233:175 234:176 235:177 236:177 237:178 238:179 239:180 240:181 241:182 242:183 243:184 244:185 245:186 246:186 247:186 248:187 249:188 250:189 251:190 252:191 253:192 254:193 255:194 256:195 257:195 258:196 259:196 260:197 261:198 262:199 263:199 264:199 265:200 266:201 267:202 268:203 269:204 270:205 271:206 272:207 273:208 274:209 275:209 276:210 277:211 278:211 279:212 280:213 281:214 282:215 283:215 284:216 285:217 286:218 287:219 288:219 289:220 290:221 291:222 292:223 293:224 294:225 295:225 296:225 297:226 298:227 299:228 300:229 301:230 302:231 303:232 304:233 305:234 306:234 307:234 308:234 309:235 310:236 311:236 312:237 313:238 314:239 315:240 316:241 317:242 318:243 319:244 320:245 321:246 322:247 323:248 324:249 325:249 326:250 327:251 328:251 329:252 330:253 331:254 332:255 333:256 334:257 335:258 336:259 337:260 338:260 339:260 340:260 341:261 342:262 343:263 344:263 345:263 346:264 347:265 348:266 349:267 350:268 351:269 352:270 353:271 354:271 355:272 356:272 357:273 358:274 359:274 360:275 361:276 362:277 363:278 364:279 365:280 366:281 367:281 368:282 369:283 370:283 371:284 372:285 373:286 374:287 375:288 376:289 377:290 378:291 379:292 380:293 381:294 382:295\n",
            "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.001864 139789930788736 set_essential_params.py:440] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 102\n",
            "I0703 18:12:00.039524 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.040046 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.040370 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.044346 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000001\n",
            "I0703 18:12:00.044517 139789930788736 set_essential_params.py:432] unique_id: 1000000001\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.044615 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "I0703 18:12:00.044700 139789930788736 set_essential_params.py:434] doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . [SEP]\n",
            "I0703 18:12:00.044918 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:99 11:100 12:101 13:102 14:103 15:104 16:105 17:105 18:106 19:107 20:108 21:109 22:110 23:111 24:112 25:113 26:114 27:114 28:115 29:116 30:117 31:117 32:118 33:119 34:120 35:121 36:122 37:123 38:124 39:124 40:124 41:125 42:126 43:127 44:128 45:128 46:129 47:130 48:130 49:131 50:132 51:133 52:134 53:135 54:136 55:137 56:137 57:138 58:139 59:140 60:141 61:141 62:142 63:143 64:144 65:145 66:145 67:146 68:146 69:147 70:148 71:148 72:149 73:150 74:151 75:152 76:153 77:153 78:153 79:154 80:155 81:156 82:157 83:158 84:158 85:158 86:159 87:160 88:161 89:162 90:163 91:163 92:164 93:165 94:166 95:166 96:167 97:168 98:169 99:170 100:171 101:172 102:173 103:174 104:175 105:175 106:176 107:177 108:177 109:178 110:179 111:180 112:181 113:182 114:183 115:184 116:185 117:186 118:186 119:186 120:187 121:188 122:189 123:190 124:191 125:192 126:193 127:194 128:195 129:195 130:196 131:196 132:197 133:198 134:199 135:199 136:199 137:200 138:201 139:202 140:203 141:204 142:205 143:206 144:207 145:208 146:209 147:209 148:210 149:211 150:211 151:212 152:213 153:214 154:215 155:215 156:216 157:217 158:218 159:219 160:219 161:220 162:221 163:222 164:223 165:224 166:225 167:225 168:225 169:226 170:227 171:228 172:229 173:230 174:231 175:232 176:233 177:234 178:234 179:234 180:234 181:235 182:236 183:236 184:237 185:238 186:239 187:240 188:241 189:242 190:243 191:244 192:245 193:246 194:247 195:248 196:249 197:249 198:250 199:251 200:251 201:252 202:253 203:254 204:255 205:256 206:257 207:258 208:259 209:260 210:260 211:260 212:260 213:261 214:262 215:263 216:263 217:263 218:264 219:265 220:266 221:267 222:268 223:269 224:270 225:271 226:271 227:272 228:272 229:273 230:274 231:274 232:275 233:276 234:277 235:278 236:279 237:280 238:281 239:281 240:282 241:283 242:283 243:284 244:285 245:286 246:287 247:288 248:289 249:290 250:291 251:292 252:293 253:294 254:295 255:296 256:297 257:298 258:299 259:300 260:301 261:302 262:302 263:303 264:304 265:304 266:305 267:306 268:307 269:308 270:309 271:310 272:311 273:312 274:313 275:314 276:315 277:315 278:316 279:317 280:318 281:319 282:320 283:321 284:321 285:322 286:323 287:324 288:325 289:326 290:327 291:328 292:329 293:330 294:331 295:332 296:333 297:334 298:335 299:336 300:337 301:338 302:338 303:339 304:340 305:341 306:341 307:342 308:342 309:343 310:344 311:344 312:345 313:346 314:347 315:348 316:348 317:349 318:350 319:351 320:352 321:353 322:354 323:355 324:356 325:357 326:357 327:357 328:357 329:358 330:359 331:359 332:359 333:360 334:361 335:362 336:363 337:364 338:365 339:365 340:365 341:365 342:365 343:365 344:365 345:366 346:367 347:367 348:368 349:369 350:369 351:370 352:371 353:371 354:372 355:373 356:373 357:373 358:373 359:373 360:373 361:373 362:374 363:375 364:375 365:375 366:376 367:377 368:378 369:379 370:380 371:380 372:380 373:381 374:382 375:383 376:384 377:385 378:386 379:387 380:388 381:389 382:389\n",
            "I0703 18:12:00.045145 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:99 11:100 12:101 13:102 14:103 15:104 16:105 17:105 18:106 19:107 20:108 21:109 22:110 23:111 24:112 25:113 26:114 27:114 28:115 29:116 30:117 31:117 32:118 33:119 34:120 35:121 36:122 37:123 38:124 39:124 40:124 41:125 42:126 43:127 44:128 45:128 46:129 47:130 48:130 49:131 50:132 51:133 52:134 53:135 54:136 55:137 56:137 57:138 58:139 59:140 60:141 61:141 62:142 63:143 64:144 65:145 66:145 67:146 68:146 69:147 70:148 71:148 72:149 73:150 74:151 75:152 76:153 77:153 78:153 79:154 80:155 81:156 82:157 83:158 84:158 85:158 86:159 87:160 88:161 89:162 90:163 91:163 92:164 93:165 94:166 95:166 96:167 97:168 98:169 99:170 100:171 101:172 102:173 103:174 104:175 105:175 106:176 107:177 108:177 109:178 110:179 111:180 112:181 113:182 114:183 115:184 116:185 117:186 118:186 119:186 120:187 121:188 122:189 123:190 124:191 125:192 126:193 127:194 128:195 129:195 130:196 131:196 132:197 133:198 134:199 135:199 136:199 137:200 138:201 139:202 140:203 141:204 142:205 143:206 144:207 145:208 146:209 147:209 148:210 149:211 150:211 151:212 152:213 153:214 154:215 155:215 156:216 157:217 158:218 159:219 160:219 161:220 162:221 163:222 164:223 165:224 166:225 167:225 168:225 169:226 170:227 171:228 172:229 173:230 174:231 175:232 176:233 177:234 178:234 179:234 180:234 181:235 182:236 183:236 184:237 185:238 186:239 187:240 188:241 189:242 190:243 191:244 192:245 193:246 194:247 195:248 196:249 197:249 198:250 199:251 200:251 201:252 202:253 203:254 204:255 205:256 206:257 207:258 208:259 209:260 210:260 211:260 212:260 213:261 214:262 215:263 216:263 217:263 218:264 219:265 220:266 221:267 222:268 223:269 224:270 225:271 226:271 227:272 228:272 229:273 230:274 231:274 232:275 233:276 234:277 235:278 236:279 237:280 238:281 239:281 240:282 241:283 242:283 243:284 244:285 245:286 246:287 247:288 248:289 249:290 250:291 251:292 252:293 253:294 254:295 255:296 256:297 257:298 258:299 259:300 260:301 261:302 262:302 263:303 264:304 265:304 266:305 267:306 268:307 269:308 270:309 271:310 272:311 273:312 274:313 275:314 276:315 277:315 278:316 279:317 280:318 281:319 282:320 283:321 284:321 285:322 286:323 287:324 288:325 289:326 290:327 291:328 292:329 293:330 294:331 295:332 296:333 297:334 298:335 299:336 300:337 301:338 302:338 303:339 304:340 305:341 306:341 307:342 308:342 309:343 310:344 311:344 312:345 313:346 314:347 315:348 316:348 317:349 318:350 319:351 320:352 321:353 322:354 323:355 324:356 325:357 326:357 327:357 328:357 329:358 330:359 331:359 332:359 333:360 334:361 335:362 336:363 337:364 338:365 339:365 340:365 341:365 342:365 343:365 344:365 345:366 346:367 347:367 348:368 349:369 350:369 351:370 352:371 353:371 354:372 355:373 356:373 357:373 358:373 359:373 360:373 361:373 362:374 363:375 364:375 365:375 366:376 367:377 368:378 369:379 370:380 371:380 372:380 373:381 374:382 375:383 376:384 377:385 378:386 379:387 380:388 381:389 382:389\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.045374 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 102\n",
            "I0703 18:12:00.143198 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.143717 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.144020 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.148614 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000002\n",
            "I0703 18:12:00.148791 139789930788736 set_essential_params.py:432] unique_id: 1000000002\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.148889 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "I0703 18:12:00.148975 139789930788736 set_essential_params.py:434] doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day [SEP]\n",
            "I0703 18:12:00.149192 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:201 11:202 12:203 13:204 14:205 15:206 16:207 17:208 18:209 19:209 20:210 21:211 22:211 23:212 24:213 25:214 26:215 27:215 28:216 29:217 30:218 31:219 32:219 33:220 34:221 35:222 36:223 37:224 38:225 39:225 40:225 41:226 42:227 43:228 44:229 45:230 46:231 47:232 48:233 49:234 50:234 51:234 52:234 53:235 54:236 55:236 56:237 57:238 58:239 59:240 60:241 61:242 62:243 63:244 64:245 65:246 66:247 67:248 68:249 69:249 70:250 71:251 72:251 73:252 74:253 75:254 76:255 77:256 78:257 79:258 80:259 81:260 82:260 83:260 84:260 85:261 86:262 87:263 88:263 89:263 90:264 91:265 92:266 93:267 94:268 95:269 96:270 97:271 98:271 99:272 100:272 101:273 102:274 103:274 104:275 105:276 106:277 107:278 108:279 109:280 110:281 111:281 112:282 113:283 114:283 115:284 116:285 117:286 118:287 119:288 120:289 121:290 122:291 123:292 124:293 125:294 126:295 127:296 128:297 129:298 130:299 131:300 132:301 133:302 134:302 135:303 136:304 137:304 138:305 139:306 140:307 141:308 142:309 143:310 144:311 145:312 146:313 147:314 148:315 149:315 150:316 151:317 152:318 153:319 154:320 155:321 156:321 157:322 158:323 159:324 160:325 161:326 162:327 163:328 164:329 165:330 166:331 167:332 168:333 169:334 170:335 171:336 172:337 173:338 174:338 175:339 176:340 177:341 178:341 179:342 180:342 181:343 182:344 183:344 184:345 185:346 186:347 187:348 188:348 189:349 190:350 191:351 192:352 193:353 194:354 195:355 196:356 197:357 198:357 199:357 200:357 201:358 202:359 203:359 204:359 205:360 206:361 207:362 208:363 209:364 210:365 211:365 212:365 213:365 214:365 215:365 216:365 217:366 218:367 219:367 220:368 221:369 222:369 223:370 224:371 225:371 226:372 227:373 228:373 229:373 230:373 231:373 232:373 233:373 234:374 235:375 236:375 237:375 238:376 239:377 240:378 241:379 242:380 243:380 244:380 245:381 246:382 247:383 248:384 249:385 250:386 251:387 252:388 253:389 254:389 255:390 256:391 257:391 258:392 259:393 260:394 261:395 262:396 263:397 264:398 265:399 266:400 267:401 268:402 269:402 270:403 271:403 272:403 273:404 274:404 275:405 276:406 277:407 278:408 279:409 280:410 281:411 282:411 283:412 284:413 285:414 286:415 287:416 288:416 289:417 290:418 291:419 292:420 293:421 294:422 295:423 296:423 297:424 298:425 299:425 300:426 301:427 302:428 303:428 304:428 305:429 306:430 307:430 308:431 309:431 310:431 311:432 312:432 313:432 314:433 315:434 316:434 317:435 318:435 319:435 320:435 321:435 322:435 323:436 324:436 325:436 326:437 327:438 328:438 329:438 330:438 331:438 332:438 333:439 334:440 335:440 336:440 337:440 338:440 339:440 340:440 341:440 342:441 343:441 344:442 345:442 346:442 347:443 348:444 349:445 350:446 351:447 352:447 353:447 354:447 355:447 356:447 357:447 358:448 359:449 360:449 361:449 362:449 363:449 364:450 365:451 366:452 367:453 368:454 369:454 370:454 371:455 372:456 373:457 374:458 375:459 376:460 377:461 378:462 379:463 380:464 381:464 382:464\n",
            "I0703 18:12:00.149442 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:201 11:202 12:203 13:204 14:205 15:206 16:207 17:208 18:209 19:209 20:210 21:211 22:211 23:212 24:213 25:214 26:215 27:215 28:216 29:217 30:218 31:219 32:219 33:220 34:221 35:222 36:223 37:224 38:225 39:225 40:225 41:226 42:227 43:228 44:229 45:230 46:231 47:232 48:233 49:234 50:234 51:234 52:234 53:235 54:236 55:236 56:237 57:238 58:239 59:240 60:241 61:242 62:243 63:244 64:245 65:246 66:247 67:248 68:249 69:249 70:250 71:251 72:251 73:252 74:253 75:254 76:255 77:256 78:257 79:258 80:259 81:260 82:260 83:260 84:260 85:261 86:262 87:263 88:263 89:263 90:264 91:265 92:266 93:267 94:268 95:269 96:270 97:271 98:271 99:272 100:272 101:273 102:274 103:274 104:275 105:276 106:277 107:278 108:279 109:280 110:281 111:281 112:282 113:283 114:283 115:284 116:285 117:286 118:287 119:288 120:289 121:290 122:291 123:292 124:293 125:294 126:295 127:296 128:297 129:298 130:299 131:300 132:301 133:302 134:302 135:303 136:304 137:304 138:305 139:306 140:307 141:308 142:309 143:310 144:311 145:312 146:313 147:314 148:315 149:315 150:316 151:317 152:318 153:319 154:320 155:321 156:321 157:322 158:323 159:324 160:325 161:326 162:327 163:328 164:329 165:330 166:331 167:332 168:333 169:334 170:335 171:336 172:337 173:338 174:338 175:339 176:340 177:341 178:341 179:342 180:342 181:343 182:344 183:344 184:345 185:346 186:347 187:348 188:348 189:349 190:350 191:351 192:352 193:353 194:354 195:355 196:356 197:357 198:357 199:357 200:357 201:358 202:359 203:359 204:359 205:360 206:361 207:362 208:363 209:364 210:365 211:365 212:365 213:365 214:365 215:365 216:365 217:366 218:367 219:367 220:368 221:369 222:369 223:370 224:371 225:371 226:372 227:373 228:373 229:373 230:373 231:373 232:373 233:373 234:374 235:375 236:375 237:375 238:376 239:377 240:378 241:379 242:380 243:380 244:380 245:381 246:382 247:383 248:384 249:385 250:386 251:387 252:388 253:389 254:389 255:390 256:391 257:391 258:392 259:393 260:394 261:395 262:396 263:397 264:398 265:399 266:400 267:401 268:402 269:402 270:403 271:403 272:403 273:404 274:404 275:405 276:406 277:407 278:408 279:409 280:410 281:411 282:411 283:412 284:413 285:414 286:415 287:416 288:416 289:417 290:418 291:419 292:420 293:421 294:422 295:423 296:423 297:424 298:425 299:425 300:426 301:427 302:428 303:428 304:428 305:429 306:430 307:430 308:431 309:431 310:431 311:432 312:432 313:432 314:433 315:434 316:434 317:435 318:435 319:435 320:435 321:435 322:435 323:436 324:436 325:436 326:437 327:438 328:438 329:438 330:438 331:438 332:438 333:439 334:440 335:440 336:440 337:440 338:440 339:440 340:440 341:440 342:441 343:441 344:442 345:442 346:442 347:443 348:444 349:445 350:446 351:447 352:447 353:447 354:447 355:447 356:447 357:447 358:448 359:449 360:449 361:449 362:449 363:449 364:450 365:451 366:452 367:453 368:454 369:454 370:454 371:455 372:456 373:457 374:458 375:459 376:460 377:461 378:462 379:463 380:464 381:464 382:464\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.149656 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 102\n",
            "I0703 18:12:00.247967 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.248483 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.248815 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.254324 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000003\n",
            "I0703 18:12:00.254618 139789930788736 set_essential_params.py:432] unique_id: 1000000003\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.254709 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 3\n",
            "I0703 18:12:00.254788 139789930788736 set_essential_params.py:434] doc_span_index: 3\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration [SEP]\n",
            "I0703 18:12:00.255064 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:305 11:306 12:307 13:308 14:309 15:310 16:311 17:312 18:313 19:314 20:315 21:315 22:316 23:317 24:318 25:319 26:320 27:321 28:321 29:322 30:323 31:324 32:325 33:326 34:327 35:328 36:329 37:330 38:331 39:332 40:333 41:334 42:335 43:336 44:337 45:338 46:338 47:339 48:340 49:341 50:341 51:342 52:342 53:343 54:344 55:344 56:345 57:346 58:347 59:348 60:348 61:349 62:350 63:351 64:352 65:353 66:354 67:355 68:356 69:357 70:357 71:357 72:357 73:358 74:359 75:359 76:359 77:360 78:361 79:362 80:363 81:364 82:365 83:365 84:365 85:365 86:365 87:365 88:365 89:366 90:367 91:367 92:368 93:369 94:369 95:370 96:371 97:371 98:372 99:373 100:373 101:373 102:373 103:373 104:373 105:373 106:374 107:375 108:375 109:375 110:376 111:377 112:378 113:379 114:380 115:380 116:380 117:381 118:382 119:383 120:384 121:385 122:386 123:387 124:388 125:389 126:389 127:390 128:391 129:391 130:392 131:393 132:394 133:395 134:396 135:397 136:398 137:399 138:400 139:401 140:402 141:402 142:403 143:403 144:403 145:404 146:404 147:405 148:406 149:407 150:408 151:409 152:410 153:411 154:411 155:412 156:413 157:414 158:415 159:416 160:416 161:417 162:418 163:419 164:420 165:421 166:422 167:423 168:423 169:424 170:425 171:425 172:426 173:427 174:428 175:428 176:428 177:429 178:430 179:430 180:431 181:431 182:431 183:432 184:432 185:432 186:433 187:434 188:434 189:435 190:435 191:435 192:435 193:435 194:435 195:436 196:436 197:436 198:437 199:438 200:438 201:438 202:438 203:438 204:438 205:439 206:440 207:440 208:440 209:440 210:440 211:440 212:440 213:440 214:441 215:441 216:442 217:442 218:442 219:443 220:444 221:445 222:446 223:447 224:447 225:447 226:447 227:447 228:447 229:447 230:448 231:449 232:449 233:449 234:449 235:449 236:450 237:451 238:452 239:453 240:454 241:454 242:454 243:455 244:456 245:457 246:458 247:459 248:460 249:461 250:462 251:463 252:464 253:464 254:464 255:465 256:466 257:466 258:467 259:468 260:469 261:469 262:470 263:471 264:472 265:473 266:473 267:473 268:473 269:473 270:474 271:475 272:476 273:477 274:478 275:479 276:480 277:481 278:482 279:483 280:484 281:485 282:486 283:486 284:487 285:488 286:489 287:490 288:491 289:492 290:493 291:494 292:495 293:495 294:496 295:497 296:498 297:499 298:500 299:501 300:502 301:503 302:504 303:505 304:506 305:507 306:508 307:509 308:509 309:509 310:510 311:511 312:512 313:513 314:514 315:514 316:514 317:515 318:516 319:517 320:517 321:518 322:519 323:519 324:519 325:519 326:520 327:520 328:521 329:522 330:522 331:523 332:524 333:524 334:525 335:525 336:525 337:525 338:525 339:525 340:525 341:526 342:527 343:528 344:529 345:530 346:531 347:532 348:533 349:534 350:534 351:534 352:534 353:535 354:535 355:536 356:537 357:538 358:539 359:540 360:541 361:542 362:543 363:544 364:544 365:545 366:546 367:547 368:548 369:548 370:549 371:550 372:550 373:551 374:552 375:553 376:554 377:555 378:556 379:557 380:558 381:559 382:560\n",
            "I0703 18:12:00.255427 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:305 11:306 12:307 13:308 14:309 15:310 16:311 17:312 18:313 19:314 20:315 21:315 22:316 23:317 24:318 25:319 26:320 27:321 28:321 29:322 30:323 31:324 32:325 33:326 34:327 35:328 36:329 37:330 38:331 39:332 40:333 41:334 42:335 43:336 44:337 45:338 46:338 47:339 48:340 49:341 50:341 51:342 52:342 53:343 54:344 55:344 56:345 57:346 58:347 59:348 60:348 61:349 62:350 63:351 64:352 65:353 66:354 67:355 68:356 69:357 70:357 71:357 72:357 73:358 74:359 75:359 76:359 77:360 78:361 79:362 80:363 81:364 82:365 83:365 84:365 85:365 86:365 87:365 88:365 89:366 90:367 91:367 92:368 93:369 94:369 95:370 96:371 97:371 98:372 99:373 100:373 101:373 102:373 103:373 104:373 105:373 106:374 107:375 108:375 109:375 110:376 111:377 112:378 113:379 114:380 115:380 116:380 117:381 118:382 119:383 120:384 121:385 122:386 123:387 124:388 125:389 126:389 127:390 128:391 129:391 130:392 131:393 132:394 133:395 134:396 135:397 136:398 137:399 138:400 139:401 140:402 141:402 142:403 143:403 144:403 145:404 146:404 147:405 148:406 149:407 150:408 151:409 152:410 153:411 154:411 155:412 156:413 157:414 158:415 159:416 160:416 161:417 162:418 163:419 164:420 165:421 166:422 167:423 168:423 169:424 170:425 171:425 172:426 173:427 174:428 175:428 176:428 177:429 178:430 179:430 180:431 181:431 182:431 183:432 184:432 185:432 186:433 187:434 188:434 189:435 190:435 191:435 192:435 193:435 194:435 195:436 196:436 197:436 198:437 199:438 200:438 201:438 202:438 203:438 204:438 205:439 206:440 207:440 208:440 209:440 210:440 211:440 212:440 213:440 214:441 215:441 216:442 217:442 218:442 219:443 220:444 221:445 222:446 223:447 224:447 225:447 226:447 227:447 228:447 229:447 230:448 231:449 232:449 233:449 234:449 235:449 236:450 237:451 238:452 239:453 240:454 241:454 242:454 243:455 244:456 245:457 246:458 247:459 248:460 249:461 250:462 251:463 252:464 253:464 254:464 255:465 256:466 257:466 258:467 259:468 260:469 261:469 262:470 263:471 264:472 265:473 266:473 267:473 268:473 269:473 270:474 271:475 272:476 273:477 274:478 275:479 276:480 277:481 278:482 279:483 280:484 281:485 282:486 283:486 284:487 285:488 286:489 287:490 288:491 289:492 290:493 291:494 292:495 293:495 294:496 295:497 296:498 297:499 298:500 299:501 300:502 301:503 302:504 303:505 304:506 305:507 306:508 307:509 308:509 309:509 310:510 311:511 312:512 313:513 314:514 315:514 316:514 317:515 318:516 319:517 320:517 321:518 322:519 323:519 324:519 325:519 326:520 327:520 328:521 329:522 330:522 331:523 332:524 333:524 334:525 335:525 336:525 337:525 338:525 339:525 340:525 341:526 342:527 343:528 344:529 345:530 346:531 347:532 348:533 349:534 350:534 351:534 352:534 353:535 354:535 355:536 356:537 357:538 358:539 359:540 360:541 361:542 362:543 363:544 364:544 365:545 366:546 367:547 368:548 369:548 370:549 371:550 372:550 373:551 374:552 375:553 376:554 377:555 378:556 379:557 380:558 381:559 382:560\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.348394 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 102\n",
            "I0703 18:12:00.350052 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.350481 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.350811 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.354315 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000004\n",
            "I0703 18:12:00.354492 139789930788736 set_essential_params.py:432] unique_id: 1000000004\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.354594 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 4\n",
            "I0703 18:12:00.354684 139789930788736 set_essential_params.py:434] doc_span_index: 4\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e [SEP]\n",
            "I0703 18:12:00.354896 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:400 11:401 12:402 13:402 14:403 15:403 16:403 17:404 18:404 19:405 20:406 21:407 22:408 23:409 24:410 25:411 26:411 27:412 28:413 29:414 30:415 31:416 32:416 33:417 34:418 35:419 36:420 37:421 38:422 39:423 40:423 41:424 42:425 43:425 44:426 45:427 46:428 47:428 48:428 49:429 50:430 51:430 52:431 53:431 54:431 55:432 56:432 57:432 58:433 59:434 60:434 61:435 62:435 63:435 64:435 65:435 66:435 67:436 68:436 69:436 70:437 71:438 72:438 73:438 74:438 75:438 76:438 77:439 78:440 79:440 80:440 81:440 82:440 83:440 84:440 85:440 86:441 87:441 88:442 89:442 90:442 91:443 92:444 93:445 94:446 95:447 96:447 97:447 98:447 99:447 100:447 101:447 102:448 103:449 104:449 105:449 106:449 107:449 108:450 109:451 110:452 111:453 112:454 113:454 114:454 115:455 116:456 117:457 118:458 119:459 120:460 121:461 122:462 123:463 124:464 125:464 126:464 127:465 128:466 129:466 130:467 131:468 132:469 133:469 134:470 135:471 136:472 137:473 138:473 139:473 140:473 141:473 142:474 143:475 144:476 145:477 146:478 147:479 148:480 149:481 150:482 151:483 152:484 153:485 154:486 155:486 156:487 157:488 158:489 159:490 160:491 161:492 162:493 163:494 164:495 165:495 166:496 167:497 168:498 169:499 170:500 171:501 172:502 173:503 174:504 175:505 176:506 177:507 178:508 179:509 180:509 181:509 182:510 183:511 184:512 185:513 186:514 187:514 188:514 189:515 190:516 191:517 192:517 193:518 194:519 195:519 196:519 197:519 198:520 199:520 200:521 201:522 202:522 203:523 204:524 205:524 206:525 207:525 208:525 209:525 210:525 211:525 212:525 213:526 214:527 215:528 216:529 217:530 218:531 219:532 220:533 221:534 222:534 223:534 224:534 225:535 226:535 227:536 228:537 229:538 230:539 231:540 232:541 233:542 234:543 235:544 236:544 237:545 238:546 239:547 240:548 241:548 242:549 243:550 244:550 245:551 246:552 247:553 248:554 249:555 250:556 251:557 252:558 253:559 254:560 255:561 256:562 257:563 258:563 259:563 260:564 261:565 262:566 263:567 264:568 265:569 266:570 267:571 268:572 269:572 270:573 271:574 272:575 273:576 274:577 275:578 276:579 277:580 278:580 279:581 280:582 281:583 282:584 283:585 284:586 285:587 286:588 287:589 288:590 289:591 290:592 291:593 292:594 293:595 294:596 295:596 296:597 297:598 298:599 299:600 300:600 301:601 302:602 303:603 304:604 305:605 306:606 307:607 308:608 309:609 310:610 311:611 312:612 313:613 314:614 315:615 316:615 317:616 318:617 319:618 320:619 321:620 322:621 323:622 324:623 325:624 326:625 327:625 328:625 329:626 330:627 331:628 332:628 333:629 334:630 335:631 336:631 337:632 338:633 339:634 340:635 341:636 342:637 343:638 344:639 345:640 346:641 347:642 348:643 349:644 350:645 351:646 352:647 353:648 354:649 355:650 356:650 357:651 358:652 359:652 360:653 361:654 362:655 363:656 364:656 365:656 366:657 367:657 368:657 369:657 370:658 371:658 372:659 373:660 374:661 375:662 376:663 377:664 378:665 379:665 380:666 381:666 382:666\n",
            "I0703 18:12:00.355127 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:400 11:401 12:402 13:402 14:403 15:403 16:403 17:404 18:404 19:405 20:406 21:407 22:408 23:409 24:410 25:411 26:411 27:412 28:413 29:414 30:415 31:416 32:416 33:417 34:418 35:419 36:420 37:421 38:422 39:423 40:423 41:424 42:425 43:425 44:426 45:427 46:428 47:428 48:428 49:429 50:430 51:430 52:431 53:431 54:431 55:432 56:432 57:432 58:433 59:434 60:434 61:435 62:435 63:435 64:435 65:435 66:435 67:436 68:436 69:436 70:437 71:438 72:438 73:438 74:438 75:438 76:438 77:439 78:440 79:440 80:440 81:440 82:440 83:440 84:440 85:440 86:441 87:441 88:442 89:442 90:442 91:443 92:444 93:445 94:446 95:447 96:447 97:447 98:447 99:447 100:447 101:447 102:448 103:449 104:449 105:449 106:449 107:449 108:450 109:451 110:452 111:453 112:454 113:454 114:454 115:455 116:456 117:457 118:458 119:459 120:460 121:461 122:462 123:463 124:464 125:464 126:464 127:465 128:466 129:466 130:467 131:468 132:469 133:469 134:470 135:471 136:472 137:473 138:473 139:473 140:473 141:473 142:474 143:475 144:476 145:477 146:478 147:479 148:480 149:481 150:482 151:483 152:484 153:485 154:486 155:486 156:487 157:488 158:489 159:490 160:491 161:492 162:493 163:494 164:495 165:495 166:496 167:497 168:498 169:499 170:500 171:501 172:502 173:503 174:504 175:505 176:506 177:507 178:508 179:509 180:509 181:509 182:510 183:511 184:512 185:513 186:514 187:514 188:514 189:515 190:516 191:517 192:517 193:518 194:519 195:519 196:519 197:519 198:520 199:520 200:521 201:522 202:522 203:523 204:524 205:524 206:525 207:525 208:525 209:525 210:525 211:525 212:525 213:526 214:527 215:528 216:529 217:530 218:531 219:532 220:533 221:534 222:534 223:534 224:534 225:535 226:535 227:536 228:537 229:538 230:539 231:540 232:541 233:542 234:543 235:544 236:544 237:545 238:546 239:547 240:548 241:548 242:549 243:550 244:550 245:551 246:552 247:553 248:554 249:555 250:556 251:557 252:558 253:559 254:560 255:561 256:562 257:563 258:563 259:563 260:564 261:565 262:566 263:567 264:568 265:569 266:570 267:571 268:572 269:572 270:573 271:574 272:575 273:576 274:577 275:578 276:579 277:580 278:580 279:581 280:582 281:583 282:584 283:585 284:586 285:587 286:588 287:589 288:590 289:591 290:592 291:593 292:594 293:595 294:596 295:596 296:597 297:598 298:599 299:600 300:600 301:601 302:602 303:603 304:604 305:605 306:606 307:607 308:608 309:609 310:610 311:611 312:612 313:613 314:614 315:615 316:615 317:616 318:617 319:618 320:619 321:620 322:621 323:622 324:623 325:624 326:625 327:625 328:625 329:626 330:627 331:628 332:628 333:629 334:630 335:631 336:631 337:632 338:633 339:634 340:635 341:636 342:637 343:638 344:639 345:640 346:641 347:642 348:643 349:644 350:645 351:646 352:647 353:648 354:649 355:650 356:650 357:651 358:652 359:652 360:653 361:654 362:655 363:656 364:656 365:656 366:657 367:657 368:657 369:657 370:658 371:658 372:659 373:660 374:661 375:662 376:663 377:664 378:665 379:665 380:666 381:666 382:666\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.355381 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 102\n",
            "I0703 18:12:00.451463 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.451879 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.452178 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.462224 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000005\n",
            "I0703 18:12:00.462545 139789930788736 set_essential_params.py:432] unique_id: 1000000005\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.462681 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 5\n",
            "I0703 18:12:00.462788 139789930788736 set_essential_params.py:434] doc_span_index: 5\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal [SEP]\n",
            "I0703 18:12:00.463120 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:473 11:473 12:473 13:473 14:474 15:475 16:476 17:477 18:478 19:479 20:480 21:481 22:482 23:483 24:484 25:485 26:486 27:486 28:487 29:488 30:489 31:490 32:491 33:492 34:493 35:494 36:495 37:495 38:496 39:497 40:498 41:499 42:500 43:501 44:502 45:503 46:504 47:505 48:506 49:507 50:508 51:509 52:509 53:509 54:510 55:511 56:512 57:513 58:514 59:514 60:514 61:515 62:516 63:517 64:517 65:518 66:519 67:519 68:519 69:519 70:520 71:520 72:521 73:522 74:522 75:523 76:524 77:524 78:525 79:525 80:525 81:525 82:525 83:525 84:525 85:526 86:527 87:528 88:529 89:530 90:531 91:532 92:533 93:534 94:534 95:534 96:534 97:535 98:535 99:536 100:537 101:538 102:539 103:540 104:541 105:542 106:543 107:544 108:544 109:545 110:546 111:547 112:548 113:548 114:549 115:550 116:550 117:551 118:552 119:553 120:554 121:555 122:556 123:557 124:558 125:559 126:560 127:561 128:562 129:563 130:563 131:563 132:564 133:565 134:566 135:567 136:568 137:569 138:570 139:571 140:572 141:572 142:573 143:574 144:575 145:576 146:577 147:578 148:579 149:580 150:580 151:581 152:582 153:583 154:584 155:585 156:586 157:587 158:588 159:589 160:590 161:591 162:592 163:593 164:594 165:595 166:596 167:596 168:597 169:598 170:599 171:600 172:600 173:601 174:602 175:603 176:604 177:605 178:606 179:607 180:608 181:609 182:610 183:611 184:612 185:613 186:614 187:615 188:615 189:616 190:617 191:618 192:619 193:620 194:621 195:622 196:623 197:624 198:625 199:625 200:625 201:626 202:627 203:628 204:628 205:629 206:630 207:631 208:631 209:632 210:633 211:634 212:635 213:636 214:637 215:638 216:639 217:640 218:641 219:642 220:643 221:644 222:645 223:646 224:647 225:648 226:649 227:650 228:650 229:651 230:652 231:652 232:653 233:654 234:655 235:656 236:656 237:656 238:657 239:657 240:657 241:657 242:658 243:658 244:659 245:660 246:661 247:662 248:663 249:664 250:665 251:665 252:666 253:666 254:666 255:667 256:667 257:667 258:668 259:668 260:668 261:669 262:670 263:671 264:672 265:673 266:674 267:675 268:676 269:677 270:678 271:679 272:680 273:681 274:682 275:683 276:684 277:685 278:685 279:686 280:687 281:688 282:689 283:689 284:690 285:691 286:692 287:693 288:694 289:695 290:696 291:697 292:698 293:699 294:700 295:701 296:701 297:702 298:703 299:704 300:705 301:706 302:707 303:707 304:708 305:709 306:709 307:709 308:709 309:710 310:711 311:712 312:713 313:713 314:714 315:714 316:715 317:716 318:717 319:718 320:719 321:720 322:721 323:722 324:723 325:724 326:724 327:725 328:725 329:726 330:727 331:728 332:729 333:730 334:730 335:731 336:732 337:733 338:734 339:735 340:735 341:736 342:737 343:737 344:737 345:738 346:738 347:739 348:740 349:741 350:741 351:742 352:743 353:744 354:745 355:746 356:747 357:748 358:748 359:749 360:749 361:749 362:750 363:751 364:752 365:753 366:753 367:754 368:755 369:755 370:756 371:757 372:757 373:758 374:759 375:759 376:759 377:760 378:761 379:761 380:762 381:763 382:764\n",
            "I0703 18:12:00.463485 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:473 11:473 12:473 13:473 14:474 15:475 16:476 17:477 18:478 19:479 20:480 21:481 22:482 23:483 24:484 25:485 26:486 27:486 28:487 29:488 30:489 31:490 32:491 33:492 34:493 35:494 36:495 37:495 38:496 39:497 40:498 41:499 42:500 43:501 44:502 45:503 46:504 47:505 48:506 49:507 50:508 51:509 52:509 53:509 54:510 55:511 56:512 57:513 58:514 59:514 60:514 61:515 62:516 63:517 64:517 65:518 66:519 67:519 68:519 69:519 70:520 71:520 72:521 73:522 74:522 75:523 76:524 77:524 78:525 79:525 80:525 81:525 82:525 83:525 84:525 85:526 86:527 87:528 88:529 89:530 90:531 91:532 92:533 93:534 94:534 95:534 96:534 97:535 98:535 99:536 100:537 101:538 102:539 103:540 104:541 105:542 106:543 107:544 108:544 109:545 110:546 111:547 112:548 113:548 114:549 115:550 116:550 117:551 118:552 119:553 120:554 121:555 122:556 123:557 124:558 125:559 126:560 127:561 128:562 129:563 130:563 131:563 132:564 133:565 134:566 135:567 136:568 137:569 138:570 139:571 140:572 141:572 142:573 143:574 144:575 145:576 146:577 147:578 148:579 149:580 150:580 151:581 152:582 153:583 154:584 155:585 156:586 157:587 158:588 159:589 160:590 161:591 162:592 163:593 164:594 165:595 166:596 167:596 168:597 169:598 170:599 171:600 172:600 173:601 174:602 175:603 176:604 177:605 178:606 179:607 180:608 181:609 182:610 183:611 184:612 185:613 186:614 187:615 188:615 189:616 190:617 191:618 192:619 193:620 194:621 195:622 196:623 197:624 198:625 199:625 200:625 201:626 202:627 203:628 204:628 205:629 206:630 207:631 208:631 209:632 210:633 211:634 212:635 213:636 214:637 215:638 216:639 217:640 218:641 219:642 220:643 221:644 222:645 223:646 224:647 225:648 226:649 227:650 228:650 229:651 230:652 231:652 232:653 233:654 234:655 235:656 236:656 237:656 238:657 239:657 240:657 241:657 242:658 243:658 244:659 245:660 246:661 247:662 248:663 249:664 250:665 251:665 252:666 253:666 254:666 255:667 256:667 257:667 258:668 259:668 260:668 261:669 262:670 263:671 264:672 265:673 266:674 267:675 268:676 269:677 270:678 271:679 272:680 273:681 274:682 275:683 276:684 277:685 278:685 279:686 280:687 281:688 282:689 283:689 284:690 285:691 286:692 287:693 288:694 289:695 290:696 291:697 292:698 293:699 294:700 295:701 296:701 297:702 298:703 299:704 300:705 301:706 302:707 303:707 304:708 305:709 306:709 307:709 308:709 309:710 310:711 311:712 312:713 313:713 314:714 315:714 316:715 317:716 318:717 319:718 320:719 321:720 322:721 323:722 324:723 325:724 326:724 327:725 328:725 329:726 330:727 331:728 332:729 333:730 334:730 335:731 336:732 337:733 338:734 339:735 340:735 341:736 342:737 343:737 344:737 345:738 346:738 347:739 348:740 349:741 350:741 351:742 352:743 353:744 354:745 355:746 356:747 357:748 358:748 359:749 360:749 361:749 362:750 363:751 364:752 365:753 366:753 367:754 368:755 369:755 370:756 371:757 372:757 373:758 374:759 375:759 376:759 377:760 378:761 379:761 380:762 381:763 382:764\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.463808 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 102\n",
            "I0703 18:12:00.553912 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.555087 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.556167 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.560603 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000006\n",
            "I0703 18:12:00.560804 139789930788736 set_essential_params.py:432] unique_id: 1000000006\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.560906 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 6\n",
            "I0703 18:12:00.561002 139789930788736 set_essential_params.py:434] doc_span_index: 6\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens [SEP]\n",
            "I0703 18:12:00.561222 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:570 11:571 12:572 13:572 14:573 15:574 16:575 17:576 18:577 19:578 20:579 21:580 22:580 23:581 24:582 25:583 26:584 27:585 28:586 29:587 30:588 31:589 32:590 33:591 34:592 35:593 36:594 37:595 38:596 39:596 40:597 41:598 42:599 43:600 44:600 45:601 46:602 47:603 48:604 49:605 50:606 51:607 52:608 53:609 54:610 55:611 56:612 57:613 58:614 59:615 60:615 61:616 62:617 63:618 64:619 65:620 66:621 67:622 68:623 69:624 70:625 71:625 72:625 73:626 74:627 75:628 76:628 77:629 78:630 79:631 80:631 81:632 82:633 83:634 84:635 85:636 86:637 87:638 88:639 89:640 90:641 91:642 92:643 93:644 94:645 95:646 96:647 97:648 98:649 99:650 100:650 101:651 102:652 103:652 104:653 105:654 106:655 107:656 108:656 109:656 110:657 111:657 112:657 113:657 114:658 115:658 116:659 117:660 118:661 119:662 120:663 121:664 122:665 123:665 124:666 125:666 126:666 127:667 128:667 129:667 130:668 131:668 132:668 133:669 134:670 135:671 136:672 137:673 138:674 139:675 140:676 141:677 142:678 143:679 144:680 145:681 146:682 147:683 148:684 149:685 150:685 151:686 152:687 153:688 154:689 155:689 156:690 157:691 158:692 159:693 160:694 161:695 162:696 163:697 164:698 165:699 166:700 167:701 168:701 169:702 170:703 171:704 172:705 173:706 174:707 175:707 176:708 177:709 178:709 179:709 180:709 181:710 182:711 183:712 184:713 185:713 186:714 187:714 188:715 189:716 190:717 191:718 192:719 193:720 194:721 195:722 196:723 197:724 198:724 199:725 200:725 201:726 202:727 203:728 204:729 205:730 206:730 207:731 208:732 209:733 210:734 211:735 212:735 213:736 214:737 215:737 216:737 217:738 218:738 219:739 220:740 221:741 222:741 223:742 224:743 225:744 226:745 227:746 228:747 229:748 230:748 231:749 232:749 233:749 234:750 235:751 236:752 237:753 238:753 239:754 240:755 241:755 242:756 243:757 244:757 245:758 246:759 247:759 248:759 249:760 250:761 251:761 252:762 253:763 254:764 255:764 256:765 257:765 258:765 259:765 260:765 261:766 262:767 263:768 264:768 265:768 266:769 267:769 268:769 269:769 270:769 271:769 272:769 273:769 274:770 275:770 276:770 277:770 278:771 279:772 280:773 281:773 282:774 283:775 284:775 285:775 286:775 287:775 288:775 289:775 290:776 291:776 292:776 293:776 294:777 295:778 296:779 297:779 298:780 299:781 300:782 301:783 302:784 303:784 304:785 305:786 306:786 307:787 308:788 309:789 310:789 311:790 312:791 313:792 314:792 315:793 316:794 317:794 318:795 319:796 320:797 321:798 322:798 323:799 324:800 325:801 326:802 327:803 328:804 329:805 330:806 331:807 332:808 333:809 334:810 335:811 336:812 337:812 338:813 339:814 340:814 341:815 342:816 343:816 344:816 345:817 346:818 347:819 348:820 349:821 350:822 351:823 352:824 353:824 354:825 355:826 356:826 357:827 358:828 359:829 360:829 361:830 362:831 363:832 364:833 365:834 366:835 367:836 368:837 369:837 370:837 371:837 372:838 373:838 374:838 375:838 376:838 377:839 378:840 379:841 380:841 381:842 382:843\n",
            "I0703 18:12:00.561594 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:570 11:571 12:572 13:572 14:573 15:574 16:575 17:576 18:577 19:578 20:579 21:580 22:580 23:581 24:582 25:583 26:584 27:585 28:586 29:587 30:588 31:589 32:590 33:591 34:592 35:593 36:594 37:595 38:596 39:596 40:597 41:598 42:599 43:600 44:600 45:601 46:602 47:603 48:604 49:605 50:606 51:607 52:608 53:609 54:610 55:611 56:612 57:613 58:614 59:615 60:615 61:616 62:617 63:618 64:619 65:620 66:621 67:622 68:623 69:624 70:625 71:625 72:625 73:626 74:627 75:628 76:628 77:629 78:630 79:631 80:631 81:632 82:633 83:634 84:635 85:636 86:637 87:638 88:639 89:640 90:641 91:642 92:643 93:644 94:645 95:646 96:647 97:648 98:649 99:650 100:650 101:651 102:652 103:652 104:653 105:654 106:655 107:656 108:656 109:656 110:657 111:657 112:657 113:657 114:658 115:658 116:659 117:660 118:661 119:662 120:663 121:664 122:665 123:665 124:666 125:666 126:666 127:667 128:667 129:667 130:668 131:668 132:668 133:669 134:670 135:671 136:672 137:673 138:674 139:675 140:676 141:677 142:678 143:679 144:680 145:681 146:682 147:683 148:684 149:685 150:685 151:686 152:687 153:688 154:689 155:689 156:690 157:691 158:692 159:693 160:694 161:695 162:696 163:697 164:698 165:699 166:700 167:701 168:701 169:702 170:703 171:704 172:705 173:706 174:707 175:707 176:708 177:709 178:709 179:709 180:709 181:710 182:711 183:712 184:713 185:713 186:714 187:714 188:715 189:716 190:717 191:718 192:719 193:720 194:721 195:722 196:723 197:724 198:724 199:725 200:725 201:726 202:727 203:728 204:729 205:730 206:730 207:731 208:732 209:733 210:734 211:735 212:735 213:736 214:737 215:737 216:737 217:738 218:738 219:739 220:740 221:741 222:741 223:742 224:743 225:744 226:745 227:746 228:747 229:748 230:748 231:749 232:749 233:749 234:750 235:751 236:752 237:753 238:753 239:754 240:755 241:755 242:756 243:757 244:757 245:758 246:759 247:759 248:759 249:760 250:761 251:761 252:762 253:763 254:764 255:764 256:765 257:765 258:765 259:765 260:765 261:766 262:767 263:768 264:768 265:768 266:769 267:769 268:769 269:769 270:769 271:769 272:769 273:769 274:770 275:770 276:770 277:770 278:771 279:772 280:773 281:773 282:774 283:775 284:775 285:775 286:775 287:775 288:775 289:775 290:776 291:776 292:776 293:776 294:777 295:778 296:779 297:779 298:780 299:781 300:782 301:783 302:784 303:784 304:785 305:786 306:786 307:787 308:788 309:789 310:789 311:790 312:791 313:792 314:792 315:793 316:794 317:794 318:795 319:796 320:797 321:798 322:798 323:799 324:800 325:801 326:802 327:803 328:804 329:805 330:806 331:807 332:808 333:809 334:810 335:811 336:812 337:812 338:813 339:814 340:814 341:815 342:816 343:816 344:816 345:817 346:818 347:819 348:820 349:821 350:822 351:823 352:824 353:824 354:825 355:826 356:826 357:827 358:828 359:829 360:829 361:830 362:831 363:832 364:833 365:834 366:835 367:836 368:837 369:837 370:837 371:837 372:838 373:838 374:838 375:838 376:838 377:839 378:840 379:841 380:841 381:842 382:843\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.561939 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 102\n",
            "I0703 18:12:00.661306 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.661724 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.661978 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.667064 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000007\n",
            "I0703 18:12:00.667290 139789930788736 set_essential_params.py:432] unique_id: 1000000007\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.667377 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 7\n",
            "I0703 18:12:00.667475 139789930788736 set_essential_params.py:434] doc_span_index: 7\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 [SEP]\n",
            "I0703 18:12:00.667765 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:674 11:675 12:676 13:677 14:678 15:679 16:680 17:681 18:682 19:683 20:684 21:685 22:685 23:686 24:687 25:688 26:689 27:689 28:690 29:691 30:692 31:693 32:694 33:695 34:696 35:697 36:698 37:699 38:700 39:701 40:701 41:702 42:703 43:704 44:705 45:706 46:707 47:707 48:708 49:709 50:709 51:709 52:709 53:710 54:711 55:712 56:713 57:713 58:714 59:714 60:715 61:716 62:717 63:718 64:719 65:720 66:721 67:722 68:723 69:724 70:724 71:725 72:725 73:726 74:727 75:728 76:729 77:730 78:730 79:731 80:732 81:733 82:734 83:735 84:735 85:736 86:737 87:737 88:737 89:738 90:738 91:739 92:740 93:741 94:741 95:742 96:743 97:744 98:745 99:746 100:747 101:748 102:748 103:749 104:749 105:749 106:750 107:751 108:752 109:753 110:753 111:754 112:755 113:755 114:756 115:757 116:757 117:758 118:759 119:759 120:759 121:760 122:761 123:761 124:762 125:763 126:764 127:764 128:765 129:765 130:765 131:765 132:765 133:766 134:767 135:768 136:768 137:768 138:769 139:769 140:769 141:769 142:769 143:769 144:769 145:769 146:770 147:770 148:770 149:770 150:771 151:772 152:773 153:773 154:774 155:775 156:775 157:775 158:775 159:775 160:775 161:775 162:776 163:776 164:776 165:776 166:777 167:778 168:779 169:779 170:780 171:781 172:782 173:783 174:784 175:784 176:785 177:786 178:786 179:787 180:788 181:789 182:789 183:790 184:791 185:792 186:792 187:793 188:794 189:794 190:795 191:796 192:797 193:798 194:798 195:799 196:800 197:801 198:802 199:803 200:804 201:805 202:806 203:807 204:808 205:809 206:810 207:811 208:812 209:812 210:813 211:814 212:814 213:815 214:816 215:816 216:816 217:817 218:818 219:819 220:820 221:821 222:822 223:823 224:824 225:824 226:825 227:826 228:826 229:827 230:828 231:829 232:829 233:830 234:831 235:832 236:833 237:834 238:835 239:836 240:837 241:837 242:837 243:837 244:838 245:838 246:838 247:838 248:838 249:839 250:840 251:841 252:841 253:842 254:843 255:844 256:845 257:846 258:847 259:847 260:847 261:847 262:848 263:849 264:850 265:851 266:852 267:852 268:852 269:853 270:854 271:854 272:854 273:854 274:855 275:856 276:856 277:857 278:858 279:859 280:860 281:860 282:860 283:860 284:861 285:862 286:863 287:864 288:865 289:866 290:867 291:867 292:868 293:869 294:870 295:871 296:872 297:873 298:874 299:875 300:876 301:877 302:878 303:879 304:879 305:880 306:881 307:882 308:882 309:883 310:884 311:884 312:884 313:884 314:885 315:885 316:886 317:887 318:888 319:889 320:890 321:890 322:891 323:892 324:893 325:894 326:895 327:896 328:897 329:897 330:898 331:899 332:900 333:901 334:902 335:903 336:904 337:905 338:906 339:907 340:907 341:907 342:907 343:908 344:909 345:910 346:911 347:912 348:913 349:914 350:914 351:915 352:916 353:916 354:917 355:918 356:919 357:920 358:920 359:920 360:920 361:921 362:922 363:923 364:924 365:924 366:925 367:926 368:927 369:928 370:929 371:929 372:929 373:929 374:930 375:930 376:930 377:931 378:931 379:931 380:932 381:932 382:932\n",
            "I0703 18:12:00.668154 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:674 11:675 12:676 13:677 14:678 15:679 16:680 17:681 18:682 19:683 20:684 21:685 22:685 23:686 24:687 25:688 26:689 27:689 28:690 29:691 30:692 31:693 32:694 33:695 34:696 35:697 36:698 37:699 38:700 39:701 40:701 41:702 42:703 43:704 44:705 45:706 46:707 47:707 48:708 49:709 50:709 51:709 52:709 53:710 54:711 55:712 56:713 57:713 58:714 59:714 60:715 61:716 62:717 63:718 64:719 65:720 66:721 67:722 68:723 69:724 70:724 71:725 72:725 73:726 74:727 75:728 76:729 77:730 78:730 79:731 80:732 81:733 82:734 83:735 84:735 85:736 86:737 87:737 88:737 89:738 90:738 91:739 92:740 93:741 94:741 95:742 96:743 97:744 98:745 99:746 100:747 101:748 102:748 103:749 104:749 105:749 106:750 107:751 108:752 109:753 110:753 111:754 112:755 113:755 114:756 115:757 116:757 117:758 118:759 119:759 120:759 121:760 122:761 123:761 124:762 125:763 126:764 127:764 128:765 129:765 130:765 131:765 132:765 133:766 134:767 135:768 136:768 137:768 138:769 139:769 140:769 141:769 142:769 143:769 144:769 145:769 146:770 147:770 148:770 149:770 150:771 151:772 152:773 153:773 154:774 155:775 156:775 157:775 158:775 159:775 160:775 161:775 162:776 163:776 164:776 165:776 166:777 167:778 168:779 169:779 170:780 171:781 172:782 173:783 174:784 175:784 176:785 177:786 178:786 179:787 180:788 181:789 182:789 183:790 184:791 185:792 186:792 187:793 188:794 189:794 190:795 191:796 192:797 193:798 194:798 195:799 196:800 197:801 198:802 199:803 200:804 201:805 202:806 203:807 204:808 205:809 206:810 207:811 208:812 209:812 210:813 211:814 212:814 213:815 214:816 215:816 216:816 217:817 218:818 219:819 220:820 221:821 222:822 223:823 224:824 225:824 226:825 227:826 228:826 229:827 230:828 231:829 232:829 233:830 234:831 235:832 236:833 237:834 238:835 239:836 240:837 241:837 242:837 243:837 244:838 245:838 246:838 247:838 248:838 249:839 250:840 251:841 252:841 253:842 254:843 255:844 256:845 257:846 258:847 259:847 260:847 261:847 262:848 263:849 264:850 265:851 266:852 267:852 268:852 269:853 270:854 271:854 272:854 273:854 274:855 275:856 276:856 277:857 278:858 279:859 280:860 281:860 282:860 283:860 284:861 285:862 286:863 287:864 288:865 289:866 290:867 291:867 292:868 293:869 294:870 295:871 296:872 297:873 298:874 299:875 300:876 301:877 302:878 303:879 304:879 305:880 306:881 307:882 308:882 309:883 310:884 311:884 312:884 313:884 314:885 315:885 316:886 317:887 318:888 319:889 320:890 321:890 322:891 323:892 324:893 325:894 326:895 327:896 328:897 329:897 330:898 331:899 332:900 333:901 334:902 335:903 336:904 337:905 338:906 339:907 340:907 341:907 342:907 343:908 344:909 345:910 346:911 347:912 348:913 349:914 350:914 351:915 352:916 353:916 354:917 355:918 356:919 357:920 358:920 359:920 360:920 361:921 362:922 363:923 364:924 365:924 366:925 367:926 368:927 369:928 370:929 371:929 372:929 373:929 374:930 375:930 376:930 377:931 378:931 379:931 380:932 381:932 382:932\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.761838 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 102\n",
            "I0703 18:12:00.762106 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.865456 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.865838 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:00.871313 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000008\n",
            "I0703 18:12:00.871550 139789930788736 set_essential_params.py:432] unique_id: 1000000008\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:00.871646 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 8\n",
            "I0703 18:12:00.871728 139789930788736 set_essential_params.py:434] doc_span_index: 8\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta [SEP]\n",
            "I0703 18:12:00.872010 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:769 11:769 12:769 13:769 14:769 15:769 16:769 17:769 18:770 19:770 20:770 21:770 22:771 23:772 24:773 25:773 26:774 27:775 28:775 29:775 30:775 31:775 32:775 33:775 34:776 35:776 36:776 37:776 38:777 39:778 40:779 41:779 42:780 43:781 44:782 45:783 46:784 47:784 48:785 49:786 50:786 51:787 52:788 53:789 54:789 55:790 56:791 57:792 58:792 59:793 60:794 61:794 62:795 63:796 64:797 65:798 66:798 67:799 68:800 69:801 70:802 71:803 72:804 73:805 74:806 75:807 76:808 77:809 78:810 79:811 80:812 81:812 82:813 83:814 84:814 85:815 86:816 87:816 88:816 89:817 90:818 91:819 92:820 93:821 94:822 95:823 96:824 97:824 98:825 99:826 100:826 101:827 102:828 103:829 104:829 105:830 106:831 107:832 108:833 109:834 110:835 111:836 112:837 113:837 114:837 115:837 116:838 117:838 118:838 119:838 120:838 121:839 122:840 123:841 124:841 125:842 126:843 127:844 128:845 129:846 130:847 131:847 132:847 133:847 134:848 135:849 136:850 137:851 138:852 139:852 140:852 141:853 142:854 143:854 144:854 145:854 146:855 147:856 148:856 149:857 150:858 151:859 152:860 153:860 154:860 155:860 156:861 157:862 158:863 159:864 160:865 161:866 162:867 163:867 164:868 165:869 166:870 167:871 168:872 169:873 170:874 171:875 172:876 173:877 174:878 175:879 176:879 177:880 178:881 179:882 180:882 181:883 182:884 183:884 184:884 185:884 186:885 187:885 188:886 189:887 190:888 191:889 192:890 193:890 194:891 195:892 196:893 197:894 198:895 199:896 200:897 201:897 202:898 203:899 204:900 205:901 206:902 207:903 208:904 209:905 210:906 211:907 212:907 213:907 214:907 215:908 216:909 217:910 218:911 219:912 220:913 221:914 222:914 223:915 224:916 225:916 226:917 227:918 228:919 229:920 230:920 231:920 232:920 233:921 234:922 235:923 236:924 237:924 238:925 239:926 240:927 241:928 242:929 243:929 244:929 245:929 246:930 247:930 248:930 249:931 250:931 251:931 252:932 253:932 254:932 255:933 256:933 257:933 258:933 259:933 260:933 261:934 262:935 263:936 264:937 265:937 266:938 267:939 268:940 269:941 270:942 271:943 272:943 273:943 274:944 275:944 276:945 277:946 278:947 279:947 280:948 281:949 282:950 283:951 284:952 285:953 286:954 287:954 288:955 289:955 290:956 291:957 292:958 293:959 294:960 295:961 296:962 297:963 298:964 299:965 300:966 301:967 302:968 303:968 304:968 305:969 306:970 307:970 308:971 309:971 310:971 311:971 312:971 313:971 314:972 315:973 316:973 317:974 318:975 319:976 320:976 321:976 322:976 323:976 324:977 325:978 326:979 327:980 328:981 329:982 330:982 331:982 332:982 333:983 334:983 335:984 336:984 337:985 338:986 339:987 340:988 341:989 342:989 343:990 344:991 345:992 346:993 347:994 348:994 349:995 350:996 351:997 352:998 353:998 354:999 355:1000 356:1000 357:1001 358:1002 359:1002 360:1002 361:1002 362:1003 363:1003 364:1004 365:1004 366:1005 367:1006 368:1007 369:1008 370:1009 371:1010 372:1010 373:1011 374:1012 375:1012 376:1013 377:1014 378:1015 379:1016 380:1017 381:1017 382:1017\n",
            "I0703 18:12:00.872341 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:769 11:769 12:769 13:769 14:769 15:769 16:769 17:769 18:770 19:770 20:770 21:770 22:771 23:772 24:773 25:773 26:774 27:775 28:775 29:775 30:775 31:775 32:775 33:775 34:776 35:776 36:776 37:776 38:777 39:778 40:779 41:779 42:780 43:781 44:782 45:783 46:784 47:784 48:785 49:786 50:786 51:787 52:788 53:789 54:789 55:790 56:791 57:792 58:792 59:793 60:794 61:794 62:795 63:796 64:797 65:798 66:798 67:799 68:800 69:801 70:802 71:803 72:804 73:805 74:806 75:807 76:808 77:809 78:810 79:811 80:812 81:812 82:813 83:814 84:814 85:815 86:816 87:816 88:816 89:817 90:818 91:819 92:820 93:821 94:822 95:823 96:824 97:824 98:825 99:826 100:826 101:827 102:828 103:829 104:829 105:830 106:831 107:832 108:833 109:834 110:835 111:836 112:837 113:837 114:837 115:837 116:838 117:838 118:838 119:838 120:838 121:839 122:840 123:841 124:841 125:842 126:843 127:844 128:845 129:846 130:847 131:847 132:847 133:847 134:848 135:849 136:850 137:851 138:852 139:852 140:852 141:853 142:854 143:854 144:854 145:854 146:855 147:856 148:856 149:857 150:858 151:859 152:860 153:860 154:860 155:860 156:861 157:862 158:863 159:864 160:865 161:866 162:867 163:867 164:868 165:869 166:870 167:871 168:872 169:873 170:874 171:875 172:876 173:877 174:878 175:879 176:879 177:880 178:881 179:882 180:882 181:883 182:884 183:884 184:884 185:884 186:885 187:885 188:886 189:887 190:888 191:889 192:890 193:890 194:891 195:892 196:893 197:894 198:895 199:896 200:897 201:897 202:898 203:899 204:900 205:901 206:902 207:903 208:904 209:905 210:906 211:907 212:907 213:907 214:907 215:908 216:909 217:910 218:911 219:912 220:913 221:914 222:914 223:915 224:916 225:916 226:917 227:918 228:919 229:920 230:920 231:920 232:920 233:921 234:922 235:923 236:924 237:924 238:925 239:926 240:927 241:928 242:929 243:929 244:929 245:929 246:930 247:930 248:930 249:931 250:931 251:931 252:932 253:932 254:932 255:933 256:933 257:933 258:933 259:933 260:933 261:934 262:935 263:936 264:937 265:937 266:938 267:939 268:940 269:941 270:942 271:943 272:943 273:943 274:944 275:944 276:945 277:946 278:947 279:947 280:948 281:949 282:950 283:951 284:952 285:953 286:954 287:954 288:955 289:955 290:956 291:957 292:958 293:959 294:960 295:961 296:962 297:963 298:964 299:965 300:966 301:967 302:968 303:968 304:968 305:969 306:970 307:970 308:971 309:971 310:971 311:971 312:971 313:971 314:972 315:973 316:973 317:974 318:975 319:976 320:976 321:976 322:976 323:976 324:977 325:978 326:979 327:980 328:981 329:982 330:982 331:982 332:982 333:983 334:983 335:984 336:984 337:985 338:986 339:987 340:988 341:989 342:989 343:990 344:991 345:992 346:993 347:994 348:994 349:995 350:996 351:997 352:998 353:998 354:999 355:1000 356:1000 357:1001 358:1002 359:1002 360:1002 361:1002 362:1003 363:1003 364:1004 365:1004 366:1005 367:1006 368:1007 369:1008 370:1009 371:1010 372:1010 373:1011 374:1012 375:1012 376:1013 377:1014 378:1015 379:1016 380:1017 381:1017 382:1017\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:00.965725 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 102\n",
            "I0703 18:12:00.966099 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.966305 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:00.966516 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.074469 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000009\n",
            "I0703 18:12:01.074733 139789930788736 set_essential_params.py:432] unique_id: 1000000009\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:01.074823 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 9\n",
            "I0703 18:12:01.074897 139789930788736 set_essential_params.py:434] doc_span_index: 9\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol [SEP]\n",
            "I0703 18:12:01.075136 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:852 11:852 12:852 13:853 14:854 15:854 16:854 17:854 18:855 19:856 20:856 21:857 22:858 23:859 24:860 25:860 26:860 27:860 28:861 29:862 30:863 31:864 32:865 33:866 34:867 35:867 36:868 37:869 38:870 39:871 40:872 41:873 42:874 43:875 44:876 45:877 46:878 47:879 48:879 49:880 50:881 51:882 52:882 53:883 54:884 55:884 56:884 57:884 58:885 59:885 60:886 61:887 62:888 63:889 64:890 65:890 66:891 67:892 68:893 69:894 70:895 71:896 72:897 73:897 74:898 75:899 76:900 77:901 78:902 79:903 80:904 81:905 82:906 83:907 84:907 85:907 86:907 87:908 88:909 89:910 90:911 91:912 92:913 93:914 94:914 95:915 96:916 97:916 98:917 99:918 100:919 101:920 102:920 103:920 104:920 105:921 106:922 107:923 108:924 109:924 110:925 111:926 112:927 113:928 114:929 115:929 116:929 117:929 118:930 119:930 120:930 121:931 122:931 123:931 124:932 125:932 126:932 127:933 128:933 129:933 130:933 131:933 132:933 133:934 134:935 135:936 136:937 137:937 138:938 139:939 140:940 141:941 142:942 143:943 144:943 145:943 146:944 147:944 148:945 149:946 150:947 151:947 152:948 153:949 154:950 155:951 156:952 157:953 158:954 159:954 160:955 161:955 162:956 163:957 164:958 165:959 166:960 167:961 168:962 169:963 170:964 171:965 172:966 173:967 174:968 175:968 176:968 177:969 178:970 179:970 180:971 181:971 182:971 183:971 184:971 185:971 186:972 187:973 188:973 189:974 190:975 191:976 192:976 193:976 194:976 195:976 196:977 197:978 198:979 199:980 200:981 201:982 202:982 203:982 204:982 205:983 206:983 207:984 208:984 209:985 210:986 211:987 212:988 213:989 214:989 215:990 216:991 217:992 218:993 219:994 220:994 221:995 222:996 223:997 224:998 225:998 226:999 227:1000 228:1000 229:1001 230:1002 231:1002 232:1002 233:1002 234:1003 235:1003 236:1004 237:1004 238:1005 239:1006 240:1007 241:1008 242:1009 243:1010 244:1010 245:1011 246:1012 247:1012 248:1013 249:1014 250:1015 251:1016 252:1017 253:1017 254:1017 255:1017 256:1018 257:1018 258:1019 259:1020 260:1021 261:1022 262:1023 263:1024 264:1024 265:1025 266:1026 267:1027 268:1028 269:1028 270:1029 271:1029 272:1030 273:1031 274:1032 275:1033 276:1034 277:1034 278:1034 279:1035 280:1036 281:1036 282:1037 283:1038 284:1039 285:1039 286:1040 287:1041 288:1042 289:1043 290:1044 291:1045 292:1046 293:1046 294:1047 295:1047 296:1047 297:1047 298:1048 299:1048 300:1049 301:1050 302:1051 303:1052 304:1053 305:1054 306:1054 307:1055 308:1056 309:1057 310:1057 311:1058 312:1059 313:1060 314:1061 315:1062 316:1063 317:1064 318:1065 319:1066 320:1066 321:1067 322:1067 323:1068 324:1069 325:1070 326:1071 327:1071 328:1072 329:1072 330:1073 331:1074 332:1075 333:1076 334:1077 335:1078 336:1079 337:1080 338:1080 339:1081 340:1081 341:1081 342:1082 343:1083 344:1084 345:1085 346:1086 347:1087 348:1088 349:1089 350:1090 351:1090 352:1091 353:1091 354:1092 355:1093 356:1093 357:1094 358:1095 359:1096 360:1097 361:1097 362:1097 363:1098 364:1099 365:1100 366:1100 367:1101 368:1101 369:1102 370:1103 371:1104 372:1105 373:1105 374:1106 375:1107 376:1108 377:1108 378:1108 379:1109 380:1110 381:1111 382:1111\n",
            "I0703 18:12:01.075457 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:852 11:852 12:852 13:853 14:854 15:854 16:854 17:854 18:855 19:856 20:856 21:857 22:858 23:859 24:860 25:860 26:860 27:860 28:861 29:862 30:863 31:864 32:865 33:866 34:867 35:867 36:868 37:869 38:870 39:871 40:872 41:873 42:874 43:875 44:876 45:877 46:878 47:879 48:879 49:880 50:881 51:882 52:882 53:883 54:884 55:884 56:884 57:884 58:885 59:885 60:886 61:887 62:888 63:889 64:890 65:890 66:891 67:892 68:893 69:894 70:895 71:896 72:897 73:897 74:898 75:899 76:900 77:901 78:902 79:903 80:904 81:905 82:906 83:907 84:907 85:907 86:907 87:908 88:909 89:910 90:911 91:912 92:913 93:914 94:914 95:915 96:916 97:916 98:917 99:918 100:919 101:920 102:920 103:920 104:920 105:921 106:922 107:923 108:924 109:924 110:925 111:926 112:927 113:928 114:929 115:929 116:929 117:929 118:930 119:930 120:930 121:931 122:931 123:931 124:932 125:932 126:932 127:933 128:933 129:933 130:933 131:933 132:933 133:934 134:935 135:936 136:937 137:937 138:938 139:939 140:940 141:941 142:942 143:943 144:943 145:943 146:944 147:944 148:945 149:946 150:947 151:947 152:948 153:949 154:950 155:951 156:952 157:953 158:954 159:954 160:955 161:955 162:956 163:957 164:958 165:959 166:960 167:961 168:962 169:963 170:964 171:965 172:966 173:967 174:968 175:968 176:968 177:969 178:970 179:970 180:971 181:971 182:971 183:971 184:971 185:971 186:972 187:973 188:973 189:974 190:975 191:976 192:976 193:976 194:976 195:976 196:977 197:978 198:979 199:980 200:981 201:982 202:982 203:982 204:982 205:983 206:983 207:984 208:984 209:985 210:986 211:987 212:988 213:989 214:989 215:990 216:991 217:992 218:993 219:994 220:994 221:995 222:996 223:997 224:998 225:998 226:999 227:1000 228:1000 229:1001 230:1002 231:1002 232:1002 233:1002 234:1003 235:1003 236:1004 237:1004 238:1005 239:1006 240:1007 241:1008 242:1009 243:1010 244:1010 245:1011 246:1012 247:1012 248:1013 249:1014 250:1015 251:1016 252:1017 253:1017 254:1017 255:1017 256:1018 257:1018 258:1019 259:1020 260:1021 261:1022 262:1023 263:1024 264:1024 265:1025 266:1026 267:1027 268:1028 269:1028 270:1029 271:1029 272:1030 273:1031 274:1032 275:1033 276:1034 277:1034 278:1034 279:1035 280:1036 281:1036 282:1037 283:1038 284:1039 285:1039 286:1040 287:1041 288:1042 289:1043 290:1044 291:1045 292:1046 293:1046 294:1047 295:1047 296:1047 297:1047 298:1048 299:1048 300:1049 301:1050 302:1051 303:1052 304:1053 305:1054 306:1054 307:1055 308:1056 309:1057 310:1057 311:1058 312:1059 313:1060 314:1061 315:1062 316:1063 317:1064 318:1065 319:1066 320:1066 321:1067 322:1067 323:1068 324:1069 325:1070 326:1071 327:1071 328:1072 329:1072 330:1073 331:1074 332:1075 333:1076 334:1077 335:1078 336:1079 337:1080 338:1080 339:1081 340:1081 341:1081 342:1082 343:1083 344:1084 345:1085 346:1086 347:1087 348:1088 349:1089 350:1090 351:1090 352:1091 353:1091 354:1092 355:1093 356:1093 357:1094 358:1095 359:1096 360:1097 361:1097 362:1097 363:1098 364:1099 365:1100 366:1100 367:1101 368:1101 369:1102 370:1103 371:1104 372:1105 373:1105 374:1106 375:1107 376:1108 377:1108 378:1108 379:1109 380:1110 381:1111 382:1111\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:01.075721 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 102\n",
            "I0703 18:12:01.169641 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.169856 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.169993 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.172938 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000010\n",
            "I0703 18:12:01.173110 139789930788736 set_essential_params.py:432] unique_id: 1000000010\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:01.173172 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 10\n",
            "I0703 18:12:01.173226 139789930788736 set_essential_params.py:434] doc_span_index: 10\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens [SEP]\n",
            "I0703 18:12:01.173388 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:938 11:939 12:940 13:941 14:942 15:943 16:943 17:943 18:944 19:944 20:945 21:946 22:947 23:947 24:948 25:949 26:950 27:951 28:952 29:953 30:954 31:954 32:955 33:955 34:956 35:957 36:958 37:959 38:960 39:961 40:962 41:963 42:964 43:965 44:966 45:967 46:968 47:968 48:968 49:969 50:970 51:970 52:971 53:971 54:971 55:971 56:971 57:971 58:972 59:973 60:973 61:974 62:975 63:976 64:976 65:976 66:976 67:976 68:977 69:978 70:979 71:980 72:981 73:982 74:982 75:982 76:982 77:983 78:983 79:984 80:984 81:985 82:986 83:987 84:988 85:989 86:989 87:990 88:991 89:992 90:993 91:994 92:994 93:995 94:996 95:997 96:998 97:998 98:999 99:1000 100:1000 101:1001 102:1002 103:1002 104:1002 105:1002 106:1003 107:1003 108:1004 109:1004 110:1005 111:1006 112:1007 113:1008 114:1009 115:1010 116:1010 117:1011 118:1012 119:1012 120:1013 121:1014 122:1015 123:1016 124:1017 125:1017 126:1017 127:1017 128:1018 129:1018 130:1019 131:1020 132:1021 133:1022 134:1023 135:1024 136:1024 137:1025 138:1026 139:1027 140:1028 141:1028 142:1029 143:1029 144:1030 145:1031 146:1032 147:1033 148:1034 149:1034 150:1034 151:1035 152:1036 153:1036 154:1037 155:1038 156:1039 157:1039 158:1040 159:1041 160:1042 161:1043 162:1044 163:1045 164:1046 165:1046 166:1047 167:1047 168:1047 169:1047 170:1048 171:1048 172:1049 173:1050 174:1051 175:1052 176:1053 177:1054 178:1054 179:1055 180:1056 181:1057 182:1057 183:1058 184:1059 185:1060 186:1061 187:1062 188:1063 189:1064 190:1065 191:1066 192:1066 193:1067 194:1067 195:1068 196:1069 197:1070 198:1071 199:1071 200:1072 201:1072 202:1073 203:1074 204:1075 205:1076 206:1077 207:1078 208:1079 209:1080 210:1080 211:1081 212:1081 213:1081 214:1082 215:1083 216:1084 217:1085 218:1086 219:1087 220:1088 221:1089 222:1090 223:1090 224:1091 225:1091 226:1092 227:1093 228:1093 229:1094 230:1095 231:1096 232:1097 233:1097 234:1097 235:1098 236:1099 237:1100 238:1100 239:1101 240:1101 241:1102 242:1103 243:1104 244:1105 245:1105 246:1106 247:1107 248:1108 249:1108 250:1108 251:1109 252:1110 253:1111 254:1111 255:1111 256:1112 257:1112 258:1113 259:1114 260:1115 261:1115 262:1116 263:1117 264:1118 265:1119 266:1120 267:1121 268:1122 269:1122 270:1123 271:1124 272:1124 273:1124 274:1124 275:1125 276:1126 277:1126 278:1126 279:1127 280:1128 281:1129 282:1130 283:1130 284:1130 285:1131 286:1132 287:1133 288:1134 289:1134 290:1134 291:1134 292:1135 293:1136 294:1137 295:1138 296:1139 297:1139 298:1140 299:1141 300:1141 301:1142 302:1143 303:1144 304:1145 305:1146 306:1147 307:1148 308:1149 309:1150 310:1151 311:1151 312:1151 313:1152 314:1153 315:1154 316:1155 317:1155 318:1155 319:1156 320:1157 321:1158 322:1159 323:1160 324:1160 325:1161 326:1161 327:1161 328:1161 329:1161 330:1162 331:1162 332:1163 333:1164 334:1165 335:1165 336:1166 337:1167 338:1168 339:1169 340:1170 341:1171 342:1172 343:1173 344:1174 345:1175 346:1175 347:1176 348:1177 349:1178 350:1178 351:1179 352:1180 353:1181 354:1182 355:1182 356:1182 357:1182 358:1183 359:1184 360:1185 361:1186 362:1187 363:1188 364:1189 365:1190 366:1191 367:1192 368:1193 369:1194 370:1195 371:1196 372:1197 373:1198 374:1199 375:1200 376:1201 377:1202 378:1202 379:1203 380:1204 381:1204 382:1205\n",
            "I0703 18:12:01.273383 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:938 11:939 12:940 13:941 14:942 15:943 16:943 17:943 18:944 19:944 20:945 21:946 22:947 23:947 24:948 25:949 26:950 27:951 28:952 29:953 30:954 31:954 32:955 33:955 34:956 35:957 36:958 37:959 38:960 39:961 40:962 41:963 42:964 43:965 44:966 45:967 46:968 47:968 48:968 49:969 50:970 51:970 52:971 53:971 54:971 55:971 56:971 57:971 58:972 59:973 60:973 61:974 62:975 63:976 64:976 65:976 66:976 67:976 68:977 69:978 70:979 71:980 72:981 73:982 74:982 75:982 76:982 77:983 78:983 79:984 80:984 81:985 82:986 83:987 84:988 85:989 86:989 87:990 88:991 89:992 90:993 91:994 92:994 93:995 94:996 95:997 96:998 97:998 98:999 99:1000 100:1000 101:1001 102:1002 103:1002 104:1002 105:1002 106:1003 107:1003 108:1004 109:1004 110:1005 111:1006 112:1007 113:1008 114:1009 115:1010 116:1010 117:1011 118:1012 119:1012 120:1013 121:1014 122:1015 123:1016 124:1017 125:1017 126:1017 127:1017 128:1018 129:1018 130:1019 131:1020 132:1021 133:1022 134:1023 135:1024 136:1024 137:1025 138:1026 139:1027 140:1028 141:1028 142:1029 143:1029 144:1030 145:1031 146:1032 147:1033 148:1034 149:1034 150:1034 151:1035 152:1036 153:1036 154:1037 155:1038 156:1039 157:1039 158:1040 159:1041 160:1042 161:1043 162:1044 163:1045 164:1046 165:1046 166:1047 167:1047 168:1047 169:1047 170:1048 171:1048 172:1049 173:1050 174:1051 175:1052 176:1053 177:1054 178:1054 179:1055 180:1056 181:1057 182:1057 183:1058 184:1059 185:1060 186:1061 187:1062 188:1063 189:1064 190:1065 191:1066 192:1066 193:1067 194:1067 195:1068 196:1069 197:1070 198:1071 199:1071 200:1072 201:1072 202:1073 203:1074 204:1075 205:1076 206:1077 207:1078 208:1079 209:1080 210:1080 211:1081 212:1081 213:1081 214:1082 215:1083 216:1084 217:1085 218:1086 219:1087 220:1088 221:1089 222:1090 223:1090 224:1091 225:1091 226:1092 227:1093 228:1093 229:1094 230:1095 231:1096 232:1097 233:1097 234:1097 235:1098 236:1099 237:1100 238:1100 239:1101 240:1101 241:1102 242:1103 243:1104 244:1105 245:1105 246:1106 247:1107 248:1108 249:1108 250:1108 251:1109 252:1110 253:1111 254:1111 255:1111 256:1112 257:1112 258:1113 259:1114 260:1115 261:1115 262:1116 263:1117 264:1118 265:1119 266:1120 267:1121 268:1122 269:1122 270:1123 271:1124 272:1124 273:1124 274:1124 275:1125 276:1126 277:1126 278:1126 279:1127 280:1128 281:1129 282:1130 283:1130 284:1130 285:1131 286:1132 287:1133 288:1134 289:1134 290:1134 291:1134 292:1135 293:1136 294:1137 295:1138 296:1139 297:1139 298:1140 299:1141 300:1141 301:1142 302:1143 303:1144 304:1145 305:1146 306:1147 307:1148 308:1149 309:1150 310:1151 311:1151 312:1151 313:1152 314:1153 315:1154 316:1155 317:1155 318:1155 319:1156 320:1157 321:1158 322:1159 323:1160 324:1160 325:1161 326:1161 327:1161 328:1161 329:1161 330:1162 331:1162 332:1163 333:1164 334:1165 335:1165 336:1166 337:1167 338:1168 339:1169 340:1170 341:1171 342:1172 343:1173 344:1174 345:1175 346:1175 347:1176 348:1177 349:1178 350:1178 351:1179 352:1180 353:1181 354:1182 355:1182 356:1182 357:1182 358:1183 359:1184 360:1185 361:1186 362:1187 363:1188 364:1189 365:1190 366:1191 367:1192 368:1193 369:1194 370:1195 371:1196 372:1197 373:1198 374:1199 375:1200 376:1201 377:1202 378:1202 379:1203 380:1204 381:1204 382:1205\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:01.273862 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 102\n",
            "I0703 18:12:01.274257 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.373223 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.374855 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.377928 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000011\n",
            "I0703 18:12:01.378087 139789930788736 set_essential_params.py:432] unique_id: 1000000011\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:01.378182 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 11\n",
            "I0703 18:12:01.378268 139789930788736 set_essential_params.py:434] doc_span_index: 11\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology [SEP]\n",
            "I0703 18:12:01.378498 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:1026 11:1027 12:1028 13:1028 14:1029 15:1029 16:1030 17:1031 18:1032 19:1033 20:1034 21:1034 22:1034 23:1035 24:1036 25:1036 26:1037 27:1038 28:1039 29:1039 30:1040 31:1041 32:1042 33:1043 34:1044 35:1045 36:1046 37:1046 38:1047 39:1047 40:1047 41:1047 42:1048 43:1048 44:1049 45:1050 46:1051 47:1052 48:1053 49:1054 50:1054 51:1055 52:1056 53:1057 54:1057 55:1058 56:1059 57:1060 58:1061 59:1062 60:1063 61:1064 62:1065 63:1066 64:1066 65:1067 66:1067 67:1068 68:1069 69:1070 70:1071 71:1071 72:1072 73:1072 74:1073 75:1074 76:1075 77:1076 78:1077 79:1078 80:1079 81:1080 82:1080 83:1081 84:1081 85:1081 86:1082 87:1083 88:1084 89:1085 90:1086 91:1087 92:1088 93:1089 94:1090 95:1090 96:1091 97:1091 98:1092 99:1093 100:1093 101:1094 102:1095 103:1096 104:1097 105:1097 106:1097 107:1098 108:1099 109:1100 110:1100 111:1101 112:1101 113:1102 114:1103 115:1104 116:1105 117:1105 118:1106 119:1107 120:1108 121:1108 122:1108 123:1109 124:1110 125:1111 126:1111 127:1111 128:1112 129:1112 130:1113 131:1114 132:1115 133:1115 134:1116 135:1117 136:1118 137:1119 138:1120 139:1121 140:1122 141:1122 142:1123 143:1124 144:1124 145:1124 146:1124 147:1125 148:1126 149:1126 150:1126 151:1127 152:1128 153:1129 154:1130 155:1130 156:1130 157:1131 158:1132 159:1133 160:1134 161:1134 162:1134 163:1134 164:1135 165:1136 166:1137 167:1138 168:1139 169:1139 170:1140 171:1141 172:1141 173:1142 174:1143 175:1144 176:1145 177:1146 178:1147 179:1148 180:1149 181:1150 182:1151 183:1151 184:1151 185:1152 186:1153 187:1154 188:1155 189:1155 190:1155 191:1156 192:1157 193:1158 194:1159 195:1160 196:1160 197:1161 198:1161 199:1161 200:1161 201:1161 202:1162 203:1162 204:1163 205:1164 206:1165 207:1165 208:1166 209:1167 210:1168 211:1169 212:1170 213:1171 214:1172 215:1173 216:1174 217:1175 218:1175 219:1176 220:1177 221:1178 222:1178 223:1179 224:1180 225:1181 226:1182 227:1182 228:1182 229:1182 230:1183 231:1184 232:1185 233:1186 234:1187 235:1188 236:1189 237:1190 238:1191 239:1192 240:1193 241:1194 242:1195 243:1196 244:1197 245:1198 246:1199 247:1200 248:1201 249:1202 250:1202 251:1203 252:1204 253:1204 254:1205 255:1206 256:1207 257:1207 258:1207 259:1208 260:1209 261:1210 262:1211 263:1212 264:1213 265:1213 266:1213 267:1213 268:1214 269:1215 270:1216 271:1217 272:1218 273:1219 274:1220 275:1221 276:1222 277:1223 278:1224 279:1225 280:1226 281:1227 282:1228 283:1229 284:1230 285:1231 286:1231 287:1232 288:1233 289:1233 290:1234 291:1234 292:1235 293:1236 294:1237 295:1238 296:1239 297:1240 298:1241 299:1242 300:1243 301:1244 302:1245 303:1245 304:1245 305:1246 306:1246 307:1247 308:1248 309:1248 310:1248 311:1248 312:1249 313:1250 314:1251 315:1252 316:1253 317:1254 318:1255 319:1256 320:1257 321:1257 322:1258 323:1259 324:1259 325:1259 326:1259 327:1260 328:1261 329:1262 330:1263 331:1263 332:1264 333:1264 334:1265 335:1265 336:1265 337:1266 338:1267 339:1268 340:1268 341:1269 342:1270 343:1271 344:1272 345:1272 346:1273 347:1274 348:1275 349:1276 350:1277 351:1277 352:1277 353:1277 354:1278 355:1278 356:1279 357:1280 358:1281 359:1282 360:1282 361:1283 362:1284 363:1284 364:1285 365:1285 366:1285 367:1285 368:1286 369:1287 370:1288 371:1289 372:1290 373:1290 374:1291 375:1292 376:1293 377:1293 378:1294 379:1295 380:1296 381:1297 382:1298\n",
            "I0703 18:12:01.378745 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:1026 11:1027 12:1028 13:1028 14:1029 15:1029 16:1030 17:1031 18:1032 19:1033 20:1034 21:1034 22:1034 23:1035 24:1036 25:1036 26:1037 27:1038 28:1039 29:1039 30:1040 31:1041 32:1042 33:1043 34:1044 35:1045 36:1046 37:1046 38:1047 39:1047 40:1047 41:1047 42:1048 43:1048 44:1049 45:1050 46:1051 47:1052 48:1053 49:1054 50:1054 51:1055 52:1056 53:1057 54:1057 55:1058 56:1059 57:1060 58:1061 59:1062 60:1063 61:1064 62:1065 63:1066 64:1066 65:1067 66:1067 67:1068 68:1069 69:1070 70:1071 71:1071 72:1072 73:1072 74:1073 75:1074 76:1075 77:1076 78:1077 79:1078 80:1079 81:1080 82:1080 83:1081 84:1081 85:1081 86:1082 87:1083 88:1084 89:1085 90:1086 91:1087 92:1088 93:1089 94:1090 95:1090 96:1091 97:1091 98:1092 99:1093 100:1093 101:1094 102:1095 103:1096 104:1097 105:1097 106:1097 107:1098 108:1099 109:1100 110:1100 111:1101 112:1101 113:1102 114:1103 115:1104 116:1105 117:1105 118:1106 119:1107 120:1108 121:1108 122:1108 123:1109 124:1110 125:1111 126:1111 127:1111 128:1112 129:1112 130:1113 131:1114 132:1115 133:1115 134:1116 135:1117 136:1118 137:1119 138:1120 139:1121 140:1122 141:1122 142:1123 143:1124 144:1124 145:1124 146:1124 147:1125 148:1126 149:1126 150:1126 151:1127 152:1128 153:1129 154:1130 155:1130 156:1130 157:1131 158:1132 159:1133 160:1134 161:1134 162:1134 163:1134 164:1135 165:1136 166:1137 167:1138 168:1139 169:1139 170:1140 171:1141 172:1141 173:1142 174:1143 175:1144 176:1145 177:1146 178:1147 179:1148 180:1149 181:1150 182:1151 183:1151 184:1151 185:1152 186:1153 187:1154 188:1155 189:1155 190:1155 191:1156 192:1157 193:1158 194:1159 195:1160 196:1160 197:1161 198:1161 199:1161 200:1161 201:1161 202:1162 203:1162 204:1163 205:1164 206:1165 207:1165 208:1166 209:1167 210:1168 211:1169 212:1170 213:1171 214:1172 215:1173 216:1174 217:1175 218:1175 219:1176 220:1177 221:1178 222:1178 223:1179 224:1180 225:1181 226:1182 227:1182 228:1182 229:1182 230:1183 231:1184 232:1185 233:1186 234:1187 235:1188 236:1189 237:1190 238:1191 239:1192 240:1193 241:1194 242:1195 243:1196 244:1197 245:1198 246:1199 247:1200 248:1201 249:1202 250:1202 251:1203 252:1204 253:1204 254:1205 255:1206 256:1207 257:1207 258:1207 259:1208 260:1209 261:1210 262:1211 263:1212 264:1213 265:1213 266:1213 267:1213 268:1214 269:1215 270:1216 271:1217 272:1218 273:1219 274:1220 275:1221 276:1222 277:1223 278:1224 279:1225 280:1226 281:1227 282:1228 283:1229 284:1230 285:1231 286:1231 287:1232 288:1233 289:1233 290:1234 291:1234 292:1235 293:1236 294:1237 295:1238 296:1239 297:1240 298:1241 299:1242 300:1243 301:1244 302:1245 303:1245 304:1245 305:1246 306:1246 307:1247 308:1248 309:1248 310:1248 311:1248 312:1249 313:1250 314:1251 315:1252 316:1253 317:1254 318:1255 319:1256 320:1257 321:1257 322:1258 323:1259 324:1259 325:1259 326:1259 327:1260 328:1261 329:1262 330:1263 331:1263 332:1264 333:1264 334:1265 335:1265 336:1265 337:1266 338:1267 339:1268 340:1268 341:1269 342:1270 343:1271 344:1272 345:1272 346:1273 347:1274 348:1275 349:1276 350:1277 351:1277 352:1277 353:1277 354:1278 355:1278 356:1279 357:1280 358:1281 359:1282 360:1282 361:1283 362:1284 363:1284 364:1285 365:1285 366:1285 367:1285 368:1286 369:1287 370:1288 371:1289 372:1290 373:1290 374:1291 375:1292 376:1293 377:1293 378:1294 379:1295 380:1296 381:1297 382:1298\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:01.378988 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 102\n",
            "I0703 18:12:01.480242 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.480905 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.481460 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.486883 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000012\n",
            "I0703 18:12:01.487619 139789930788736 set_essential_params.py:432] unique_id: 1000000012\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:01.488851 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 12\n",
            "I0703 18:12:01.489039 139789930788736 set_essential_params.py:434] doc_span_index: 12\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by [SEP]\n",
            "I0703 18:12:01.489475 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:1120 11:1121 12:1122 13:1122 14:1123 15:1124 16:1124 17:1124 18:1124 19:1125 20:1126 21:1126 22:1126 23:1127 24:1128 25:1129 26:1130 27:1130 28:1130 29:1131 30:1132 31:1133 32:1134 33:1134 34:1134 35:1134 36:1135 37:1136 38:1137 39:1138 40:1139 41:1139 42:1140 43:1141 44:1141 45:1142 46:1143 47:1144 48:1145 49:1146 50:1147 51:1148 52:1149 53:1150 54:1151 55:1151 56:1151 57:1152 58:1153 59:1154 60:1155 61:1155 62:1155 63:1156 64:1157 65:1158 66:1159 67:1160 68:1160 69:1161 70:1161 71:1161 72:1161 73:1161 74:1162 75:1162 76:1163 77:1164 78:1165 79:1165 80:1166 81:1167 82:1168 83:1169 84:1170 85:1171 86:1172 87:1173 88:1174 89:1175 90:1175 91:1176 92:1177 93:1178 94:1178 95:1179 96:1180 97:1181 98:1182 99:1182 100:1182 101:1182 102:1183 103:1184 104:1185 105:1186 106:1187 107:1188 108:1189 109:1190 110:1191 111:1192 112:1193 113:1194 114:1195 115:1196 116:1197 117:1198 118:1199 119:1200 120:1201 121:1202 122:1202 123:1203 124:1204 125:1204 126:1205 127:1206 128:1207 129:1207 130:1207 131:1208 132:1209 133:1210 134:1211 135:1212 136:1213 137:1213 138:1213 139:1213 140:1214 141:1215 142:1216 143:1217 144:1218 145:1219 146:1220 147:1221 148:1222 149:1223 150:1224 151:1225 152:1226 153:1227 154:1228 155:1229 156:1230 157:1231 158:1231 159:1232 160:1233 161:1233 162:1234 163:1234 164:1235 165:1236 166:1237 167:1238 168:1239 169:1240 170:1241 171:1242 172:1243 173:1244 174:1245 175:1245 176:1245 177:1246 178:1246 179:1247 180:1248 181:1248 182:1248 183:1248 184:1249 185:1250 186:1251 187:1252 188:1253 189:1254 190:1255 191:1256 192:1257 193:1257 194:1258 195:1259 196:1259 197:1259 198:1259 199:1260 200:1261 201:1262 202:1263 203:1263 204:1264 205:1264 206:1265 207:1265 208:1265 209:1266 210:1267 211:1268 212:1268 213:1269 214:1270 215:1271 216:1272 217:1272 218:1273 219:1274 220:1275 221:1276 222:1277 223:1277 224:1277 225:1277 226:1278 227:1278 228:1279 229:1280 230:1281 231:1282 232:1282 233:1283 234:1284 235:1284 236:1285 237:1285 238:1285 239:1285 240:1286 241:1287 242:1288 243:1289 244:1290 245:1290 246:1291 247:1292 248:1293 249:1293 250:1294 251:1295 252:1296 253:1297 254:1298 255:1299 256:1300 257:1301 258:1301 259:1302 260:1302 261:1302 262:1303 263:1304 264:1304 265:1305 266:1306 267:1307 268:1308 269:1309 270:1310 271:1311 272:1312 273:1313 274:1313 275:1314 276:1315 277:1316 278:1316 279:1317 280:1318 281:1319 282:1320 283:1321 284:1322 285:1323 286:1323 287:1324 288:1325 289:1326 290:1326 291:1327 292:1327 293:1327 294:1327 295:1327 296:1327 297:1328 298:1329 299:1330 300:1331 301:1331 302:1332 303:1333 304:1334 305:1335 306:1335 307:1336 308:1337 309:1338 310:1339 311:1340 312:1340 313:1341 314:1342 315:1343 316:1344 317:1344 318:1345 319:1345 320:1346 321:1346 322:1346 323:1347 324:1347 325:1348 326:1349 327:1350 328:1351 329:1352 330:1353 331:1354 332:1355 333:1355 334:1356 335:1357 336:1357 337:1358 338:1358 339:1359 340:1359 341:1359 342:1360 343:1360 344:1361 345:1362 346:1363 347:1364 348:1365 349:1366 350:1367 351:1368 352:1369 353:1370 354:1370 355:1371 356:1371 357:1372 358:1372 359:1372 360:1373 361:1373 362:1374 363:1374 364:1374 365:1375 366:1376 367:1377 368:1378 369:1379 370:1380 371:1381 372:1382 373:1383 374:1383 375:1384 376:1385 377:1386 378:1387 379:1388 380:1389 381:1390 382:1391\n",
            "I0703 18:12:01.490019 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:1120 11:1121 12:1122 13:1122 14:1123 15:1124 16:1124 17:1124 18:1124 19:1125 20:1126 21:1126 22:1126 23:1127 24:1128 25:1129 26:1130 27:1130 28:1130 29:1131 30:1132 31:1133 32:1134 33:1134 34:1134 35:1134 36:1135 37:1136 38:1137 39:1138 40:1139 41:1139 42:1140 43:1141 44:1141 45:1142 46:1143 47:1144 48:1145 49:1146 50:1147 51:1148 52:1149 53:1150 54:1151 55:1151 56:1151 57:1152 58:1153 59:1154 60:1155 61:1155 62:1155 63:1156 64:1157 65:1158 66:1159 67:1160 68:1160 69:1161 70:1161 71:1161 72:1161 73:1161 74:1162 75:1162 76:1163 77:1164 78:1165 79:1165 80:1166 81:1167 82:1168 83:1169 84:1170 85:1171 86:1172 87:1173 88:1174 89:1175 90:1175 91:1176 92:1177 93:1178 94:1178 95:1179 96:1180 97:1181 98:1182 99:1182 100:1182 101:1182 102:1183 103:1184 104:1185 105:1186 106:1187 107:1188 108:1189 109:1190 110:1191 111:1192 112:1193 113:1194 114:1195 115:1196 116:1197 117:1198 118:1199 119:1200 120:1201 121:1202 122:1202 123:1203 124:1204 125:1204 126:1205 127:1206 128:1207 129:1207 130:1207 131:1208 132:1209 133:1210 134:1211 135:1212 136:1213 137:1213 138:1213 139:1213 140:1214 141:1215 142:1216 143:1217 144:1218 145:1219 146:1220 147:1221 148:1222 149:1223 150:1224 151:1225 152:1226 153:1227 154:1228 155:1229 156:1230 157:1231 158:1231 159:1232 160:1233 161:1233 162:1234 163:1234 164:1235 165:1236 166:1237 167:1238 168:1239 169:1240 170:1241 171:1242 172:1243 173:1244 174:1245 175:1245 176:1245 177:1246 178:1246 179:1247 180:1248 181:1248 182:1248 183:1248 184:1249 185:1250 186:1251 187:1252 188:1253 189:1254 190:1255 191:1256 192:1257 193:1257 194:1258 195:1259 196:1259 197:1259 198:1259 199:1260 200:1261 201:1262 202:1263 203:1263 204:1264 205:1264 206:1265 207:1265 208:1265 209:1266 210:1267 211:1268 212:1268 213:1269 214:1270 215:1271 216:1272 217:1272 218:1273 219:1274 220:1275 221:1276 222:1277 223:1277 224:1277 225:1277 226:1278 227:1278 228:1279 229:1280 230:1281 231:1282 232:1282 233:1283 234:1284 235:1284 236:1285 237:1285 238:1285 239:1285 240:1286 241:1287 242:1288 243:1289 244:1290 245:1290 246:1291 247:1292 248:1293 249:1293 250:1294 251:1295 252:1296 253:1297 254:1298 255:1299 256:1300 257:1301 258:1301 259:1302 260:1302 261:1302 262:1303 263:1304 264:1304 265:1305 266:1306 267:1307 268:1308 269:1309 270:1310 271:1311 272:1312 273:1313 274:1313 275:1314 276:1315 277:1316 278:1316 279:1317 280:1318 281:1319 282:1320 283:1321 284:1322 285:1323 286:1323 287:1324 288:1325 289:1326 290:1326 291:1327 292:1327 293:1327 294:1327 295:1327 296:1327 297:1328 298:1329 299:1330 300:1331 301:1331 302:1332 303:1333 304:1334 305:1335 306:1335 307:1336 308:1337 309:1338 310:1339 311:1340 312:1340 313:1341 314:1342 315:1343 316:1344 317:1344 318:1345 319:1345 320:1346 321:1346 322:1346 323:1347 324:1347 325:1348 326:1349 327:1350 328:1351 329:1352 330:1353 331:1354 332:1355 333:1355 334:1356 335:1357 336:1357 337:1358 338:1358 339:1359 340:1359 341:1359 342:1360 343:1360 344:1361 345:1362 346:1363 347:1364 348:1365 349:1366 350:1367 351:1368 352:1369 353:1370 354:1370 355:1371 356:1371 357:1372 358:1372 359:1372 360:1373 361:1373 362:1374 363:1374 364:1374 365:1375 366:1376 367:1377 368:1378 369:1379 370:1380 371:1381 372:1382 373:1383 374:1383 375:1384 376:1385 377:1386 378:1387 379:1388 380:1389 381:1390 382:1391\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:01.490478 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 102\n",
            "I0703 18:12:01.583207 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.583684 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.583993 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.586993 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000013\n",
            "I0703 18:12:01.587160 139789930788736 set_essential_params.py:432] unique_id: 1000000013\n",
            "INFO:tensorflow:example_index: 0\n",
            "I0703 18:12:01.587256 139789930788736 set_essential_params.py:433] example_index: 0\n",
            "INFO:tensorflow:doc_span_index: 13\n",
            "I0703 18:12:01.587343 139789930788736 set_essential_params.py:434] doc_span_index: 13\n",
            "INFO:tensorflow:tokens: [CLS] who is the current ceo of siemens ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "I0703 18:12:01.587539 139789930788736 set_essential_params.py:436] tokens: [CLS] who is the current ceo of siemens ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 10:1213 11:1213 12:1214 13:1215 14:1216 15:1217 16:1218 17:1219 18:1220 19:1221 20:1222 21:1223 22:1224 23:1225 24:1226 25:1227 26:1228 27:1229 28:1230 29:1231 30:1231 31:1232 32:1233 33:1233 34:1234 35:1234 36:1235 37:1236 38:1237 39:1238 40:1239 41:1240 42:1241 43:1242 44:1243 45:1244 46:1245 47:1245 48:1245 49:1246 50:1246 51:1247 52:1248 53:1248 54:1248 55:1248 56:1249 57:1250 58:1251 59:1252 60:1253 61:1254 62:1255 63:1256 64:1257 65:1257 66:1258 67:1259 68:1259 69:1259 70:1259 71:1260 72:1261 73:1262 74:1263 75:1263 76:1264 77:1264 78:1265 79:1265 80:1265 81:1266 82:1267 83:1268 84:1268 85:1269 86:1270 87:1271 88:1272 89:1272 90:1273 91:1274 92:1275 93:1276 94:1277 95:1277 96:1277 97:1277 98:1278 99:1278 100:1279 101:1280 102:1281 103:1282 104:1282 105:1283 106:1284 107:1284 108:1285 109:1285 110:1285 111:1285 112:1286 113:1287 114:1288 115:1289 116:1290 117:1290 118:1291 119:1292 120:1293 121:1293 122:1294 123:1295 124:1296 125:1297 126:1298 127:1299 128:1300 129:1301 130:1301 131:1302 132:1302 133:1302 134:1303 135:1304 136:1304 137:1305 138:1306 139:1307 140:1308 141:1309 142:1310 143:1311 144:1312 145:1313 146:1313 147:1314 148:1315 149:1316 150:1316 151:1317 152:1318 153:1319 154:1320 155:1321 156:1322 157:1323 158:1323 159:1324 160:1325 161:1326 162:1326 163:1327 164:1327 165:1327 166:1327 167:1327 168:1327 169:1328 170:1329 171:1330 172:1331 173:1331 174:1332 175:1333 176:1334 177:1335 178:1335 179:1336 180:1337 181:1338 182:1339 183:1340 184:1340 185:1341 186:1342 187:1343 188:1344 189:1344 190:1345 191:1345 192:1346 193:1346 194:1346 195:1347 196:1347 197:1348 198:1349 199:1350 200:1351 201:1352 202:1353 203:1354 204:1355 205:1355 206:1356 207:1357 208:1357 209:1358 210:1358 211:1359 212:1359 213:1359 214:1360 215:1360 216:1361 217:1362 218:1363 219:1364 220:1365 221:1366 222:1367 223:1368 224:1369 225:1370 226:1370 227:1371 228:1371 229:1372 230:1372 231:1372 232:1373 233:1373 234:1374 235:1374 236:1374 237:1375 238:1376 239:1377 240:1378 241:1379 242:1380 243:1381 244:1382 245:1383 246:1383 247:1384 248:1385 249:1386 250:1387 251:1388 252:1389 253:1390 254:1391 255:1392 256:1393 257:1394 258:1395 259:1396 260:1397 261:1398 262:1398 263:1399 264:1399 265:1400 266:1401 267:1402 268:1402 269:1403 270:1404 271:1405 272:1405 273:1406 274:1407 275:1408 276:1409 277:1410 278:1411 279:1412 280:1413 281:1414 282:1414 283:1415 284:1415\n",
            "I0703 18:12:01.587855 139789930788736 set_essential_params.py:438] token_to_orig_map: 10:1213 11:1213 12:1214 13:1215 14:1216 15:1217 16:1218 17:1219 18:1220 19:1221 20:1222 21:1223 22:1224 23:1225 24:1226 25:1227 26:1228 27:1229 28:1230 29:1231 30:1231 31:1232 32:1233 33:1233 34:1234 35:1234 36:1235 37:1236 38:1237 39:1238 40:1239 41:1240 42:1241 43:1242 44:1243 45:1244 46:1245 47:1245 48:1245 49:1246 50:1246 51:1247 52:1248 53:1248 54:1248 55:1248 56:1249 57:1250 58:1251 59:1252 60:1253 61:1254 62:1255 63:1256 64:1257 65:1257 66:1258 67:1259 68:1259 69:1259 70:1259 71:1260 72:1261 73:1262 74:1263 75:1263 76:1264 77:1264 78:1265 79:1265 80:1265 81:1266 82:1267 83:1268 84:1268 85:1269 86:1270 87:1271 88:1272 89:1272 90:1273 91:1274 92:1275 93:1276 94:1277 95:1277 96:1277 97:1277 98:1278 99:1278 100:1279 101:1280 102:1281 103:1282 104:1282 105:1283 106:1284 107:1284 108:1285 109:1285 110:1285 111:1285 112:1286 113:1287 114:1288 115:1289 116:1290 117:1290 118:1291 119:1292 120:1293 121:1293 122:1294 123:1295 124:1296 125:1297 126:1298 127:1299 128:1300 129:1301 130:1301 131:1302 132:1302 133:1302 134:1303 135:1304 136:1304 137:1305 138:1306 139:1307 140:1308 141:1309 142:1310 143:1311 144:1312 145:1313 146:1313 147:1314 148:1315 149:1316 150:1316 151:1317 152:1318 153:1319 154:1320 155:1321 156:1322 157:1323 158:1323 159:1324 160:1325 161:1326 162:1326 163:1327 164:1327 165:1327 166:1327 167:1327 168:1327 169:1328 170:1329 171:1330 172:1331 173:1331 174:1332 175:1333 176:1334 177:1335 178:1335 179:1336 180:1337 181:1338 182:1339 183:1340 184:1340 185:1341 186:1342 187:1343 188:1344 189:1344 190:1345 191:1345 192:1346 193:1346 194:1346 195:1347 196:1347 197:1348 198:1349 199:1350 200:1351 201:1352 202:1353 203:1354 204:1355 205:1355 206:1356 207:1357 208:1357 209:1358 210:1358 211:1359 212:1359 213:1359 214:1360 215:1360 216:1361 217:1362 218:1363 219:1364 220:1365 221:1366 222:1367 223:1368 224:1369 225:1370 226:1370 227:1371 228:1371 229:1372 230:1372 231:1372 232:1373 233:1373 234:1374 235:1374 236:1374 237:1375 238:1376 239:1377 240:1378 241:1379 242:1380 243:1381 244:1382 245:1383 246:1383 247:1384 248:1385 249:1386 250:1387 251:1388 252:1389 253:1390 254:1391 255:1392 256:1393 257:1394 258:1395 259:1396 260:1397 261:1398 262:1398 263:1399 264:1399 265:1400 266:1401 267:1402 268:1402 269:1403 270:1404 271:1405 272:1405 273:1406 274:1407 275:1408 276:1409 277:1410 278:1411 279:1412 280:1413 281:1414 282:1414 283:1415 284:1415\n",
            "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True\n",
            "I0703 18:12:01.588156 139789930788736 set_essential_params.py:440] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:01.685757 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2003 1996 2783 5766 1997 22108 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:01.686741 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:01.687630 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.726030 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000014\n",
            "I0703 18:12:01.726276 139789930788736 set_essential_params.py:432] unique_id: 1000000014\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:01.726343 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:12:01.726410 139789930788736 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons [SEP]\n",
            "I0703 18:12:01.726576 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:0 7:1 8:2 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:9 17:10 18:11 19:12 20:12 21:13 22:14 23:15 24:16 25:16 26:17 27:18 28:19 29:20 30:20 31:21 32:22 33:23 34:24 35:25 36:26 37:27 38:28 39:29 40:30 41:31 42:32 43:32 44:33 45:34 46:35 47:36 48:37 49:37 50:38 51:39 52:39 53:40 54:41 55:42 56:42 57:42 58:42 59:42 60:42 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:64 88:65 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:73 100:73 101:74 102:75 103:76 104:77 105:77 106:78 107:79 108:80 109:81 110:82 111:83 112:84 113:85 114:85 115:86 116:87 117:87 118:88 119:89 120:89 121:89 122:90 123:91 124:91 125:92 126:93 127:94 128:94 129:95 130:96 131:97 132:98 133:98 134:99 135:100 136:101 137:102 138:103 139:104 140:105 141:105 142:106 143:107 144:108 145:109 146:110 147:111 148:112 149:113 150:114 151:114 152:115 153:116 154:117 155:117 156:118 157:119 158:120 159:121 160:122 161:123 162:124 163:124 164:124 165:125 166:126 167:127 168:128 169:128 170:129 171:130 172:130 173:131 174:132 175:133 176:134 177:135 178:136 179:137 180:137 181:138 182:139 183:140 184:141 185:141 186:142 187:143 188:144 189:145 190:145 191:146 192:146 193:147 194:148 195:148 196:149 197:150 198:151 199:152 200:153 201:153 202:153 203:154 204:155 205:156 206:157 207:158 208:158 209:158 210:159 211:160 212:161 213:162 214:163 215:163 216:164 217:165 218:166 219:166 220:167 221:168 222:169 223:170 224:171 225:172 226:173 227:174 228:175 229:175 230:176 231:177 232:177 233:178 234:179 235:180 236:181 237:182 238:183 239:184 240:185 241:186 242:186 243:186 244:187 245:188 246:189 247:190 248:191 249:192 250:193 251:194 252:195 253:195 254:196 255:196 256:197 257:198 258:199 259:199 260:199 261:200 262:201 263:202 264:203 265:204 266:205 267:206 268:207 269:208 270:209 271:209 272:210 273:211 274:211 275:212 276:213 277:214 278:215 279:215 280:216 281:217 282:218 283:219 284:219 285:220 286:221 287:222 288:223 289:224 290:225 291:225 292:225 293:226 294:227 295:228 296:229 297:230 298:231 299:232 300:233 301:234 302:234 303:234 304:234 305:235 306:236 307:236 308:237 309:238 310:239 311:240 312:241 313:242 314:243 315:244 316:245 317:246 318:247 319:248 320:249 321:249 322:250 323:251 324:251 325:252 326:253 327:254 328:255 329:256 330:257 331:258 332:259 333:260 334:260 335:260 336:260 337:261 338:262 339:263 340:263 341:263 342:264 343:265 344:266 345:267 346:268 347:269 348:270 349:271 350:271 351:272 352:272 353:273 354:274 355:274 356:275 357:276 358:277 359:278 360:279 361:280 362:281 363:281 364:282 365:283 366:283 367:284 368:285 369:286 370:287 371:288 372:289 373:290 374:291 375:292 376:293 377:294 378:295 379:296 380:297 381:298 382:299\n",
            "I0703 18:12:01.726772 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:0 7:1 8:2 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:9 17:10 18:11 19:12 20:12 21:13 22:14 23:15 24:16 25:16 26:17 27:18 28:19 29:20 30:20 31:21 32:22 33:23 34:24 35:25 36:26 37:27 38:28 39:29 40:30 41:31 42:32 43:32 44:33 45:34 46:35 47:36 48:37 49:37 50:38 51:39 52:39 53:40 54:41 55:42 56:42 57:42 58:42 59:42 60:42 61:42 62:43 63:44 64:45 65:46 66:46 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:64 88:65 89:65 90:66 91:67 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:73 100:73 101:74 102:75 103:76 104:77 105:77 106:78 107:79 108:80 109:81 110:82 111:83 112:84 113:85 114:85 115:86 116:87 117:87 118:88 119:89 120:89 121:89 122:90 123:91 124:91 125:92 126:93 127:94 128:94 129:95 130:96 131:97 132:98 133:98 134:99 135:100 136:101 137:102 138:103 139:104 140:105 141:105 142:106 143:107 144:108 145:109 146:110 147:111 148:112 149:113 150:114 151:114 152:115 153:116 154:117 155:117 156:118 157:119 158:120 159:121 160:122 161:123 162:124 163:124 164:124 165:125 166:126 167:127 168:128 169:128 170:129 171:130 172:130 173:131 174:132 175:133 176:134 177:135 178:136 179:137 180:137 181:138 182:139 183:140 184:141 185:141 186:142 187:143 188:144 189:145 190:145 191:146 192:146 193:147 194:148 195:148 196:149 197:150 198:151 199:152 200:153 201:153 202:153 203:154 204:155 205:156 206:157 207:158 208:158 209:158 210:159 211:160 212:161 213:162 214:163 215:163 216:164 217:165 218:166 219:166 220:167 221:168 222:169 223:170 224:171 225:172 226:173 227:174 228:175 229:175 230:176 231:177 232:177 233:178 234:179 235:180 236:181 237:182 238:183 239:184 240:185 241:186 242:186 243:186 244:187 245:188 246:189 247:190 248:191 249:192 250:193 251:194 252:195 253:195 254:196 255:196 256:197 257:198 258:199 259:199 260:199 261:200 262:201 263:202 264:203 265:204 266:205 267:206 268:207 269:208 270:209 271:209 272:210 273:211 274:211 275:212 276:213 277:214 278:215 279:215 280:216 281:217 282:218 283:219 284:219 285:220 286:221 287:222 288:223 289:224 290:225 291:225 292:225 293:226 294:227 295:228 296:229 297:230 298:231 299:232 300:233 301:234 302:234 303:234 304:234 305:235 306:236 307:236 308:237 309:238 310:239 311:240 312:241 313:242 314:243 315:244 316:245 317:246 318:247 319:248 320:249 321:249 322:250 323:251 324:251 325:252 326:253 327:254 328:255 329:256 330:257 331:258 332:259 333:260 334:260 335:260 336:260 337:261 338:262 339:263 340:263 341:263 342:264 343:265 344:266 345:267 346:268 347:269 348:270 349:271 350:271 351:272 352:272 353:273 354:274 355:274 356:275 357:276 358:277 359:278 360:279 361:280 362:281 363:281 364:282 365:283 366:283 367:284 368:285 369:286 370:287 371:288 372:289 373:290 374:291 375:292 376:293 377:294 378:295 379:296 380:297 381:298 382:299\n",
            "INFO:tensorflow:token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:01.788771 139789930788736 set_essential_params.py:440] token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 102\n",
            "I0703 18:12:01.789277 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.891610 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.892090 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.897752 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000015\n",
            "I0703 18:12:01.897966 139789930788736 set_essential_params.py:432] unique_id: 1000000015\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:01.898056 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "I0703 18:12:01.898135 139789930788736 set_essential_params.py:434] doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s [SEP]\n",
            "I0703 18:12:01.898448 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:99 7:100 8:101 9:102 10:103 11:104 12:105 13:105 14:106 15:107 16:108 17:109 18:110 19:111 20:112 21:113 22:114 23:114 24:115 25:116 26:117 27:117 28:118 29:119 30:120 31:121 32:122 33:123 34:124 35:124 36:124 37:125 38:126 39:127 40:128 41:128 42:129 43:130 44:130 45:131 46:132 47:133 48:134 49:135 50:136 51:137 52:137 53:138 54:139 55:140 56:141 57:141 58:142 59:143 60:144 61:145 62:145 63:146 64:146 65:147 66:148 67:148 68:149 69:150 70:151 71:152 72:153 73:153 74:153 75:154 76:155 77:156 78:157 79:158 80:158 81:158 82:159 83:160 84:161 85:162 86:163 87:163 88:164 89:165 90:166 91:166 92:167 93:168 94:169 95:170 96:171 97:172 98:173 99:174 100:175 101:175 102:176 103:177 104:177 105:178 106:179 107:180 108:181 109:182 110:183 111:184 112:185 113:186 114:186 115:186 116:187 117:188 118:189 119:190 120:191 121:192 122:193 123:194 124:195 125:195 126:196 127:196 128:197 129:198 130:199 131:199 132:199 133:200 134:201 135:202 136:203 137:204 138:205 139:206 140:207 141:208 142:209 143:209 144:210 145:211 146:211 147:212 148:213 149:214 150:215 151:215 152:216 153:217 154:218 155:219 156:219 157:220 158:221 159:222 160:223 161:224 162:225 163:225 164:225 165:226 166:227 167:228 168:229 169:230 170:231 171:232 172:233 173:234 174:234 175:234 176:234 177:235 178:236 179:236 180:237 181:238 182:239 183:240 184:241 185:242 186:243 187:244 188:245 189:246 190:247 191:248 192:249 193:249 194:250 195:251 196:251 197:252 198:253 199:254 200:255 201:256 202:257 203:258 204:259 205:260 206:260 207:260 208:260 209:261 210:262 211:263 212:263 213:263 214:264 215:265 216:266 217:267 218:268 219:269 220:270 221:271 222:271 223:272 224:272 225:273 226:274 227:274 228:275 229:276 230:277 231:278 232:279 233:280 234:281 235:281 236:282 237:283 238:283 239:284 240:285 241:286 242:287 243:288 244:289 245:290 246:291 247:292 248:293 249:294 250:295 251:296 252:297 253:298 254:299 255:300 256:301 257:302 258:302 259:303 260:304 261:304 262:305 263:306 264:307 265:308 266:309 267:310 268:311 269:312 270:313 271:314 272:315 273:315 274:316 275:317 276:318 277:319 278:320 279:321 280:321 281:322 282:323 283:324 284:325 285:326 286:327 287:328 288:329 289:330 290:331 291:332 292:333 293:334 294:335 295:336 296:337 297:338 298:338 299:339 300:340 301:341 302:341 303:342 304:342 305:343 306:344 307:344 308:345 309:346 310:347 311:348 312:348 313:349 314:350 315:351 316:352 317:353 318:354 319:355 320:356 321:357 322:357 323:357 324:357 325:358 326:359 327:359 328:359 329:360 330:361 331:362 332:363 333:364 334:365 335:365 336:365 337:365 338:365 339:365 340:365 341:366 342:367 343:367 344:368 345:369 346:369 347:370 348:371 349:371 350:372 351:373 352:373 353:373 354:373 355:373 356:373 357:373 358:374 359:375 360:375 361:375 362:376 363:377 364:378 365:379 366:380 367:380 368:380 369:381 370:382 371:383 372:384 373:385 374:386 375:387 376:388 377:389 378:389 379:390 380:391 381:391 382:392\n",
            "I0703 18:12:01.898783 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:99 7:100 8:101 9:102 10:103 11:104 12:105 13:105 14:106 15:107 16:108 17:109 18:110 19:111 20:112 21:113 22:114 23:114 24:115 25:116 26:117 27:117 28:118 29:119 30:120 31:121 32:122 33:123 34:124 35:124 36:124 37:125 38:126 39:127 40:128 41:128 42:129 43:130 44:130 45:131 46:132 47:133 48:134 49:135 50:136 51:137 52:137 53:138 54:139 55:140 56:141 57:141 58:142 59:143 60:144 61:145 62:145 63:146 64:146 65:147 66:148 67:148 68:149 69:150 70:151 71:152 72:153 73:153 74:153 75:154 76:155 77:156 78:157 79:158 80:158 81:158 82:159 83:160 84:161 85:162 86:163 87:163 88:164 89:165 90:166 91:166 92:167 93:168 94:169 95:170 96:171 97:172 98:173 99:174 100:175 101:175 102:176 103:177 104:177 105:178 106:179 107:180 108:181 109:182 110:183 111:184 112:185 113:186 114:186 115:186 116:187 117:188 118:189 119:190 120:191 121:192 122:193 123:194 124:195 125:195 126:196 127:196 128:197 129:198 130:199 131:199 132:199 133:200 134:201 135:202 136:203 137:204 138:205 139:206 140:207 141:208 142:209 143:209 144:210 145:211 146:211 147:212 148:213 149:214 150:215 151:215 152:216 153:217 154:218 155:219 156:219 157:220 158:221 159:222 160:223 161:224 162:225 163:225 164:225 165:226 166:227 167:228 168:229 169:230 170:231 171:232 172:233 173:234 174:234 175:234 176:234 177:235 178:236 179:236 180:237 181:238 182:239 183:240 184:241 185:242 186:243 187:244 188:245 189:246 190:247 191:248 192:249 193:249 194:250 195:251 196:251 197:252 198:253 199:254 200:255 201:256 202:257 203:258 204:259 205:260 206:260 207:260 208:260 209:261 210:262 211:263 212:263 213:263 214:264 215:265 216:266 217:267 218:268 219:269 220:270 221:271 222:271 223:272 224:272 225:273 226:274 227:274 228:275 229:276 230:277 231:278 232:279 233:280 234:281 235:281 236:282 237:283 238:283 239:284 240:285 241:286 242:287 243:288 244:289 245:290 246:291 247:292 248:293 249:294 250:295 251:296 252:297 253:298 254:299 255:300 256:301 257:302 258:302 259:303 260:304 261:304 262:305 263:306 264:307 265:308 266:309 267:310 268:311 269:312 270:313 271:314 272:315 273:315 274:316 275:317 276:318 277:319 278:320 279:321 280:321 281:322 282:323 283:324 284:325 285:326 286:327 287:328 288:329 289:330 290:331 291:332 292:333 293:334 294:335 295:336 296:337 297:338 298:338 299:339 300:340 301:341 302:341 303:342 304:342 305:343 306:344 307:344 308:345 309:346 310:347 311:348 312:348 313:349 314:350 315:351 316:352 317:353 318:354 319:355 320:356 321:357 322:357 323:357 324:357 325:358 326:359 327:359 328:359 329:360 330:361 331:362 332:363 333:364 334:365 335:365 336:365 337:365 338:365 339:365 340:365 341:366 342:367 343:367 344:368 345:369 346:369 347:370 348:371 349:371 350:372 351:373 352:373 353:373 354:373 355:373 356:373 357:373 358:374 359:375 360:375 361:375 362:376 363:377 364:378 365:379 366:380 367:380 368:380 369:381 370:382 371:383 372:384 373:385 374:386 375:387 376:388 377:389 378:389 379:390 380:391 381:391 382:392\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:01.899127 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 102\n",
            "I0703 18:12:01.991187 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.991388 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:01.991560 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:01.994524 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000016\n",
            "I0703 18:12:01.994694 139789930788736 set_essential_params.py:432] unique_id: 1000000016\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:01.994756 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "I0703 18:12:01.994810 139789930788736 set_essential_params.py:434] doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in [SEP]\n",
            "I0703 18:12:01.994967 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:201 7:202 8:203 9:204 10:205 11:206 12:207 13:208 14:209 15:209 16:210 17:211 18:211 19:212 20:213 21:214 22:215 23:215 24:216 25:217 26:218 27:219 28:219 29:220 30:221 31:222 32:223 33:224 34:225 35:225 36:225 37:226 38:227 39:228 40:229 41:230 42:231 43:232 44:233 45:234 46:234 47:234 48:234 49:235 50:236 51:236 52:237 53:238 54:239 55:240 56:241 57:242 58:243 59:244 60:245 61:246 62:247 63:248 64:249 65:249 66:250 67:251 68:251 69:252 70:253 71:254 72:255 73:256 74:257 75:258 76:259 77:260 78:260 79:260 80:260 81:261 82:262 83:263 84:263 85:263 86:264 87:265 88:266 89:267 90:268 91:269 92:270 93:271 94:271 95:272 96:272 97:273 98:274 99:274 100:275 101:276 102:277 103:278 104:279 105:280 106:281 107:281 108:282 109:283 110:283 111:284 112:285 113:286 114:287 115:288 116:289 117:290 118:291 119:292 120:293 121:294 122:295 123:296 124:297 125:298 126:299 127:300 128:301 129:302 130:302 131:303 132:304 133:304 134:305 135:306 136:307 137:308 138:309 139:310 140:311 141:312 142:313 143:314 144:315 145:315 146:316 147:317 148:318 149:319 150:320 151:321 152:321 153:322 154:323 155:324 156:325 157:326 158:327 159:328 160:329 161:330 162:331 163:332 164:333 165:334 166:335 167:336 168:337 169:338 170:338 171:339 172:340 173:341 174:341 175:342 176:342 177:343 178:344 179:344 180:345 181:346 182:347 183:348 184:348 185:349 186:350 187:351 188:352 189:353 190:354 191:355 192:356 193:357 194:357 195:357 196:357 197:358 198:359 199:359 200:359 201:360 202:361 203:362 204:363 205:364 206:365 207:365 208:365 209:365 210:365 211:365 212:365 213:366 214:367 215:367 216:368 217:369 218:369 219:370 220:371 221:371 222:372 223:373 224:373 225:373 226:373 227:373 228:373 229:373 230:374 231:375 232:375 233:375 234:376 235:377 236:378 237:379 238:380 239:380 240:380 241:381 242:382 243:383 244:384 245:385 246:386 247:387 248:388 249:389 250:389 251:390 252:391 253:391 254:392 255:393 256:394 257:395 258:396 259:397 260:398 261:399 262:400 263:401 264:402 265:402 266:403 267:403 268:403 269:404 270:404 271:405 272:406 273:407 274:408 275:409 276:410 277:411 278:411 279:412 280:413 281:414 282:415 283:416 284:416 285:417 286:418 287:419 288:420 289:421 290:422 291:423 292:423 293:424 294:425 295:425 296:426 297:427 298:428 299:428 300:428 301:429 302:430 303:430 304:431 305:431 306:431 307:432 308:432 309:432 310:433 311:434 312:434 313:435 314:435 315:435 316:435 317:435 318:435 319:436 320:436 321:436 322:437 323:438 324:438 325:438 326:438 327:438 328:438 329:439 330:440 331:440 332:440 333:440 334:440 335:440 336:440 337:440 338:441 339:441 340:442 341:442 342:442 343:443 344:444 345:445 346:446 347:447 348:447 349:447 350:447 351:447 352:447 353:447 354:448 355:449 356:449 357:449 358:449 359:449 360:450 361:451 362:452 363:453 364:454 365:454 366:454 367:455 368:456 369:457 370:458 371:459 372:460 373:461 374:462 375:463 376:464 377:464 378:464 379:465 380:466 381:466 382:467\n",
            "I0703 18:12:02.092784 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:201 7:202 8:203 9:204 10:205 11:206 12:207 13:208 14:209 15:209 16:210 17:211 18:211 19:212 20:213 21:214 22:215 23:215 24:216 25:217 26:218 27:219 28:219 29:220 30:221 31:222 32:223 33:224 34:225 35:225 36:225 37:226 38:227 39:228 40:229 41:230 42:231 43:232 44:233 45:234 46:234 47:234 48:234 49:235 50:236 51:236 52:237 53:238 54:239 55:240 56:241 57:242 58:243 59:244 60:245 61:246 62:247 63:248 64:249 65:249 66:250 67:251 68:251 69:252 70:253 71:254 72:255 73:256 74:257 75:258 76:259 77:260 78:260 79:260 80:260 81:261 82:262 83:263 84:263 85:263 86:264 87:265 88:266 89:267 90:268 91:269 92:270 93:271 94:271 95:272 96:272 97:273 98:274 99:274 100:275 101:276 102:277 103:278 104:279 105:280 106:281 107:281 108:282 109:283 110:283 111:284 112:285 113:286 114:287 115:288 116:289 117:290 118:291 119:292 120:293 121:294 122:295 123:296 124:297 125:298 126:299 127:300 128:301 129:302 130:302 131:303 132:304 133:304 134:305 135:306 136:307 137:308 138:309 139:310 140:311 141:312 142:313 143:314 144:315 145:315 146:316 147:317 148:318 149:319 150:320 151:321 152:321 153:322 154:323 155:324 156:325 157:326 158:327 159:328 160:329 161:330 162:331 163:332 164:333 165:334 166:335 167:336 168:337 169:338 170:338 171:339 172:340 173:341 174:341 175:342 176:342 177:343 178:344 179:344 180:345 181:346 182:347 183:348 184:348 185:349 186:350 187:351 188:352 189:353 190:354 191:355 192:356 193:357 194:357 195:357 196:357 197:358 198:359 199:359 200:359 201:360 202:361 203:362 204:363 205:364 206:365 207:365 208:365 209:365 210:365 211:365 212:365 213:366 214:367 215:367 216:368 217:369 218:369 219:370 220:371 221:371 222:372 223:373 224:373 225:373 226:373 227:373 228:373 229:373 230:374 231:375 232:375 233:375 234:376 235:377 236:378 237:379 238:380 239:380 240:380 241:381 242:382 243:383 244:384 245:385 246:386 247:387 248:388 249:389 250:389 251:390 252:391 253:391 254:392 255:393 256:394 257:395 258:396 259:397 260:398 261:399 262:400 263:401 264:402 265:402 266:403 267:403 268:403 269:404 270:404 271:405 272:406 273:407 274:408 275:409 276:410 277:411 278:411 279:412 280:413 281:414 282:415 283:416 284:416 285:417 286:418 287:419 288:420 289:421 290:422 291:423 292:423 293:424 294:425 295:425 296:426 297:427 298:428 299:428 300:428 301:429 302:430 303:430 304:431 305:431 306:431 307:432 308:432 309:432 310:433 311:434 312:434 313:435 314:435 315:435 316:435 317:435 318:435 319:436 320:436 321:436 322:437 323:438 324:438 325:438 326:438 327:438 328:438 329:439 330:440 331:440 332:440 333:440 334:440 335:440 336:440 337:440 338:441 339:441 340:442 341:442 342:442 343:443 344:444 345:445 346:446 347:447 348:447 349:447 350:447 351:447 352:447 353:447 354:448 355:449 356:449 357:449 358:449 359:449 360:450 361:451 362:452 363:453 364:454 365:454 366:454 367:455 368:456 369:457 370:458 371:459 372:460 373:461 374:462 375:463 376:464 377:464 378:464 379:465 380:466 381:466 382:467\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.097429 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 102\n",
            "I0703 18:12:02.097850 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.098128 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.197665 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.200782 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000017\n",
            "I0703 18:12:02.200969 139789930788736 set_essential_params.py:432] unique_id: 1000000017\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.201027 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 3\n",
            "I0703 18:12:02.201075 139789930788736 set_essential_params.py:434] doc_span_index: 3\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck [SEP]\n",
            "I0703 18:12:02.201232 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:305 7:306 8:307 9:308 10:309 11:310 12:311 13:312 14:313 15:314 16:315 17:315 18:316 19:317 20:318 21:319 22:320 23:321 24:321 25:322 26:323 27:324 28:325 29:326 30:327 31:328 32:329 33:330 34:331 35:332 36:333 37:334 38:335 39:336 40:337 41:338 42:338 43:339 44:340 45:341 46:341 47:342 48:342 49:343 50:344 51:344 52:345 53:346 54:347 55:348 56:348 57:349 58:350 59:351 60:352 61:353 62:354 63:355 64:356 65:357 66:357 67:357 68:357 69:358 70:359 71:359 72:359 73:360 74:361 75:362 76:363 77:364 78:365 79:365 80:365 81:365 82:365 83:365 84:365 85:366 86:367 87:367 88:368 89:369 90:369 91:370 92:371 93:371 94:372 95:373 96:373 97:373 98:373 99:373 100:373 101:373 102:374 103:375 104:375 105:375 106:376 107:377 108:378 109:379 110:380 111:380 112:380 113:381 114:382 115:383 116:384 117:385 118:386 119:387 120:388 121:389 122:389 123:390 124:391 125:391 126:392 127:393 128:394 129:395 130:396 131:397 132:398 133:399 134:400 135:401 136:402 137:402 138:403 139:403 140:403 141:404 142:404 143:405 144:406 145:407 146:408 147:409 148:410 149:411 150:411 151:412 152:413 153:414 154:415 155:416 156:416 157:417 158:418 159:419 160:420 161:421 162:422 163:423 164:423 165:424 166:425 167:425 168:426 169:427 170:428 171:428 172:428 173:429 174:430 175:430 176:431 177:431 178:431 179:432 180:432 181:432 182:433 183:434 184:434 185:435 186:435 187:435 188:435 189:435 190:435 191:436 192:436 193:436 194:437 195:438 196:438 197:438 198:438 199:438 200:438 201:439 202:440 203:440 204:440 205:440 206:440 207:440 208:440 209:440 210:441 211:441 212:442 213:442 214:442 215:443 216:444 217:445 218:446 219:447 220:447 221:447 222:447 223:447 224:447 225:447 226:448 227:449 228:449 229:449 230:449 231:449 232:450 233:451 234:452 235:453 236:454 237:454 238:454 239:455 240:456 241:457 242:458 243:459 244:460 245:461 246:462 247:463 248:464 249:464 250:464 251:465 252:466 253:466 254:467 255:468 256:469 257:469 258:470 259:471 260:472 261:473 262:473 263:473 264:473 265:473 266:474 267:475 268:476 269:477 270:478 271:479 272:480 273:481 274:482 275:483 276:484 277:485 278:486 279:486 280:487 281:488 282:489 283:490 284:491 285:492 286:493 287:494 288:495 289:495 290:496 291:497 292:498 293:499 294:500 295:501 296:502 297:503 298:504 299:505 300:506 301:507 302:508 303:509 304:509 305:509 306:510 307:511 308:512 309:513 310:514 311:514 312:514 313:515 314:516 315:517 316:517 317:518 318:519 319:519 320:519 321:519 322:520 323:520 324:521 325:522 326:522 327:523 328:524 329:524 330:525 331:525 332:525 333:525 334:525 335:525 336:525 337:526 338:527 339:528 340:529 341:530 342:531 343:532 344:533 345:534 346:534 347:534 348:534 349:535 350:535 351:536 352:537 353:538 354:539 355:540 356:541 357:542 358:543 359:544 360:544 361:545 362:546 363:547 364:548 365:548 366:549 367:550 368:550 369:551 370:552 371:553 372:554 373:555 374:556 375:557 376:558 377:559 378:560 379:561 380:562 381:563 382:563\n",
            "I0703 18:12:02.201440 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:305 7:306 8:307 9:308 10:309 11:310 12:311 13:312 14:313 15:314 16:315 17:315 18:316 19:317 20:318 21:319 22:320 23:321 24:321 25:322 26:323 27:324 28:325 29:326 30:327 31:328 32:329 33:330 34:331 35:332 36:333 37:334 38:335 39:336 40:337 41:338 42:338 43:339 44:340 45:341 46:341 47:342 48:342 49:343 50:344 51:344 52:345 53:346 54:347 55:348 56:348 57:349 58:350 59:351 60:352 61:353 62:354 63:355 64:356 65:357 66:357 67:357 68:357 69:358 70:359 71:359 72:359 73:360 74:361 75:362 76:363 77:364 78:365 79:365 80:365 81:365 82:365 83:365 84:365 85:366 86:367 87:367 88:368 89:369 90:369 91:370 92:371 93:371 94:372 95:373 96:373 97:373 98:373 99:373 100:373 101:373 102:374 103:375 104:375 105:375 106:376 107:377 108:378 109:379 110:380 111:380 112:380 113:381 114:382 115:383 116:384 117:385 118:386 119:387 120:388 121:389 122:389 123:390 124:391 125:391 126:392 127:393 128:394 129:395 130:396 131:397 132:398 133:399 134:400 135:401 136:402 137:402 138:403 139:403 140:403 141:404 142:404 143:405 144:406 145:407 146:408 147:409 148:410 149:411 150:411 151:412 152:413 153:414 154:415 155:416 156:416 157:417 158:418 159:419 160:420 161:421 162:422 163:423 164:423 165:424 166:425 167:425 168:426 169:427 170:428 171:428 172:428 173:429 174:430 175:430 176:431 177:431 178:431 179:432 180:432 181:432 182:433 183:434 184:434 185:435 186:435 187:435 188:435 189:435 190:435 191:436 192:436 193:436 194:437 195:438 196:438 197:438 198:438 199:438 200:438 201:439 202:440 203:440 204:440 205:440 206:440 207:440 208:440 209:440 210:441 211:441 212:442 213:442 214:442 215:443 216:444 217:445 218:446 219:447 220:447 221:447 222:447 223:447 224:447 225:447 226:448 227:449 228:449 229:449 230:449 231:449 232:450 233:451 234:452 235:453 236:454 237:454 238:454 239:455 240:456 241:457 242:458 243:459 244:460 245:461 246:462 247:463 248:464 249:464 250:464 251:465 252:466 253:466 254:467 255:468 256:469 257:469 258:470 259:471 260:472 261:473 262:473 263:473 264:473 265:473 266:474 267:475 268:476 269:477 270:478 271:479 272:480 273:481 274:482 275:483 276:484 277:485 278:486 279:486 280:487 281:488 282:489 283:490 284:491 285:492 286:493 287:494 288:495 289:495 290:496 291:497 292:498 293:499 294:500 295:501 296:502 297:503 298:504 299:505 300:506 301:507 302:508 303:509 304:509 305:509 306:510 307:511 308:512 309:513 310:514 311:514 312:514 313:515 314:516 315:517 316:517 317:518 318:519 319:519 320:519 321:519 322:520 323:520 324:521 325:522 326:522 327:523 328:524 329:524 330:525 331:525 332:525 333:525 334:525 335:525 336:525 337:526 338:527 339:528 340:529 341:530 342:531 343:532 344:533 345:534 346:534 347:534 348:534 349:535 350:535 351:536 352:537 353:538 354:539 355:540 356:541 357:542 358:543 359:544 360:544 361:545 362:546 363:547 364:548 365:548 366:549 367:550 368:550 369:551 370:552 371:553 372:554 373:555 374:556 375:557 376:558 377:559 378:560 379:561 380:562 381:563 382:563\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.203139 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 102\n",
            "I0703 18:12:02.203464 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.306071 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.306504 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.312074 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000018\n",
            "I0703 18:12:02.312381 139789930788736 set_essential_params.py:432] unique_id: 1000000018\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.312523 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 4\n",
            "I0703 18:12:02.312629 139789930788736 set_essential_params.py:434] doc_span_index: 4\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw [SEP]\n",
            "I0703 18:12:02.312880 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:400 7:401 8:402 9:402 10:403 11:403 12:403 13:404 14:404 15:405 16:406 17:407 18:408 19:409 20:410 21:411 22:411 23:412 24:413 25:414 26:415 27:416 28:416 29:417 30:418 31:419 32:420 33:421 34:422 35:423 36:423 37:424 38:425 39:425 40:426 41:427 42:428 43:428 44:428 45:429 46:430 47:430 48:431 49:431 50:431 51:432 52:432 53:432 54:433 55:434 56:434 57:435 58:435 59:435 60:435 61:435 62:435 63:436 64:436 65:436 66:437 67:438 68:438 69:438 70:438 71:438 72:438 73:439 74:440 75:440 76:440 77:440 78:440 79:440 80:440 81:440 82:441 83:441 84:442 85:442 86:442 87:443 88:444 89:445 90:446 91:447 92:447 93:447 94:447 95:447 96:447 97:447 98:448 99:449 100:449 101:449 102:449 103:449 104:450 105:451 106:452 107:453 108:454 109:454 110:454 111:455 112:456 113:457 114:458 115:459 116:460 117:461 118:462 119:463 120:464 121:464 122:464 123:465 124:466 125:466 126:467 127:468 128:469 129:469 130:470 131:471 132:472 133:473 134:473 135:473 136:473 137:473 138:474 139:475 140:476 141:477 142:478 143:479 144:480 145:481 146:482 147:483 148:484 149:485 150:486 151:486 152:487 153:488 154:489 155:490 156:491 157:492 158:493 159:494 160:495 161:495 162:496 163:497 164:498 165:499 166:500 167:501 168:502 169:503 170:504 171:505 172:506 173:507 174:508 175:509 176:509 177:509 178:510 179:511 180:512 181:513 182:514 183:514 184:514 185:515 186:516 187:517 188:517 189:518 190:519 191:519 192:519 193:519 194:520 195:520 196:521 197:522 198:522 199:523 200:524 201:524 202:525 203:525 204:525 205:525 206:525 207:525 208:525 209:526 210:527 211:528 212:529 213:530 214:531 215:532 216:533 217:534 218:534 219:534 220:534 221:535 222:535 223:536 224:537 225:538 226:539 227:540 228:541 229:542 230:543 231:544 232:544 233:545 234:546 235:547 236:548 237:548 238:549 239:550 240:550 241:551 242:552 243:553 244:554 245:555 246:556 247:557 248:558 249:559 250:560 251:561 252:562 253:563 254:563 255:563 256:564 257:565 258:566 259:567 260:568 261:569 262:570 263:571 264:572 265:572 266:573 267:574 268:575 269:576 270:577 271:578 272:579 273:580 274:580 275:581 276:582 277:583 278:584 279:585 280:586 281:587 282:588 283:589 284:590 285:591 286:592 287:593 288:594 289:595 290:596 291:596 292:597 293:598 294:599 295:600 296:600 297:601 298:602 299:603 300:604 301:605 302:606 303:607 304:608 305:609 306:610 307:611 308:612 309:613 310:614 311:615 312:615 313:616 314:617 315:618 316:619 317:620 318:621 319:622 320:623 321:624 322:625 323:625 324:625 325:626 326:627 327:628 328:628 329:629 330:630 331:631 332:631 333:632 334:633 335:634 336:635 337:636 338:637 339:638 340:639 341:640 342:641 343:642 344:643 345:644 346:645 347:646 348:647 349:648 350:649 351:650 352:650 353:651 354:652 355:652 356:653 357:654 358:655 359:656 360:656 361:656 362:657 363:657 364:657 365:657 366:658 367:658 368:659 369:660 370:661 371:662 372:663 373:664 374:665 375:665 376:666 377:666 378:666 379:667 380:667 381:667 382:668\n",
            "I0703 18:12:02.313155 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:400 7:401 8:402 9:402 10:403 11:403 12:403 13:404 14:404 15:405 16:406 17:407 18:408 19:409 20:410 21:411 22:411 23:412 24:413 25:414 26:415 27:416 28:416 29:417 30:418 31:419 32:420 33:421 34:422 35:423 36:423 37:424 38:425 39:425 40:426 41:427 42:428 43:428 44:428 45:429 46:430 47:430 48:431 49:431 50:431 51:432 52:432 53:432 54:433 55:434 56:434 57:435 58:435 59:435 60:435 61:435 62:435 63:436 64:436 65:436 66:437 67:438 68:438 69:438 70:438 71:438 72:438 73:439 74:440 75:440 76:440 77:440 78:440 79:440 80:440 81:440 82:441 83:441 84:442 85:442 86:442 87:443 88:444 89:445 90:446 91:447 92:447 93:447 94:447 95:447 96:447 97:447 98:448 99:449 100:449 101:449 102:449 103:449 104:450 105:451 106:452 107:453 108:454 109:454 110:454 111:455 112:456 113:457 114:458 115:459 116:460 117:461 118:462 119:463 120:464 121:464 122:464 123:465 124:466 125:466 126:467 127:468 128:469 129:469 130:470 131:471 132:472 133:473 134:473 135:473 136:473 137:473 138:474 139:475 140:476 141:477 142:478 143:479 144:480 145:481 146:482 147:483 148:484 149:485 150:486 151:486 152:487 153:488 154:489 155:490 156:491 157:492 158:493 159:494 160:495 161:495 162:496 163:497 164:498 165:499 166:500 167:501 168:502 169:503 170:504 171:505 172:506 173:507 174:508 175:509 176:509 177:509 178:510 179:511 180:512 181:513 182:514 183:514 184:514 185:515 186:516 187:517 188:517 189:518 190:519 191:519 192:519 193:519 194:520 195:520 196:521 197:522 198:522 199:523 200:524 201:524 202:525 203:525 204:525 205:525 206:525 207:525 208:525 209:526 210:527 211:528 212:529 213:530 214:531 215:532 216:533 217:534 218:534 219:534 220:534 221:535 222:535 223:536 224:537 225:538 226:539 227:540 228:541 229:542 230:543 231:544 232:544 233:545 234:546 235:547 236:548 237:548 238:549 239:550 240:550 241:551 242:552 243:553 244:554 245:555 246:556 247:557 248:558 249:559 250:560 251:561 252:562 253:563 254:563 255:563 256:564 257:565 258:566 259:567 260:568 261:569 262:570 263:571 264:572 265:572 266:573 267:574 268:575 269:576 270:577 271:578 272:579 273:580 274:580 275:581 276:582 277:583 278:584 279:585 280:586 281:587 282:588 283:589 284:590 285:591 286:592 287:593 288:594 289:595 290:596 291:596 292:597 293:598 294:599 295:600 296:600 297:601 298:602 299:603 300:604 301:605 302:606 303:607 304:608 305:609 306:610 307:611 308:612 309:613 310:614 311:615 312:615 313:616 314:617 315:618 316:619 317:620 318:621 319:622 320:623 321:624 322:625 323:625 324:625 325:626 326:627 327:628 328:628 329:629 330:630 331:631 332:631 333:632 334:633 335:634 336:635 337:636 338:637 339:638 340:639 341:640 342:641 343:642 344:643 345:644 346:645 347:646 348:647 349:648 350:649 351:650 352:650 353:651 354:652 355:652 356:653 357:654 358:655 359:656 360:656 361:656 362:657 363:657 364:657 365:657 366:658 367:658 368:659 369:660 370:661 371:662 372:663 373:664 374:665 375:665 376:666 377:666 378:666 379:667 380:667 381:667 382:668\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.404608 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 102\n",
            "I0703 18:12:02.405353 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.405712 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.405979 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.409878 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000019\n",
            "I0703 18:12:02.410050 139789930788736 set_essential_params.py:432] unique_id: 1000000019\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.410148 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 5\n",
            "I0703 18:12:02.410234 139789930788736 set_essential_params.py:434] doc_span_index: 5\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & [SEP]\n",
            "I0703 18:12:02.410462 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:473 7:473 8:473 9:473 10:474 11:475 12:476 13:477 14:478 15:479 16:480 17:481 18:482 19:483 20:484 21:485 22:486 23:486 24:487 25:488 26:489 27:490 28:491 29:492 30:493 31:494 32:495 33:495 34:496 35:497 36:498 37:499 38:500 39:501 40:502 41:503 42:504 43:505 44:506 45:507 46:508 47:509 48:509 49:509 50:510 51:511 52:512 53:513 54:514 55:514 56:514 57:515 58:516 59:517 60:517 61:518 62:519 63:519 64:519 65:519 66:520 67:520 68:521 69:522 70:522 71:523 72:524 73:524 74:525 75:525 76:525 77:525 78:525 79:525 80:525 81:526 82:527 83:528 84:529 85:530 86:531 87:532 88:533 89:534 90:534 91:534 92:534 93:535 94:535 95:536 96:537 97:538 98:539 99:540 100:541 101:542 102:543 103:544 104:544 105:545 106:546 107:547 108:548 109:548 110:549 111:550 112:550 113:551 114:552 115:553 116:554 117:555 118:556 119:557 120:558 121:559 122:560 123:561 124:562 125:563 126:563 127:563 128:564 129:565 130:566 131:567 132:568 133:569 134:570 135:571 136:572 137:572 138:573 139:574 140:575 141:576 142:577 143:578 144:579 145:580 146:580 147:581 148:582 149:583 150:584 151:585 152:586 153:587 154:588 155:589 156:590 157:591 158:592 159:593 160:594 161:595 162:596 163:596 164:597 165:598 166:599 167:600 168:600 169:601 170:602 171:603 172:604 173:605 174:606 175:607 176:608 177:609 178:610 179:611 180:612 181:613 182:614 183:615 184:615 185:616 186:617 187:618 188:619 189:620 190:621 191:622 192:623 193:624 194:625 195:625 196:625 197:626 198:627 199:628 200:628 201:629 202:630 203:631 204:631 205:632 206:633 207:634 208:635 209:636 210:637 211:638 212:639 213:640 214:641 215:642 216:643 217:644 218:645 219:646 220:647 221:648 222:649 223:650 224:650 225:651 226:652 227:652 228:653 229:654 230:655 231:656 232:656 233:656 234:657 235:657 236:657 237:657 238:658 239:658 240:659 241:660 242:661 243:662 244:663 245:664 246:665 247:665 248:666 249:666 250:666 251:667 252:667 253:667 254:668 255:668 256:668 257:669 258:670 259:671 260:672 261:673 262:674 263:675 264:676 265:677 266:678 267:679 268:680 269:681 270:682 271:683 272:684 273:685 274:685 275:686 276:687 277:688 278:689 279:689 280:690 281:691 282:692 283:693 284:694 285:695 286:696 287:697 288:698 289:699 290:700 291:701 292:701 293:702 294:703 295:704 296:705 297:706 298:707 299:707 300:708 301:709 302:709 303:709 304:709 305:710 306:711 307:712 308:713 309:713 310:714 311:714 312:715 313:716 314:717 315:718 316:719 317:720 318:721 319:722 320:723 321:724 322:724 323:725 324:725 325:726 326:727 327:728 328:729 329:730 330:730 331:731 332:732 333:733 334:734 335:735 336:735 337:736 338:737 339:737 340:737 341:738 342:738 343:739 344:740 345:741 346:741 347:742 348:743 349:744 350:745 351:746 352:747 353:748 354:748 355:749 356:749 357:749 358:750 359:751 360:752 361:753 362:753 363:754 364:755 365:755 366:756 367:757 368:757 369:758 370:759 371:759 372:759 373:760 374:761 375:761 376:762 377:763 378:764 379:764 380:765 381:765 382:765\n",
            "I0703 18:12:02.410703 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:473 7:473 8:473 9:473 10:474 11:475 12:476 13:477 14:478 15:479 16:480 17:481 18:482 19:483 20:484 21:485 22:486 23:486 24:487 25:488 26:489 27:490 28:491 29:492 30:493 31:494 32:495 33:495 34:496 35:497 36:498 37:499 38:500 39:501 40:502 41:503 42:504 43:505 44:506 45:507 46:508 47:509 48:509 49:509 50:510 51:511 52:512 53:513 54:514 55:514 56:514 57:515 58:516 59:517 60:517 61:518 62:519 63:519 64:519 65:519 66:520 67:520 68:521 69:522 70:522 71:523 72:524 73:524 74:525 75:525 76:525 77:525 78:525 79:525 80:525 81:526 82:527 83:528 84:529 85:530 86:531 87:532 88:533 89:534 90:534 91:534 92:534 93:535 94:535 95:536 96:537 97:538 98:539 99:540 100:541 101:542 102:543 103:544 104:544 105:545 106:546 107:547 108:548 109:548 110:549 111:550 112:550 113:551 114:552 115:553 116:554 117:555 118:556 119:557 120:558 121:559 122:560 123:561 124:562 125:563 126:563 127:563 128:564 129:565 130:566 131:567 132:568 133:569 134:570 135:571 136:572 137:572 138:573 139:574 140:575 141:576 142:577 143:578 144:579 145:580 146:580 147:581 148:582 149:583 150:584 151:585 152:586 153:587 154:588 155:589 156:590 157:591 158:592 159:593 160:594 161:595 162:596 163:596 164:597 165:598 166:599 167:600 168:600 169:601 170:602 171:603 172:604 173:605 174:606 175:607 176:608 177:609 178:610 179:611 180:612 181:613 182:614 183:615 184:615 185:616 186:617 187:618 188:619 189:620 190:621 191:622 192:623 193:624 194:625 195:625 196:625 197:626 198:627 199:628 200:628 201:629 202:630 203:631 204:631 205:632 206:633 207:634 208:635 209:636 210:637 211:638 212:639 213:640 214:641 215:642 216:643 217:644 218:645 219:646 220:647 221:648 222:649 223:650 224:650 225:651 226:652 227:652 228:653 229:654 230:655 231:656 232:656 233:656 234:657 235:657 236:657 237:657 238:658 239:658 240:659 241:660 242:661 243:662 244:663 245:664 246:665 247:665 248:666 249:666 250:666 251:667 252:667 253:667 254:668 255:668 256:668 257:669 258:670 259:671 260:672 261:673 262:674 263:675 264:676 265:677 266:678 267:679 268:680 269:681 270:682 271:683 272:684 273:685 274:685 275:686 276:687 277:688 278:689 279:689 280:690 281:691 282:692 283:693 284:694 285:695 286:696 287:697 288:698 289:699 290:700 291:701 292:701 293:702 294:703 295:704 296:705 297:706 298:707 299:707 300:708 301:709 302:709 303:709 304:709 305:710 306:711 307:712 308:713 309:713 310:714 311:714 312:715 313:716 314:717 315:718 316:719 317:720 318:721 319:722 320:723 321:724 322:724 323:725 324:725 325:726 326:727 327:728 328:729 329:730 330:730 331:731 332:732 333:733 334:734 335:735 336:735 337:736 338:737 339:737 340:737 341:738 342:738 343:739 344:740 345:741 346:741 347:742 348:743 349:744 350:745 351:746 352:747 353:748 354:748 355:749 356:749 357:749 358:750 359:751 360:752 361:753 362:753 363:754 364:755 365:755 366:756 367:757 368:757 369:758 370:759 371:759 372:759 373:760 374:761 375:761 376:762 377:763 378:764 379:764 380:765 381:765 382:765\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.410935 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 102\n",
            "I0703 18:12:02.510750 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.511582 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.511950 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.518415 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000020\n",
            "I0703 18:12:02.518686 139789930788736 set_essential_params.py:432] unique_id: 1000000020\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.518806 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 6\n",
            "I0703 18:12:02.518929 139789930788736 set_essential_params.py:434] doc_span_index: 6\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av [SEP]\n",
            "I0703 18:12:02.519288 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:570 7:571 8:572 9:572 10:573 11:574 12:575 13:576 14:577 15:578 16:579 17:580 18:580 19:581 20:582 21:583 22:584 23:585 24:586 25:587 26:588 27:589 28:590 29:591 30:592 31:593 32:594 33:595 34:596 35:596 36:597 37:598 38:599 39:600 40:600 41:601 42:602 43:603 44:604 45:605 46:606 47:607 48:608 49:609 50:610 51:611 52:612 53:613 54:614 55:615 56:615 57:616 58:617 59:618 60:619 61:620 62:621 63:622 64:623 65:624 66:625 67:625 68:625 69:626 70:627 71:628 72:628 73:629 74:630 75:631 76:631 77:632 78:633 79:634 80:635 81:636 82:637 83:638 84:639 85:640 86:641 87:642 88:643 89:644 90:645 91:646 92:647 93:648 94:649 95:650 96:650 97:651 98:652 99:652 100:653 101:654 102:655 103:656 104:656 105:656 106:657 107:657 108:657 109:657 110:658 111:658 112:659 113:660 114:661 115:662 116:663 117:664 118:665 119:665 120:666 121:666 122:666 123:667 124:667 125:667 126:668 127:668 128:668 129:669 130:670 131:671 132:672 133:673 134:674 135:675 136:676 137:677 138:678 139:679 140:680 141:681 142:682 143:683 144:684 145:685 146:685 147:686 148:687 149:688 150:689 151:689 152:690 153:691 154:692 155:693 156:694 157:695 158:696 159:697 160:698 161:699 162:700 163:701 164:701 165:702 166:703 167:704 168:705 169:706 170:707 171:707 172:708 173:709 174:709 175:709 176:709 177:710 178:711 179:712 180:713 181:713 182:714 183:714 184:715 185:716 186:717 187:718 188:719 189:720 190:721 191:722 192:723 193:724 194:724 195:725 196:725 197:726 198:727 199:728 200:729 201:730 202:730 203:731 204:732 205:733 206:734 207:735 208:735 209:736 210:737 211:737 212:737 213:738 214:738 215:739 216:740 217:741 218:741 219:742 220:743 221:744 222:745 223:746 224:747 225:748 226:748 227:749 228:749 229:749 230:750 231:751 232:752 233:753 234:753 235:754 236:755 237:755 238:756 239:757 240:757 241:758 242:759 243:759 244:759 245:760 246:761 247:761 248:762 249:763 250:764 251:764 252:765 253:765 254:765 255:765 256:765 257:766 258:767 259:768 260:768 261:768 262:769 263:769 264:769 265:769 266:769 267:769 268:769 269:769 270:770 271:770 272:770 273:770 274:771 275:772 276:773 277:773 278:774 279:775 280:775 281:775 282:775 283:775 284:775 285:775 286:776 287:776 288:776 289:776 290:777 291:778 292:779 293:779 294:780 295:781 296:782 297:783 298:784 299:784 300:785 301:786 302:786 303:787 304:788 305:789 306:789 307:790 308:791 309:792 310:792 311:793 312:794 313:794 314:795 315:796 316:797 317:798 318:798 319:799 320:800 321:801 322:802 323:803 324:804 325:805 326:806 327:807 328:808 329:809 330:810 331:811 332:812 333:812 334:813 335:814 336:814 337:815 338:816 339:816 340:816 341:817 342:818 343:819 344:820 345:821 346:822 347:823 348:824 349:824 350:825 351:826 352:826 353:827 354:828 355:829 356:829 357:830 358:831 359:832 360:833 361:834 362:835 363:836 364:837 365:837 366:837 367:837 368:838 369:838 370:838 371:838 372:838 373:839 374:840 375:841 376:841 377:842 378:843 379:844 380:845 381:846 382:847\n",
            "I0703 18:12:02.519771 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:570 7:571 8:572 9:572 10:573 11:574 12:575 13:576 14:577 15:578 16:579 17:580 18:580 19:581 20:582 21:583 22:584 23:585 24:586 25:587 26:588 27:589 28:590 29:591 30:592 31:593 32:594 33:595 34:596 35:596 36:597 37:598 38:599 39:600 40:600 41:601 42:602 43:603 44:604 45:605 46:606 47:607 48:608 49:609 50:610 51:611 52:612 53:613 54:614 55:615 56:615 57:616 58:617 59:618 60:619 61:620 62:621 63:622 64:623 65:624 66:625 67:625 68:625 69:626 70:627 71:628 72:628 73:629 74:630 75:631 76:631 77:632 78:633 79:634 80:635 81:636 82:637 83:638 84:639 85:640 86:641 87:642 88:643 89:644 90:645 91:646 92:647 93:648 94:649 95:650 96:650 97:651 98:652 99:652 100:653 101:654 102:655 103:656 104:656 105:656 106:657 107:657 108:657 109:657 110:658 111:658 112:659 113:660 114:661 115:662 116:663 117:664 118:665 119:665 120:666 121:666 122:666 123:667 124:667 125:667 126:668 127:668 128:668 129:669 130:670 131:671 132:672 133:673 134:674 135:675 136:676 137:677 138:678 139:679 140:680 141:681 142:682 143:683 144:684 145:685 146:685 147:686 148:687 149:688 150:689 151:689 152:690 153:691 154:692 155:693 156:694 157:695 158:696 159:697 160:698 161:699 162:700 163:701 164:701 165:702 166:703 167:704 168:705 169:706 170:707 171:707 172:708 173:709 174:709 175:709 176:709 177:710 178:711 179:712 180:713 181:713 182:714 183:714 184:715 185:716 186:717 187:718 188:719 189:720 190:721 191:722 192:723 193:724 194:724 195:725 196:725 197:726 198:727 199:728 200:729 201:730 202:730 203:731 204:732 205:733 206:734 207:735 208:735 209:736 210:737 211:737 212:737 213:738 214:738 215:739 216:740 217:741 218:741 219:742 220:743 221:744 222:745 223:746 224:747 225:748 226:748 227:749 228:749 229:749 230:750 231:751 232:752 233:753 234:753 235:754 236:755 237:755 238:756 239:757 240:757 241:758 242:759 243:759 244:759 245:760 246:761 247:761 248:762 249:763 250:764 251:764 252:765 253:765 254:765 255:765 256:765 257:766 258:767 259:768 260:768 261:768 262:769 263:769 264:769 265:769 266:769 267:769 268:769 269:769 270:770 271:770 272:770 273:770 274:771 275:772 276:773 277:773 278:774 279:775 280:775 281:775 282:775 283:775 284:775 285:775 286:776 287:776 288:776 289:776 290:777 291:778 292:779 293:779 294:780 295:781 296:782 297:783 298:784 299:784 300:785 301:786 302:786 303:787 304:788 305:789 306:789 307:790 308:791 309:792 310:792 311:793 312:794 313:794 314:795 315:796 316:797 317:798 318:798 319:799 320:800 321:801 322:802 323:803 324:804 325:805 326:806 327:807 328:808 329:809 330:810 331:811 332:812 333:812 334:813 335:814 336:814 337:815 338:816 339:816 340:816 341:817 342:818 343:819 344:820 345:821 346:822 347:823 348:824 349:824 350:825 351:826 352:826 353:827 354:828 355:829 356:829 357:830 358:831 359:832 360:833 361:834 362:835 363:836 364:837 365:837 366:837 367:837 368:838 369:838 370:838 371:838 372:838 373:839 374:840 375:841 376:841 377:842 378:843 379:844 380:845 381:846 382:847\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.610002 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 102\n",
            "I0703 18:12:02.611793 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.612776 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.613045 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.616050 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000021\n",
            "I0703 18:12:02.616198 139789930788736 set_essential_params.py:432] unique_id: 1000000021\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.616295 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 7\n",
            "I0703 18:12:02.616379 139789930788736 set_essential_params.py:434] doc_span_index: 7\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor [SEP]\n",
            "I0703 18:12:02.616613 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:674 7:675 8:676 9:677 10:678 11:679 12:680 13:681 14:682 15:683 16:684 17:685 18:685 19:686 20:687 21:688 22:689 23:689 24:690 25:691 26:692 27:693 28:694 29:695 30:696 31:697 32:698 33:699 34:700 35:701 36:701 37:702 38:703 39:704 40:705 41:706 42:707 43:707 44:708 45:709 46:709 47:709 48:709 49:710 50:711 51:712 52:713 53:713 54:714 55:714 56:715 57:716 58:717 59:718 60:719 61:720 62:721 63:722 64:723 65:724 66:724 67:725 68:725 69:726 70:727 71:728 72:729 73:730 74:730 75:731 76:732 77:733 78:734 79:735 80:735 81:736 82:737 83:737 84:737 85:738 86:738 87:739 88:740 89:741 90:741 91:742 92:743 93:744 94:745 95:746 96:747 97:748 98:748 99:749 100:749 101:749 102:750 103:751 104:752 105:753 106:753 107:754 108:755 109:755 110:756 111:757 112:757 113:758 114:759 115:759 116:759 117:760 118:761 119:761 120:762 121:763 122:764 123:764 124:765 125:765 126:765 127:765 128:765 129:766 130:767 131:768 132:768 133:768 134:769 135:769 136:769 137:769 138:769 139:769 140:769 141:769 142:770 143:770 144:770 145:770 146:771 147:772 148:773 149:773 150:774 151:775 152:775 153:775 154:775 155:775 156:775 157:775 158:776 159:776 160:776 161:776 162:777 163:778 164:779 165:779 166:780 167:781 168:782 169:783 170:784 171:784 172:785 173:786 174:786 175:787 176:788 177:789 178:789 179:790 180:791 181:792 182:792 183:793 184:794 185:794 186:795 187:796 188:797 189:798 190:798 191:799 192:800 193:801 194:802 195:803 196:804 197:805 198:806 199:807 200:808 201:809 202:810 203:811 204:812 205:812 206:813 207:814 208:814 209:815 210:816 211:816 212:816 213:817 214:818 215:819 216:820 217:821 218:822 219:823 220:824 221:824 222:825 223:826 224:826 225:827 226:828 227:829 228:829 229:830 230:831 231:832 232:833 233:834 234:835 235:836 236:837 237:837 238:837 239:837 240:838 241:838 242:838 243:838 244:838 245:839 246:840 247:841 248:841 249:842 250:843 251:844 252:845 253:846 254:847 255:847 256:847 257:847 258:848 259:849 260:850 261:851 262:852 263:852 264:852 265:853 266:854 267:854 268:854 269:854 270:855 271:856 272:856 273:857 274:858 275:859 276:860 277:860 278:860 279:860 280:861 281:862 282:863 283:864 284:865 285:866 286:867 287:867 288:868 289:869 290:870 291:871 292:872 293:873 294:874 295:875 296:876 297:877 298:878 299:879 300:879 301:880 302:881 303:882 304:882 305:883 306:884 307:884 308:884 309:884 310:885 311:885 312:886 313:887 314:888 315:889 316:890 317:890 318:891 319:892 320:893 321:894 322:895 323:896 324:897 325:897 326:898 327:899 328:900 329:901 330:902 331:903 332:904 333:905 334:906 335:907 336:907 337:907 338:907 339:908 340:909 341:910 342:911 343:912 344:913 345:914 346:914 347:915 348:916 349:916 350:917 351:918 352:919 353:920 354:920 355:920 356:920 357:921 358:922 359:923 360:924 361:924 362:925 363:926 364:927 365:928 366:929 367:929 368:929 369:929 370:930 371:930 372:930 373:931 374:931 375:931 376:932 377:932 378:932 379:933 380:933 381:933 382:933\n",
            "I0703 18:12:02.616868 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:674 7:675 8:676 9:677 10:678 11:679 12:680 13:681 14:682 15:683 16:684 17:685 18:685 19:686 20:687 21:688 22:689 23:689 24:690 25:691 26:692 27:693 28:694 29:695 30:696 31:697 32:698 33:699 34:700 35:701 36:701 37:702 38:703 39:704 40:705 41:706 42:707 43:707 44:708 45:709 46:709 47:709 48:709 49:710 50:711 51:712 52:713 53:713 54:714 55:714 56:715 57:716 58:717 59:718 60:719 61:720 62:721 63:722 64:723 65:724 66:724 67:725 68:725 69:726 70:727 71:728 72:729 73:730 74:730 75:731 76:732 77:733 78:734 79:735 80:735 81:736 82:737 83:737 84:737 85:738 86:738 87:739 88:740 89:741 90:741 91:742 92:743 93:744 94:745 95:746 96:747 97:748 98:748 99:749 100:749 101:749 102:750 103:751 104:752 105:753 106:753 107:754 108:755 109:755 110:756 111:757 112:757 113:758 114:759 115:759 116:759 117:760 118:761 119:761 120:762 121:763 122:764 123:764 124:765 125:765 126:765 127:765 128:765 129:766 130:767 131:768 132:768 133:768 134:769 135:769 136:769 137:769 138:769 139:769 140:769 141:769 142:770 143:770 144:770 145:770 146:771 147:772 148:773 149:773 150:774 151:775 152:775 153:775 154:775 155:775 156:775 157:775 158:776 159:776 160:776 161:776 162:777 163:778 164:779 165:779 166:780 167:781 168:782 169:783 170:784 171:784 172:785 173:786 174:786 175:787 176:788 177:789 178:789 179:790 180:791 181:792 182:792 183:793 184:794 185:794 186:795 187:796 188:797 189:798 190:798 191:799 192:800 193:801 194:802 195:803 196:804 197:805 198:806 199:807 200:808 201:809 202:810 203:811 204:812 205:812 206:813 207:814 208:814 209:815 210:816 211:816 212:816 213:817 214:818 215:819 216:820 217:821 218:822 219:823 220:824 221:824 222:825 223:826 224:826 225:827 226:828 227:829 228:829 229:830 230:831 231:832 232:833 233:834 234:835 235:836 236:837 237:837 238:837 239:837 240:838 241:838 242:838 243:838 244:838 245:839 246:840 247:841 248:841 249:842 250:843 251:844 252:845 253:846 254:847 255:847 256:847 257:847 258:848 259:849 260:850 261:851 262:852 263:852 264:852 265:853 266:854 267:854 268:854 269:854 270:855 271:856 272:856 273:857 274:858 275:859 276:860 277:860 278:860 279:860 280:861 281:862 282:863 283:864 284:865 285:866 286:867 287:867 288:868 289:869 290:870 291:871 292:872 293:873 294:874 295:875 296:876 297:877 298:878 299:879 300:879 301:880 302:881 303:882 304:882 305:883 306:884 307:884 308:884 309:884 310:885 311:885 312:886 313:887 314:888 315:889 316:890 317:890 318:891 319:892 320:893 321:894 322:895 323:896 324:897 325:897 326:898 327:899 328:900 329:901 330:902 331:903 332:904 333:905 334:906 335:907 336:907 337:907 338:907 339:908 340:909 341:910 342:911 343:912 344:913 345:914 346:914 347:915 348:916 349:916 350:917 351:918 352:919 353:920 354:920 355:920 356:920 357:921 358:922 359:923 360:924 361:924 362:925 363:926 364:927 365:928 366:929 367:929 368:929 369:929 370:930 371:930 372:930 373:931 374:931 375:931 376:932 377:932 378:932 379:933 380:933 381:933 382:933\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.617107 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 102\n",
            "I0703 18:12:02.714246 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.714682 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.714937 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.720146 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000022\n",
            "I0703 18:12:02.720444 139789930788736 set_essential_params.py:432] unique_id: 1000000022\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.720618 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 8\n",
            "I0703 18:12:02.720787 139789930788736 set_essential_params.py:434] doc_span_index: 8\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including [SEP]\n",
            "I0703 18:12:02.721170 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:769 7:769 8:769 9:769 10:769 11:769 12:769 13:769 14:770 15:770 16:770 17:770 18:771 19:772 20:773 21:773 22:774 23:775 24:775 25:775 26:775 27:775 28:775 29:775 30:776 31:776 32:776 33:776 34:777 35:778 36:779 37:779 38:780 39:781 40:782 41:783 42:784 43:784 44:785 45:786 46:786 47:787 48:788 49:789 50:789 51:790 52:791 53:792 54:792 55:793 56:794 57:794 58:795 59:796 60:797 61:798 62:798 63:799 64:800 65:801 66:802 67:803 68:804 69:805 70:806 71:807 72:808 73:809 74:810 75:811 76:812 77:812 78:813 79:814 80:814 81:815 82:816 83:816 84:816 85:817 86:818 87:819 88:820 89:821 90:822 91:823 92:824 93:824 94:825 95:826 96:826 97:827 98:828 99:829 100:829 101:830 102:831 103:832 104:833 105:834 106:835 107:836 108:837 109:837 110:837 111:837 112:838 113:838 114:838 115:838 116:838 117:839 118:840 119:841 120:841 121:842 122:843 123:844 124:845 125:846 126:847 127:847 128:847 129:847 130:848 131:849 132:850 133:851 134:852 135:852 136:852 137:853 138:854 139:854 140:854 141:854 142:855 143:856 144:856 145:857 146:858 147:859 148:860 149:860 150:860 151:860 152:861 153:862 154:863 155:864 156:865 157:866 158:867 159:867 160:868 161:869 162:870 163:871 164:872 165:873 166:874 167:875 168:876 169:877 170:878 171:879 172:879 173:880 174:881 175:882 176:882 177:883 178:884 179:884 180:884 181:884 182:885 183:885 184:886 185:887 186:888 187:889 188:890 189:890 190:891 191:892 192:893 193:894 194:895 195:896 196:897 197:897 198:898 199:899 200:900 201:901 202:902 203:903 204:904 205:905 206:906 207:907 208:907 209:907 210:907 211:908 212:909 213:910 214:911 215:912 216:913 217:914 218:914 219:915 220:916 221:916 222:917 223:918 224:919 225:920 226:920 227:920 228:920 229:921 230:922 231:923 232:924 233:924 234:925 235:926 236:927 237:928 238:929 239:929 240:929 241:929 242:930 243:930 244:930 245:931 246:931 247:931 248:932 249:932 250:932 251:933 252:933 253:933 254:933 255:933 256:933 257:934 258:935 259:936 260:937 261:937 262:938 263:939 264:940 265:941 266:942 267:943 268:943 269:943 270:944 271:944 272:945 273:946 274:947 275:947 276:948 277:949 278:950 279:951 280:952 281:953 282:954 283:954 284:955 285:955 286:956 287:957 288:958 289:959 290:960 291:961 292:962 293:963 294:964 295:965 296:966 297:967 298:968 299:968 300:968 301:969 302:970 303:970 304:971 305:971 306:971 307:971 308:971 309:971 310:972 311:973 312:973 313:974 314:975 315:976 316:976 317:976 318:976 319:976 320:977 321:978 322:979 323:980 324:981 325:982 326:982 327:982 328:982 329:983 330:983 331:984 332:984 333:985 334:986 335:987 336:988 337:989 338:989 339:990 340:991 341:992 342:993 343:994 344:994 345:995 346:996 347:997 348:998 349:998 350:999 351:1000 352:1000 353:1001 354:1002 355:1002 356:1002 357:1002 358:1003 359:1003 360:1004 361:1004 362:1005 363:1006 364:1007 365:1008 366:1009 367:1010 368:1010 369:1011 370:1012 371:1012 372:1013 373:1014 374:1015 375:1016 376:1017 377:1017 378:1017 379:1017 380:1018 381:1018 382:1019\n",
            "I0703 18:12:02.815918 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:769 7:769 8:769 9:769 10:769 11:769 12:769 13:769 14:770 15:770 16:770 17:770 18:771 19:772 20:773 21:773 22:774 23:775 24:775 25:775 26:775 27:775 28:775 29:775 30:776 31:776 32:776 33:776 34:777 35:778 36:779 37:779 38:780 39:781 40:782 41:783 42:784 43:784 44:785 45:786 46:786 47:787 48:788 49:789 50:789 51:790 52:791 53:792 54:792 55:793 56:794 57:794 58:795 59:796 60:797 61:798 62:798 63:799 64:800 65:801 66:802 67:803 68:804 69:805 70:806 71:807 72:808 73:809 74:810 75:811 76:812 77:812 78:813 79:814 80:814 81:815 82:816 83:816 84:816 85:817 86:818 87:819 88:820 89:821 90:822 91:823 92:824 93:824 94:825 95:826 96:826 97:827 98:828 99:829 100:829 101:830 102:831 103:832 104:833 105:834 106:835 107:836 108:837 109:837 110:837 111:837 112:838 113:838 114:838 115:838 116:838 117:839 118:840 119:841 120:841 121:842 122:843 123:844 124:845 125:846 126:847 127:847 128:847 129:847 130:848 131:849 132:850 133:851 134:852 135:852 136:852 137:853 138:854 139:854 140:854 141:854 142:855 143:856 144:856 145:857 146:858 147:859 148:860 149:860 150:860 151:860 152:861 153:862 154:863 155:864 156:865 157:866 158:867 159:867 160:868 161:869 162:870 163:871 164:872 165:873 166:874 167:875 168:876 169:877 170:878 171:879 172:879 173:880 174:881 175:882 176:882 177:883 178:884 179:884 180:884 181:884 182:885 183:885 184:886 185:887 186:888 187:889 188:890 189:890 190:891 191:892 192:893 193:894 194:895 195:896 196:897 197:897 198:898 199:899 200:900 201:901 202:902 203:903 204:904 205:905 206:906 207:907 208:907 209:907 210:907 211:908 212:909 213:910 214:911 215:912 216:913 217:914 218:914 219:915 220:916 221:916 222:917 223:918 224:919 225:920 226:920 227:920 228:920 229:921 230:922 231:923 232:924 233:924 234:925 235:926 236:927 237:928 238:929 239:929 240:929 241:929 242:930 243:930 244:930 245:931 246:931 247:931 248:932 249:932 250:932 251:933 252:933 253:933 254:933 255:933 256:933 257:934 258:935 259:936 260:937 261:937 262:938 263:939 264:940 265:941 266:942 267:943 268:943 269:943 270:944 271:944 272:945 273:946 274:947 275:947 276:948 277:949 278:950 279:951 280:952 281:953 282:954 283:954 284:955 285:955 286:956 287:957 288:958 289:959 290:960 291:961 292:962 293:963 294:964 295:965 296:966 297:967 298:968 299:968 300:968 301:969 302:970 303:970 304:971 305:971 306:971 307:971 308:971 309:971 310:972 311:973 312:973 313:974 314:975 315:976 316:976 317:976 318:976 319:976 320:977 321:978 322:979 323:980 324:981 325:982 326:982 327:982 328:982 329:983 330:983 331:984 332:984 333:985 334:986 335:987 336:988 337:989 338:989 339:990 340:991 341:992 342:993 343:994 344:994 345:995 346:996 347:997 348:998 349:998 350:999 351:1000 352:1000 353:1001 354:1002 355:1002 356:1002 357:1002 358:1003 359:1003 360:1004 361:1004 362:1005 363:1006 364:1007 365:1008 366:1009 367:1010 368:1010 369:1011 370:1012 371:1012 372:1013 373:1014 374:1015 375:1016 376:1017 377:1017 378:1017 379:1017 380:1018 381:1018 382:1019\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.816430 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 102\n",
            "I0703 18:12:02.816866 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.817185 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.817495 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.820773 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000023\n",
            "I0703 18:12:02.820940 139789930788736 set_essential_params.py:432] unique_id: 1000000023\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.821035 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 9\n",
            "I0703 18:12:02.821123 139789930788736 set_essential_params.py:434] doc_span_index: 9\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually [SEP]\n",
            "I0703 18:12:02.821346 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:852 7:852 8:852 9:853 10:854 11:854 12:854 13:854 14:855 15:856 16:856 17:857 18:858 19:859 20:860 21:860 22:860 23:860 24:861 25:862 26:863 27:864 28:865 29:866 30:867 31:867 32:868 33:869 34:870 35:871 36:872 37:873 38:874 39:875 40:876 41:877 42:878 43:879 44:879 45:880 46:881 47:882 48:882 49:883 50:884 51:884 52:884 53:884 54:885 55:885 56:886 57:887 58:888 59:889 60:890 61:890 62:891 63:892 64:893 65:894 66:895 67:896 68:897 69:897 70:898 71:899 72:900 73:901 74:902 75:903 76:904 77:905 78:906 79:907 80:907 81:907 82:907 83:908 84:909 85:910 86:911 87:912 88:913 89:914 90:914 91:915 92:916 93:916 94:917 95:918 96:919 97:920 98:920 99:920 100:920 101:921 102:922 103:923 104:924 105:924 106:925 107:926 108:927 109:928 110:929 111:929 112:929 113:929 114:930 115:930 116:930 117:931 118:931 119:931 120:932 121:932 122:932 123:933 124:933 125:933 126:933 127:933 128:933 129:934 130:935 131:936 132:937 133:937 134:938 135:939 136:940 137:941 138:942 139:943 140:943 141:943 142:944 143:944 144:945 145:946 146:947 147:947 148:948 149:949 150:950 151:951 152:952 153:953 154:954 155:954 156:955 157:955 158:956 159:957 160:958 161:959 162:960 163:961 164:962 165:963 166:964 167:965 168:966 169:967 170:968 171:968 172:968 173:969 174:970 175:970 176:971 177:971 178:971 179:971 180:971 181:971 182:972 183:973 184:973 185:974 186:975 187:976 188:976 189:976 190:976 191:976 192:977 193:978 194:979 195:980 196:981 197:982 198:982 199:982 200:982 201:983 202:983 203:984 204:984 205:985 206:986 207:987 208:988 209:989 210:989 211:990 212:991 213:992 214:993 215:994 216:994 217:995 218:996 219:997 220:998 221:998 222:999 223:1000 224:1000 225:1001 226:1002 227:1002 228:1002 229:1002 230:1003 231:1003 232:1004 233:1004 234:1005 235:1006 236:1007 237:1008 238:1009 239:1010 240:1010 241:1011 242:1012 243:1012 244:1013 245:1014 246:1015 247:1016 248:1017 249:1017 250:1017 251:1017 252:1018 253:1018 254:1019 255:1020 256:1021 257:1022 258:1023 259:1024 260:1024 261:1025 262:1026 263:1027 264:1028 265:1028 266:1029 267:1029 268:1030 269:1031 270:1032 271:1033 272:1034 273:1034 274:1034 275:1035 276:1036 277:1036 278:1037 279:1038 280:1039 281:1039 282:1040 283:1041 284:1042 285:1043 286:1044 287:1045 288:1046 289:1046 290:1047 291:1047 292:1047 293:1047 294:1048 295:1048 296:1049 297:1050 298:1051 299:1052 300:1053 301:1054 302:1054 303:1055 304:1056 305:1057 306:1057 307:1058 308:1059 309:1060 310:1061 311:1062 312:1063 313:1064 314:1065 315:1066 316:1066 317:1067 318:1067 319:1068 320:1069 321:1070 322:1071 323:1071 324:1072 325:1072 326:1073 327:1074 328:1075 329:1076 330:1077 331:1078 332:1079 333:1080 334:1080 335:1081 336:1081 337:1081 338:1082 339:1083 340:1084 341:1085 342:1086 343:1087 344:1088 345:1089 346:1090 347:1090 348:1091 349:1091 350:1092 351:1093 352:1093 353:1094 354:1095 355:1096 356:1097 357:1097 358:1097 359:1098 360:1099 361:1100 362:1100 363:1101 364:1101 365:1102 366:1103 367:1104 368:1105 369:1105 370:1106 371:1107 372:1108 373:1108 374:1108 375:1109 376:1110 377:1111 378:1111 379:1111 380:1112 381:1112 382:1113\n",
            "I0703 18:12:02.917502 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:852 7:852 8:852 9:853 10:854 11:854 12:854 13:854 14:855 15:856 16:856 17:857 18:858 19:859 20:860 21:860 22:860 23:860 24:861 25:862 26:863 27:864 28:865 29:866 30:867 31:867 32:868 33:869 34:870 35:871 36:872 37:873 38:874 39:875 40:876 41:877 42:878 43:879 44:879 45:880 46:881 47:882 48:882 49:883 50:884 51:884 52:884 53:884 54:885 55:885 56:886 57:887 58:888 59:889 60:890 61:890 62:891 63:892 64:893 65:894 66:895 67:896 68:897 69:897 70:898 71:899 72:900 73:901 74:902 75:903 76:904 77:905 78:906 79:907 80:907 81:907 82:907 83:908 84:909 85:910 86:911 87:912 88:913 89:914 90:914 91:915 92:916 93:916 94:917 95:918 96:919 97:920 98:920 99:920 100:920 101:921 102:922 103:923 104:924 105:924 106:925 107:926 108:927 109:928 110:929 111:929 112:929 113:929 114:930 115:930 116:930 117:931 118:931 119:931 120:932 121:932 122:932 123:933 124:933 125:933 126:933 127:933 128:933 129:934 130:935 131:936 132:937 133:937 134:938 135:939 136:940 137:941 138:942 139:943 140:943 141:943 142:944 143:944 144:945 145:946 146:947 147:947 148:948 149:949 150:950 151:951 152:952 153:953 154:954 155:954 156:955 157:955 158:956 159:957 160:958 161:959 162:960 163:961 164:962 165:963 166:964 167:965 168:966 169:967 170:968 171:968 172:968 173:969 174:970 175:970 176:971 177:971 178:971 179:971 180:971 181:971 182:972 183:973 184:973 185:974 186:975 187:976 188:976 189:976 190:976 191:976 192:977 193:978 194:979 195:980 196:981 197:982 198:982 199:982 200:982 201:983 202:983 203:984 204:984 205:985 206:986 207:987 208:988 209:989 210:989 211:990 212:991 213:992 214:993 215:994 216:994 217:995 218:996 219:997 220:998 221:998 222:999 223:1000 224:1000 225:1001 226:1002 227:1002 228:1002 229:1002 230:1003 231:1003 232:1004 233:1004 234:1005 235:1006 236:1007 237:1008 238:1009 239:1010 240:1010 241:1011 242:1012 243:1012 244:1013 245:1014 246:1015 247:1016 248:1017 249:1017 250:1017 251:1017 252:1018 253:1018 254:1019 255:1020 256:1021 257:1022 258:1023 259:1024 260:1024 261:1025 262:1026 263:1027 264:1028 265:1028 266:1029 267:1029 268:1030 269:1031 270:1032 271:1033 272:1034 273:1034 274:1034 275:1035 276:1036 277:1036 278:1037 279:1038 280:1039 281:1039 282:1040 283:1041 284:1042 285:1043 286:1044 287:1045 288:1046 289:1046 290:1047 291:1047 292:1047 293:1047 294:1048 295:1048 296:1049 297:1050 298:1051 299:1052 300:1053 301:1054 302:1054 303:1055 304:1056 305:1057 306:1057 307:1058 308:1059 309:1060 310:1061 311:1062 312:1063 313:1064 314:1065 315:1066 316:1066 317:1067 318:1067 319:1068 320:1069 321:1070 322:1071 323:1071 324:1072 325:1072 326:1073 327:1074 328:1075 329:1076 330:1077 331:1078 332:1079 333:1080 334:1080 335:1081 336:1081 337:1081 338:1082 339:1083 340:1084 341:1085 342:1086 343:1087 344:1088 345:1089 346:1090 347:1090 348:1091 349:1091 350:1092 351:1093 352:1093 353:1094 354:1095 355:1096 356:1097 357:1097 358:1097 359:1098 360:1099 361:1100 362:1100 363:1101 364:1101 365:1102 366:1103 367:1104 368:1105 369:1105 370:1106 371:1107 372:1108 373:1108 374:1108 375:1109 376:1110 377:1111 378:1111 379:1111 380:1112 381:1112 382:1113\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:02.917983 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 102\n",
            "I0703 18:12:02.918375 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.918676 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:02.918960 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:02.925769 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000024\n",
            "I0703 18:12:02.926030 139789930788736 set_essential_params.py:432] unique_id: 1000000024\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:02.926162 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 10\n",
            "I0703 18:12:02.926251 139789930788736 set_essential_params.py:434] doc_span_index: 10\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house [SEP]\n",
            "I0703 18:12:02.926573 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:938 7:939 8:940 9:941 10:942 11:943 12:943 13:943 14:944 15:944 16:945 17:946 18:947 19:947 20:948 21:949 22:950 23:951 24:952 25:953 26:954 27:954 28:955 29:955 30:956 31:957 32:958 33:959 34:960 35:961 36:962 37:963 38:964 39:965 40:966 41:967 42:968 43:968 44:968 45:969 46:970 47:970 48:971 49:971 50:971 51:971 52:971 53:971 54:972 55:973 56:973 57:974 58:975 59:976 60:976 61:976 62:976 63:976 64:977 65:978 66:979 67:980 68:981 69:982 70:982 71:982 72:982 73:983 74:983 75:984 76:984 77:985 78:986 79:987 80:988 81:989 82:989 83:990 84:991 85:992 86:993 87:994 88:994 89:995 90:996 91:997 92:998 93:998 94:999 95:1000 96:1000 97:1001 98:1002 99:1002 100:1002 101:1002 102:1003 103:1003 104:1004 105:1004 106:1005 107:1006 108:1007 109:1008 110:1009 111:1010 112:1010 113:1011 114:1012 115:1012 116:1013 117:1014 118:1015 119:1016 120:1017 121:1017 122:1017 123:1017 124:1018 125:1018 126:1019 127:1020 128:1021 129:1022 130:1023 131:1024 132:1024 133:1025 134:1026 135:1027 136:1028 137:1028 138:1029 139:1029 140:1030 141:1031 142:1032 143:1033 144:1034 145:1034 146:1034 147:1035 148:1036 149:1036 150:1037 151:1038 152:1039 153:1039 154:1040 155:1041 156:1042 157:1043 158:1044 159:1045 160:1046 161:1046 162:1047 163:1047 164:1047 165:1047 166:1048 167:1048 168:1049 169:1050 170:1051 171:1052 172:1053 173:1054 174:1054 175:1055 176:1056 177:1057 178:1057 179:1058 180:1059 181:1060 182:1061 183:1062 184:1063 185:1064 186:1065 187:1066 188:1066 189:1067 190:1067 191:1068 192:1069 193:1070 194:1071 195:1071 196:1072 197:1072 198:1073 199:1074 200:1075 201:1076 202:1077 203:1078 204:1079 205:1080 206:1080 207:1081 208:1081 209:1081 210:1082 211:1083 212:1084 213:1085 214:1086 215:1087 216:1088 217:1089 218:1090 219:1090 220:1091 221:1091 222:1092 223:1093 224:1093 225:1094 226:1095 227:1096 228:1097 229:1097 230:1097 231:1098 232:1099 233:1100 234:1100 235:1101 236:1101 237:1102 238:1103 239:1104 240:1105 241:1105 242:1106 243:1107 244:1108 245:1108 246:1108 247:1109 248:1110 249:1111 250:1111 251:1111 252:1112 253:1112 254:1113 255:1114 256:1115 257:1115 258:1116 259:1117 260:1118 261:1119 262:1120 263:1121 264:1122 265:1122 266:1123 267:1124 268:1124 269:1124 270:1124 271:1125 272:1126 273:1126 274:1126 275:1127 276:1128 277:1129 278:1130 279:1130 280:1130 281:1131 282:1132 283:1133 284:1134 285:1134 286:1134 287:1134 288:1135 289:1136 290:1137 291:1138 292:1139 293:1139 294:1140 295:1141 296:1141 297:1142 298:1143 299:1144 300:1145 301:1146 302:1147 303:1148 304:1149 305:1150 306:1151 307:1151 308:1151 309:1152 310:1153 311:1154 312:1155 313:1155 314:1155 315:1156 316:1157 317:1158 318:1159 319:1160 320:1160 321:1161 322:1161 323:1161 324:1161 325:1161 326:1162 327:1162 328:1163 329:1164 330:1165 331:1165 332:1166 333:1167 334:1168 335:1169 336:1170 337:1171 338:1172 339:1173 340:1174 341:1175 342:1175 343:1176 344:1177 345:1178 346:1178 347:1179 348:1180 349:1181 350:1182 351:1182 352:1182 353:1182 354:1183 355:1184 356:1185 357:1186 358:1187 359:1188 360:1189 361:1190 362:1191 363:1192 364:1193 365:1194 366:1195 367:1196 368:1197 369:1198 370:1199 371:1200 372:1201 373:1202 374:1202 375:1203 376:1204 377:1204 378:1205 379:1206 380:1207 381:1207 382:1207\n",
            "I0703 18:12:03.021163 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:938 7:939 8:940 9:941 10:942 11:943 12:943 13:943 14:944 15:944 16:945 17:946 18:947 19:947 20:948 21:949 22:950 23:951 24:952 25:953 26:954 27:954 28:955 29:955 30:956 31:957 32:958 33:959 34:960 35:961 36:962 37:963 38:964 39:965 40:966 41:967 42:968 43:968 44:968 45:969 46:970 47:970 48:971 49:971 50:971 51:971 52:971 53:971 54:972 55:973 56:973 57:974 58:975 59:976 60:976 61:976 62:976 63:976 64:977 65:978 66:979 67:980 68:981 69:982 70:982 71:982 72:982 73:983 74:983 75:984 76:984 77:985 78:986 79:987 80:988 81:989 82:989 83:990 84:991 85:992 86:993 87:994 88:994 89:995 90:996 91:997 92:998 93:998 94:999 95:1000 96:1000 97:1001 98:1002 99:1002 100:1002 101:1002 102:1003 103:1003 104:1004 105:1004 106:1005 107:1006 108:1007 109:1008 110:1009 111:1010 112:1010 113:1011 114:1012 115:1012 116:1013 117:1014 118:1015 119:1016 120:1017 121:1017 122:1017 123:1017 124:1018 125:1018 126:1019 127:1020 128:1021 129:1022 130:1023 131:1024 132:1024 133:1025 134:1026 135:1027 136:1028 137:1028 138:1029 139:1029 140:1030 141:1031 142:1032 143:1033 144:1034 145:1034 146:1034 147:1035 148:1036 149:1036 150:1037 151:1038 152:1039 153:1039 154:1040 155:1041 156:1042 157:1043 158:1044 159:1045 160:1046 161:1046 162:1047 163:1047 164:1047 165:1047 166:1048 167:1048 168:1049 169:1050 170:1051 171:1052 172:1053 173:1054 174:1054 175:1055 176:1056 177:1057 178:1057 179:1058 180:1059 181:1060 182:1061 183:1062 184:1063 185:1064 186:1065 187:1066 188:1066 189:1067 190:1067 191:1068 192:1069 193:1070 194:1071 195:1071 196:1072 197:1072 198:1073 199:1074 200:1075 201:1076 202:1077 203:1078 204:1079 205:1080 206:1080 207:1081 208:1081 209:1081 210:1082 211:1083 212:1084 213:1085 214:1086 215:1087 216:1088 217:1089 218:1090 219:1090 220:1091 221:1091 222:1092 223:1093 224:1093 225:1094 226:1095 227:1096 228:1097 229:1097 230:1097 231:1098 232:1099 233:1100 234:1100 235:1101 236:1101 237:1102 238:1103 239:1104 240:1105 241:1105 242:1106 243:1107 244:1108 245:1108 246:1108 247:1109 248:1110 249:1111 250:1111 251:1111 252:1112 253:1112 254:1113 255:1114 256:1115 257:1115 258:1116 259:1117 260:1118 261:1119 262:1120 263:1121 264:1122 265:1122 266:1123 267:1124 268:1124 269:1124 270:1124 271:1125 272:1126 273:1126 274:1126 275:1127 276:1128 277:1129 278:1130 279:1130 280:1130 281:1131 282:1132 283:1133 284:1134 285:1134 286:1134 287:1134 288:1135 289:1136 290:1137 291:1138 292:1139 293:1139 294:1140 295:1141 296:1141 297:1142 298:1143 299:1144 300:1145 301:1146 302:1147 303:1148 304:1149 305:1150 306:1151 307:1151 308:1151 309:1152 310:1153 311:1154 312:1155 313:1155 314:1155 315:1156 316:1157 317:1158 318:1159 319:1160 320:1160 321:1161 322:1161 323:1161 324:1161 325:1161 326:1162 327:1162 328:1163 329:1164 330:1165 331:1165 332:1166 333:1167 334:1168 335:1169 336:1170 337:1171 338:1172 339:1173 340:1174 341:1175 342:1175 343:1176 344:1177 345:1178 346:1178 347:1179 348:1180 349:1181 350:1182 351:1182 352:1182 353:1182 354:1183 355:1184 356:1185 357:1186 358:1187 359:1188 360:1189 361:1190 362:1191 363:1192 364:1193 365:1194 366:1195 367:1196 368:1197 369:1198 370:1199 371:1200 372:1201 373:1202 374:1202 375:1203 376:1204 377:1204 378:1205 379:1206 380:1207 381:1207 382:1207\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.021453 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 102\n",
            "I0703 18:12:03.021672 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.123090 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.123349 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.126881 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000025\n",
            "I0703 18:12:03.127111 139789930788736 set_essential_params.py:432] unique_id: 1000000025\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:03.127183 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 11\n",
            "I0703 18:12:03.127247 139789930788736 set_essential_params.py:434] doc_span_index: 11\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor [SEP]\n",
            "I0703 18:12:03.127508 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:1026 7:1027 8:1028 9:1028 10:1029 11:1029 12:1030 13:1031 14:1032 15:1033 16:1034 17:1034 18:1034 19:1035 20:1036 21:1036 22:1037 23:1038 24:1039 25:1039 26:1040 27:1041 28:1042 29:1043 30:1044 31:1045 32:1046 33:1046 34:1047 35:1047 36:1047 37:1047 38:1048 39:1048 40:1049 41:1050 42:1051 43:1052 44:1053 45:1054 46:1054 47:1055 48:1056 49:1057 50:1057 51:1058 52:1059 53:1060 54:1061 55:1062 56:1063 57:1064 58:1065 59:1066 60:1066 61:1067 62:1067 63:1068 64:1069 65:1070 66:1071 67:1071 68:1072 69:1072 70:1073 71:1074 72:1075 73:1076 74:1077 75:1078 76:1079 77:1080 78:1080 79:1081 80:1081 81:1081 82:1082 83:1083 84:1084 85:1085 86:1086 87:1087 88:1088 89:1089 90:1090 91:1090 92:1091 93:1091 94:1092 95:1093 96:1093 97:1094 98:1095 99:1096 100:1097 101:1097 102:1097 103:1098 104:1099 105:1100 106:1100 107:1101 108:1101 109:1102 110:1103 111:1104 112:1105 113:1105 114:1106 115:1107 116:1108 117:1108 118:1108 119:1109 120:1110 121:1111 122:1111 123:1111 124:1112 125:1112 126:1113 127:1114 128:1115 129:1115 130:1116 131:1117 132:1118 133:1119 134:1120 135:1121 136:1122 137:1122 138:1123 139:1124 140:1124 141:1124 142:1124 143:1125 144:1126 145:1126 146:1126 147:1127 148:1128 149:1129 150:1130 151:1130 152:1130 153:1131 154:1132 155:1133 156:1134 157:1134 158:1134 159:1134 160:1135 161:1136 162:1137 163:1138 164:1139 165:1139 166:1140 167:1141 168:1141 169:1142 170:1143 171:1144 172:1145 173:1146 174:1147 175:1148 176:1149 177:1150 178:1151 179:1151 180:1151 181:1152 182:1153 183:1154 184:1155 185:1155 186:1155 187:1156 188:1157 189:1158 190:1159 191:1160 192:1160 193:1161 194:1161 195:1161 196:1161 197:1161 198:1162 199:1162 200:1163 201:1164 202:1165 203:1165 204:1166 205:1167 206:1168 207:1169 208:1170 209:1171 210:1172 211:1173 212:1174 213:1175 214:1175 215:1176 216:1177 217:1178 218:1178 219:1179 220:1180 221:1181 222:1182 223:1182 224:1182 225:1182 226:1183 227:1184 228:1185 229:1186 230:1187 231:1188 232:1189 233:1190 234:1191 235:1192 236:1193 237:1194 238:1195 239:1196 240:1197 241:1198 242:1199 243:1200 244:1201 245:1202 246:1202 247:1203 248:1204 249:1204 250:1205 251:1206 252:1207 253:1207 254:1207 255:1208 256:1209 257:1210 258:1211 259:1212 260:1213 261:1213 262:1213 263:1213 264:1214 265:1215 266:1216 267:1217 268:1218 269:1219 270:1220 271:1221 272:1222 273:1223 274:1224 275:1225 276:1226 277:1227 278:1228 279:1229 280:1230 281:1231 282:1231 283:1232 284:1233 285:1233 286:1234 287:1234 288:1235 289:1236 290:1237 291:1238 292:1239 293:1240 294:1241 295:1242 296:1243 297:1244 298:1245 299:1245 300:1245 301:1246 302:1246 303:1247 304:1248 305:1248 306:1248 307:1248 308:1249 309:1250 310:1251 311:1252 312:1253 313:1254 314:1255 315:1256 316:1257 317:1257 318:1258 319:1259 320:1259 321:1259 322:1259 323:1260 324:1261 325:1262 326:1263 327:1263 328:1264 329:1264 330:1265 331:1265 332:1265 333:1266 334:1267 335:1268 336:1268 337:1269 338:1270 339:1271 340:1272 341:1272 342:1273 343:1274 344:1275 345:1276 346:1277 347:1277 348:1277 349:1277 350:1278 351:1278 352:1279 353:1280 354:1281 355:1282 356:1282 357:1283 358:1284 359:1284 360:1285 361:1285 362:1285 363:1285 364:1286 365:1287 366:1288 367:1289 368:1290 369:1290 370:1291 371:1292 372:1293 373:1293 374:1294 375:1295 376:1296 377:1297 378:1298 379:1299 380:1300 381:1301 382:1301\n",
            "I0703 18:12:03.127734 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:1026 7:1027 8:1028 9:1028 10:1029 11:1029 12:1030 13:1031 14:1032 15:1033 16:1034 17:1034 18:1034 19:1035 20:1036 21:1036 22:1037 23:1038 24:1039 25:1039 26:1040 27:1041 28:1042 29:1043 30:1044 31:1045 32:1046 33:1046 34:1047 35:1047 36:1047 37:1047 38:1048 39:1048 40:1049 41:1050 42:1051 43:1052 44:1053 45:1054 46:1054 47:1055 48:1056 49:1057 50:1057 51:1058 52:1059 53:1060 54:1061 55:1062 56:1063 57:1064 58:1065 59:1066 60:1066 61:1067 62:1067 63:1068 64:1069 65:1070 66:1071 67:1071 68:1072 69:1072 70:1073 71:1074 72:1075 73:1076 74:1077 75:1078 76:1079 77:1080 78:1080 79:1081 80:1081 81:1081 82:1082 83:1083 84:1084 85:1085 86:1086 87:1087 88:1088 89:1089 90:1090 91:1090 92:1091 93:1091 94:1092 95:1093 96:1093 97:1094 98:1095 99:1096 100:1097 101:1097 102:1097 103:1098 104:1099 105:1100 106:1100 107:1101 108:1101 109:1102 110:1103 111:1104 112:1105 113:1105 114:1106 115:1107 116:1108 117:1108 118:1108 119:1109 120:1110 121:1111 122:1111 123:1111 124:1112 125:1112 126:1113 127:1114 128:1115 129:1115 130:1116 131:1117 132:1118 133:1119 134:1120 135:1121 136:1122 137:1122 138:1123 139:1124 140:1124 141:1124 142:1124 143:1125 144:1126 145:1126 146:1126 147:1127 148:1128 149:1129 150:1130 151:1130 152:1130 153:1131 154:1132 155:1133 156:1134 157:1134 158:1134 159:1134 160:1135 161:1136 162:1137 163:1138 164:1139 165:1139 166:1140 167:1141 168:1141 169:1142 170:1143 171:1144 172:1145 173:1146 174:1147 175:1148 176:1149 177:1150 178:1151 179:1151 180:1151 181:1152 182:1153 183:1154 184:1155 185:1155 186:1155 187:1156 188:1157 189:1158 190:1159 191:1160 192:1160 193:1161 194:1161 195:1161 196:1161 197:1161 198:1162 199:1162 200:1163 201:1164 202:1165 203:1165 204:1166 205:1167 206:1168 207:1169 208:1170 209:1171 210:1172 211:1173 212:1174 213:1175 214:1175 215:1176 216:1177 217:1178 218:1178 219:1179 220:1180 221:1181 222:1182 223:1182 224:1182 225:1182 226:1183 227:1184 228:1185 229:1186 230:1187 231:1188 232:1189 233:1190 234:1191 235:1192 236:1193 237:1194 238:1195 239:1196 240:1197 241:1198 242:1199 243:1200 244:1201 245:1202 246:1202 247:1203 248:1204 249:1204 250:1205 251:1206 252:1207 253:1207 254:1207 255:1208 256:1209 257:1210 258:1211 259:1212 260:1213 261:1213 262:1213 263:1213 264:1214 265:1215 266:1216 267:1217 268:1218 269:1219 270:1220 271:1221 272:1222 273:1223 274:1224 275:1225 276:1226 277:1227 278:1228 279:1229 280:1230 281:1231 282:1231 283:1232 284:1233 285:1233 286:1234 287:1234 288:1235 289:1236 290:1237 291:1238 292:1239 293:1240 294:1241 295:1242 296:1243 297:1244 298:1245 299:1245 300:1245 301:1246 302:1246 303:1247 304:1248 305:1248 306:1248 307:1248 308:1249 309:1250 310:1251 311:1252 312:1253 313:1254 314:1255 315:1256 316:1257 317:1257 318:1258 319:1259 320:1259 321:1259 322:1259 323:1260 324:1261 325:1262 326:1263 327:1263 328:1264 329:1264 330:1265 331:1265 332:1265 333:1266 334:1267 335:1268 336:1268 337:1269 338:1270 339:1271 340:1272 341:1272 342:1273 343:1274 344:1275 345:1276 346:1277 347:1277 348:1277 349:1277 350:1278 351:1278 352:1279 353:1280 354:1281 355:1282 356:1282 357:1283 358:1284 359:1284 360:1285 361:1285 362:1285 363:1285 364:1286 365:1287 366:1288 367:1289 368:1290 369:1290 370:1291 371:1292 372:1293 373:1293 374:1294 375:1295 376:1296 377:1297 378:1298 379:1299 380:1300 381:1301 382:1301\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.226035 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 102\n",
            "I0703 18:12:03.226504 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.226779 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.324206 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.327273 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000026\n",
            "I0703 18:12:03.327481 139789930788736 set_essential_params.py:432] unique_id: 1000000026\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:03.327546 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 12\n",
            "I0703 18:12:03.327601 139789930788736 set_essential_params.py:434] doc_span_index: 12\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at [SEP]\n",
            "I0703 18:12:03.327765 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:1120 7:1121 8:1122 9:1122 10:1123 11:1124 12:1124 13:1124 14:1124 15:1125 16:1126 17:1126 18:1126 19:1127 20:1128 21:1129 22:1130 23:1130 24:1130 25:1131 26:1132 27:1133 28:1134 29:1134 30:1134 31:1134 32:1135 33:1136 34:1137 35:1138 36:1139 37:1139 38:1140 39:1141 40:1141 41:1142 42:1143 43:1144 44:1145 45:1146 46:1147 47:1148 48:1149 49:1150 50:1151 51:1151 52:1151 53:1152 54:1153 55:1154 56:1155 57:1155 58:1155 59:1156 60:1157 61:1158 62:1159 63:1160 64:1160 65:1161 66:1161 67:1161 68:1161 69:1161 70:1162 71:1162 72:1163 73:1164 74:1165 75:1165 76:1166 77:1167 78:1168 79:1169 80:1170 81:1171 82:1172 83:1173 84:1174 85:1175 86:1175 87:1176 88:1177 89:1178 90:1178 91:1179 92:1180 93:1181 94:1182 95:1182 96:1182 97:1182 98:1183 99:1184 100:1185 101:1186 102:1187 103:1188 104:1189 105:1190 106:1191 107:1192 108:1193 109:1194 110:1195 111:1196 112:1197 113:1198 114:1199 115:1200 116:1201 117:1202 118:1202 119:1203 120:1204 121:1204 122:1205 123:1206 124:1207 125:1207 126:1207 127:1208 128:1209 129:1210 130:1211 131:1212 132:1213 133:1213 134:1213 135:1213 136:1214 137:1215 138:1216 139:1217 140:1218 141:1219 142:1220 143:1221 144:1222 145:1223 146:1224 147:1225 148:1226 149:1227 150:1228 151:1229 152:1230 153:1231 154:1231 155:1232 156:1233 157:1233 158:1234 159:1234 160:1235 161:1236 162:1237 163:1238 164:1239 165:1240 166:1241 167:1242 168:1243 169:1244 170:1245 171:1245 172:1245 173:1246 174:1246 175:1247 176:1248 177:1248 178:1248 179:1248 180:1249 181:1250 182:1251 183:1252 184:1253 185:1254 186:1255 187:1256 188:1257 189:1257 190:1258 191:1259 192:1259 193:1259 194:1259 195:1260 196:1261 197:1262 198:1263 199:1263 200:1264 201:1264 202:1265 203:1265 204:1265 205:1266 206:1267 207:1268 208:1268 209:1269 210:1270 211:1271 212:1272 213:1272 214:1273 215:1274 216:1275 217:1276 218:1277 219:1277 220:1277 221:1277 222:1278 223:1278 224:1279 225:1280 226:1281 227:1282 228:1282 229:1283 230:1284 231:1284 232:1285 233:1285 234:1285 235:1285 236:1286 237:1287 238:1288 239:1289 240:1290 241:1290 242:1291 243:1292 244:1293 245:1293 246:1294 247:1295 248:1296 249:1297 250:1298 251:1299 252:1300 253:1301 254:1301 255:1302 256:1302 257:1302 258:1303 259:1304 260:1304 261:1305 262:1306 263:1307 264:1308 265:1309 266:1310 267:1311 268:1312 269:1313 270:1313 271:1314 272:1315 273:1316 274:1316 275:1317 276:1318 277:1319 278:1320 279:1321 280:1322 281:1323 282:1323 283:1324 284:1325 285:1326 286:1326 287:1327 288:1327 289:1327 290:1327 291:1327 292:1327 293:1328 294:1329 295:1330 296:1331 297:1331 298:1332 299:1333 300:1334 301:1335 302:1335 303:1336 304:1337 305:1338 306:1339 307:1340 308:1340 309:1341 310:1342 311:1343 312:1344 313:1344 314:1345 315:1345 316:1346 317:1346 318:1346 319:1347 320:1347 321:1348 322:1349 323:1350 324:1351 325:1352 326:1353 327:1354 328:1355 329:1355 330:1356 331:1357 332:1357 333:1358 334:1358 335:1359 336:1359 337:1359 338:1360 339:1360 340:1361 341:1362 342:1363 343:1364 344:1365 345:1366 346:1367 347:1368 348:1369 349:1370 350:1370 351:1371 352:1371 353:1372 354:1372 355:1372 356:1373 357:1373 358:1374 359:1374 360:1374 361:1375 362:1376 363:1377 364:1378 365:1379 366:1380 367:1381 368:1382 369:1383 370:1383 371:1384 372:1385 373:1386 374:1387 375:1388 376:1389 377:1390 378:1391 379:1392 380:1393 381:1394 382:1395\n",
            "I0703 18:12:03.329183 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:1120 7:1121 8:1122 9:1122 10:1123 11:1124 12:1124 13:1124 14:1124 15:1125 16:1126 17:1126 18:1126 19:1127 20:1128 21:1129 22:1130 23:1130 24:1130 25:1131 26:1132 27:1133 28:1134 29:1134 30:1134 31:1134 32:1135 33:1136 34:1137 35:1138 36:1139 37:1139 38:1140 39:1141 40:1141 41:1142 42:1143 43:1144 44:1145 45:1146 46:1147 47:1148 48:1149 49:1150 50:1151 51:1151 52:1151 53:1152 54:1153 55:1154 56:1155 57:1155 58:1155 59:1156 60:1157 61:1158 62:1159 63:1160 64:1160 65:1161 66:1161 67:1161 68:1161 69:1161 70:1162 71:1162 72:1163 73:1164 74:1165 75:1165 76:1166 77:1167 78:1168 79:1169 80:1170 81:1171 82:1172 83:1173 84:1174 85:1175 86:1175 87:1176 88:1177 89:1178 90:1178 91:1179 92:1180 93:1181 94:1182 95:1182 96:1182 97:1182 98:1183 99:1184 100:1185 101:1186 102:1187 103:1188 104:1189 105:1190 106:1191 107:1192 108:1193 109:1194 110:1195 111:1196 112:1197 113:1198 114:1199 115:1200 116:1201 117:1202 118:1202 119:1203 120:1204 121:1204 122:1205 123:1206 124:1207 125:1207 126:1207 127:1208 128:1209 129:1210 130:1211 131:1212 132:1213 133:1213 134:1213 135:1213 136:1214 137:1215 138:1216 139:1217 140:1218 141:1219 142:1220 143:1221 144:1222 145:1223 146:1224 147:1225 148:1226 149:1227 150:1228 151:1229 152:1230 153:1231 154:1231 155:1232 156:1233 157:1233 158:1234 159:1234 160:1235 161:1236 162:1237 163:1238 164:1239 165:1240 166:1241 167:1242 168:1243 169:1244 170:1245 171:1245 172:1245 173:1246 174:1246 175:1247 176:1248 177:1248 178:1248 179:1248 180:1249 181:1250 182:1251 183:1252 184:1253 185:1254 186:1255 187:1256 188:1257 189:1257 190:1258 191:1259 192:1259 193:1259 194:1259 195:1260 196:1261 197:1262 198:1263 199:1263 200:1264 201:1264 202:1265 203:1265 204:1265 205:1266 206:1267 207:1268 208:1268 209:1269 210:1270 211:1271 212:1272 213:1272 214:1273 215:1274 216:1275 217:1276 218:1277 219:1277 220:1277 221:1277 222:1278 223:1278 224:1279 225:1280 226:1281 227:1282 228:1282 229:1283 230:1284 231:1284 232:1285 233:1285 234:1285 235:1285 236:1286 237:1287 238:1288 239:1289 240:1290 241:1290 242:1291 243:1292 244:1293 245:1293 246:1294 247:1295 248:1296 249:1297 250:1298 251:1299 252:1300 253:1301 254:1301 255:1302 256:1302 257:1302 258:1303 259:1304 260:1304 261:1305 262:1306 263:1307 264:1308 265:1309 266:1310 267:1311 268:1312 269:1313 270:1313 271:1314 272:1315 273:1316 274:1316 275:1317 276:1318 277:1319 278:1320 279:1321 280:1322 281:1323 282:1323 283:1324 284:1325 285:1326 286:1326 287:1327 288:1327 289:1327 290:1327 291:1327 292:1327 293:1328 294:1329 295:1330 296:1331 297:1331 298:1332 299:1333 300:1334 301:1335 302:1335 303:1336 304:1337 305:1338 306:1339 307:1340 308:1340 309:1341 310:1342 311:1343 312:1344 313:1344 314:1345 315:1345 316:1346 317:1346 318:1346 319:1347 320:1347 321:1348 322:1349 323:1350 324:1351 325:1352 326:1353 327:1354 328:1355 329:1355 330:1356 331:1357 332:1357 333:1358 334:1358 335:1359 336:1359 337:1359 338:1360 339:1360 340:1361 341:1362 342:1363 343:1364 344:1365 345:1366 346:1367 347:1368 348:1369 349:1370 350:1370 351:1371 352:1371 353:1372 354:1372 355:1372 356:1373 357:1373 358:1374 359:1374 360:1374 361:1375 362:1376 363:1377 364:1378 365:1379 366:1380 367:1381 368:1382 369:1383 370:1383 371:1384 372:1385 373:1386 374:1387 375:1388 376:1389 377:1390 378:1391 379:1392 380:1393 381:1394 382:1395\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.329411 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 102\n",
            "I0703 18:12:03.329605 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.431425 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.431756 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.435900 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000027\n",
            "I0703 18:12:03.436827 139789930788736 set_essential_params.py:432] unique_id: 1000000027\n",
            "INFO:tensorflow:example_index: 1\n",
            "I0703 18:12:03.436941 139789930788736 set_essential_params.py:433] example_index: 1\n",
            "INFO:tensorflow:doc_span_index: 13\n",
            "I0703 18:12:03.437036 139789930788736 set_essential_params.py:434] doc_span_index: 13\n",
            "INFO:tensorflow:tokens: [CLS] who founded siemens ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "I0703 18:12:03.437255 139789930788736 set_essential_params.py:436] tokens: [CLS] who founded siemens ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 6:1213 7:1213 8:1214 9:1215 10:1216 11:1217 12:1218 13:1219 14:1220 15:1221 16:1222 17:1223 18:1224 19:1225 20:1226 21:1227 22:1228 23:1229 24:1230 25:1231 26:1231 27:1232 28:1233 29:1233 30:1234 31:1234 32:1235 33:1236 34:1237 35:1238 36:1239 37:1240 38:1241 39:1242 40:1243 41:1244 42:1245 43:1245 44:1245 45:1246 46:1246 47:1247 48:1248 49:1248 50:1248 51:1248 52:1249 53:1250 54:1251 55:1252 56:1253 57:1254 58:1255 59:1256 60:1257 61:1257 62:1258 63:1259 64:1259 65:1259 66:1259 67:1260 68:1261 69:1262 70:1263 71:1263 72:1264 73:1264 74:1265 75:1265 76:1265 77:1266 78:1267 79:1268 80:1268 81:1269 82:1270 83:1271 84:1272 85:1272 86:1273 87:1274 88:1275 89:1276 90:1277 91:1277 92:1277 93:1277 94:1278 95:1278 96:1279 97:1280 98:1281 99:1282 100:1282 101:1283 102:1284 103:1284 104:1285 105:1285 106:1285 107:1285 108:1286 109:1287 110:1288 111:1289 112:1290 113:1290 114:1291 115:1292 116:1293 117:1293 118:1294 119:1295 120:1296 121:1297 122:1298 123:1299 124:1300 125:1301 126:1301 127:1302 128:1302 129:1302 130:1303 131:1304 132:1304 133:1305 134:1306 135:1307 136:1308 137:1309 138:1310 139:1311 140:1312 141:1313 142:1313 143:1314 144:1315 145:1316 146:1316 147:1317 148:1318 149:1319 150:1320 151:1321 152:1322 153:1323 154:1323 155:1324 156:1325 157:1326 158:1326 159:1327 160:1327 161:1327 162:1327 163:1327 164:1327 165:1328 166:1329 167:1330 168:1331 169:1331 170:1332 171:1333 172:1334 173:1335 174:1335 175:1336 176:1337 177:1338 178:1339 179:1340 180:1340 181:1341 182:1342 183:1343 184:1344 185:1344 186:1345 187:1345 188:1346 189:1346 190:1346 191:1347 192:1347 193:1348 194:1349 195:1350 196:1351 197:1352 198:1353 199:1354 200:1355 201:1355 202:1356 203:1357 204:1357 205:1358 206:1358 207:1359 208:1359 209:1359 210:1360 211:1360 212:1361 213:1362 214:1363 215:1364 216:1365 217:1366 218:1367 219:1368 220:1369 221:1370 222:1370 223:1371 224:1371 225:1372 226:1372 227:1372 228:1373 229:1373 230:1374 231:1374 232:1374 233:1375 234:1376 235:1377 236:1378 237:1379 238:1380 239:1381 240:1382 241:1383 242:1383 243:1384 244:1385 245:1386 246:1387 247:1388 248:1389 249:1390 250:1391 251:1392 252:1393 253:1394 254:1395 255:1396 256:1397 257:1398 258:1398 259:1399 260:1399 261:1400 262:1401 263:1402 264:1402 265:1403 266:1404 267:1405 268:1405 269:1406 270:1407 271:1408 272:1409 273:1410 274:1411 275:1412 276:1413 277:1414 278:1414 279:1415 280:1415\n",
            "I0703 18:12:03.437477 139789930788736 set_essential_params.py:438] token_to_orig_map: 6:1213 7:1213 8:1214 9:1215 10:1216 11:1217 12:1218 13:1219 14:1220 15:1221 16:1222 17:1223 18:1224 19:1225 20:1226 21:1227 22:1228 23:1229 24:1230 25:1231 26:1231 27:1232 28:1233 29:1233 30:1234 31:1234 32:1235 33:1236 34:1237 35:1238 36:1239 37:1240 38:1241 39:1242 40:1243 41:1244 42:1245 43:1245 44:1245 45:1246 46:1246 47:1247 48:1248 49:1248 50:1248 51:1248 52:1249 53:1250 54:1251 55:1252 56:1253 57:1254 58:1255 59:1256 60:1257 61:1257 62:1258 63:1259 64:1259 65:1259 66:1259 67:1260 68:1261 69:1262 70:1263 71:1263 72:1264 73:1264 74:1265 75:1265 76:1265 77:1266 78:1267 79:1268 80:1268 81:1269 82:1270 83:1271 84:1272 85:1272 86:1273 87:1274 88:1275 89:1276 90:1277 91:1277 92:1277 93:1277 94:1278 95:1278 96:1279 97:1280 98:1281 99:1282 100:1282 101:1283 102:1284 103:1284 104:1285 105:1285 106:1285 107:1285 108:1286 109:1287 110:1288 111:1289 112:1290 113:1290 114:1291 115:1292 116:1293 117:1293 118:1294 119:1295 120:1296 121:1297 122:1298 123:1299 124:1300 125:1301 126:1301 127:1302 128:1302 129:1302 130:1303 131:1304 132:1304 133:1305 134:1306 135:1307 136:1308 137:1309 138:1310 139:1311 140:1312 141:1313 142:1313 143:1314 144:1315 145:1316 146:1316 147:1317 148:1318 149:1319 150:1320 151:1321 152:1322 153:1323 154:1323 155:1324 156:1325 157:1326 158:1326 159:1327 160:1327 161:1327 162:1327 163:1327 164:1327 165:1328 166:1329 167:1330 168:1331 169:1331 170:1332 171:1333 172:1334 173:1335 174:1335 175:1336 176:1337 177:1338 178:1339 179:1340 180:1340 181:1341 182:1342 183:1343 184:1344 185:1344 186:1345 187:1345 188:1346 189:1346 190:1346 191:1347 192:1347 193:1348 194:1349 195:1350 196:1351 197:1352 198:1353 199:1354 200:1355 201:1355 202:1356 203:1357 204:1357 205:1358 206:1358 207:1359 208:1359 209:1359 210:1360 211:1360 212:1361 213:1362 214:1363 215:1364 216:1365 217:1366 218:1367 219:1368 220:1369 221:1370 222:1370 223:1371 224:1371 225:1372 226:1372 227:1372 228:1373 229:1373 230:1374 231:1374 232:1374 233:1375 234:1376 235:1377 236:1378 237:1379 238:1380 239:1381 240:1382 241:1383 242:1383 243:1384 244:1385 245:1386 246:1387 247:1388 248:1389 249:1390 250:1391 251:1392 252:1393 253:1394 254:1395 255:1396 256:1397 257:1398 258:1398 259:1399 260:1399 261:1400 262:1401 263:1402 264:1402 265:1403 266:1404 267:1405 268:1405 269:1406 270:1407 271:1408 272:1409 273:1410 274:1411 275:1412 276:1413 277:1414 278:1414 279:1415 280:1415\n",
            "INFO:tensorflow:token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True\n",
            "I0703 18:12:03.437694 139789930788736 set_essential_params.py:440] token_is_max_context: 6:False 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True\n",
            "INFO:tensorflow:input_ids: 101 2040 2631 22108 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:03.531798 139789930788736 set_essential_params.py:442] input_ids: 101 2040 2631 22108 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:03.531998 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:03.532142 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.564336 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000028\n",
            "I0703 18:12:03.564594 139789930788736 set_essential_params.py:432] unique_id: 1000000028\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:03.564662 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:12:03.564717 139789930788736 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and [SEP]\n",
            "I0703 18:12:03.564877 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:0 8:1 9:2 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:12 22:13 23:14 24:15 25:16 26:16 27:17 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:33 46:34 47:35 48:36 49:37 50:37 51:38 52:39 53:39 54:40 55:41 56:42 57:42 58:42 59:42 60:42 61:42 62:42 63:43 64:44 65:45 66:46 67:46 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:63 87:64 88:64 89:65 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:72 99:73 100:73 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:85 115:85 116:86 117:87 118:87 119:88 120:89 121:89 122:89 123:90 124:91 125:91 126:92 127:93 128:94 129:94 130:95 131:96 132:97 133:98 134:98 135:99 136:100 137:101 138:102 139:103 140:104 141:105 142:105 143:106 144:107 145:108 146:109 147:110 148:111 149:112 150:113 151:114 152:114 153:115 154:116 155:117 156:117 157:118 158:119 159:120 160:121 161:122 162:123 163:124 164:124 165:124 166:125 167:126 168:127 169:128 170:128 171:129 172:130 173:130 174:131 175:132 176:133 177:134 178:135 179:136 180:137 181:137 182:138 183:139 184:140 185:141 186:141 187:142 188:143 189:144 190:145 191:145 192:146 193:146 194:147 195:148 196:148 197:149 198:150 199:151 200:152 201:153 202:153 203:153 204:154 205:155 206:156 207:157 208:158 209:158 210:158 211:159 212:160 213:161 214:162 215:163 216:163 217:164 218:165 219:166 220:166 221:167 222:168 223:169 224:170 225:171 226:172 227:173 228:174 229:175 230:175 231:176 232:177 233:177 234:178 235:179 236:180 237:181 238:182 239:183 240:184 241:185 242:186 243:186 244:186 245:187 246:188 247:189 248:190 249:191 250:192 251:193 252:194 253:195 254:195 255:196 256:196 257:197 258:198 259:199 260:199 261:199 262:200 263:201 264:202 265:203 266:204 267:205 268:206 269:207 270:208 271:209 272:209 273:210 274:211 275:211 276:212 277:213 278:214 279:215 280:215 281:216 282:217 283:218 284:219 285:219 286:220 287:221 288:222 289:223 290:224 291:225 292:225 293:225 294:226 295:227 296:228 297:229 298:230 299:231 300:232 301:233 302:234 303:234 304:234 305:234 306:235 307:236 308:236 309:237 310:238 311:239 312:240 313:241 314:242 315:243 316:244 317:245 318:246 319:247 320:248 321:249 322:249 323:250 324:251 325:251 326:252 327:253 328:254 329:255 330:256 331:257 332:258 333:259 334:260 335:260 336:260 337:260 338:261 339:262 340:263 341:263 342:263 343:264 344:265 345:266 346:267 347:268 348:269 349:270 350:271 351:271 352:272 353:272 354:273 355:274 356:274 357:275 358:276 359:277 360:278 361:279 362:280 363:281 364:281 365:282 366:283 367:283 368:284 369:285 370:286 371:287 372:288 373:289 374:290 375:291 376:292 377:293 378:294 379:295 380:296 381:297 382:298\n",
            "I0703 18:12:03.565063 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:0 8:1 9:2 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:12 22:13 23:14 24:15 25:16 26:16 27:17 28:18 29:19 30:20 31:20 32:21 33:22 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:32 45:33 46:34 47:35 48:36 49:37 50:37 51:38 52:39 53:39 54:40 55:41 56:42 57:42 58:42 59:42 60:42 61:42 62:42 63:43 64:44 65:45 66:46 67:46 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:63 87:64 88:64 89:65 90:65 91:66 92:67 93:67 94:68 95:69 96:70 97:71 98:72 99:73 100:73 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:85 115:85 116:86 117:87 118:87 119:88 120:89 121:89 122:89 123:90 124:91 125:91 126:92 127:93 128:94 129:94 130:95 131:96 132:97 133:98 134:98 135:99 136:100 137:101 138:102 139:103 140:104 141:105 142:105 143:106 144:107 145:108 146:109 147:110 148:111 149:112 150:113 151:114 152:114 153:115 154:116 155:117 156:117 157:118 158:119 159:120 160:121 161:122 162:123 163:124 164:124 165:124 166:125 167:126 168:127 169:128 170:128 171:129 172:130 173:130 174:131 175:132 176:133 177:134 178:135 179:136 180:137 181:137 182:138 183:139 184:140 185:141 186:141 187:142 188:143 189:144 190:145 191:145 192:146 193:146 194:147 195:148 196:148 197:149 198:150 199:151 200:152 201:153 202:153 203:153 204:154 205:155 206:156 207:157 208:158 209:158 210:158 211:159 212:160 213:161 214:162 215:163 216:163 217:164 218:165 219:166 220:166 221:167 222:168 223:169 224:170 225:171 226:172 227:173 228:174 229:175 230:175 231:176 232:177 233:177 234:178 235:179 236:180 237:181 238:182 239:183 240:184 241:185 242:186 243:186 244:186 245:187 246:188 247:189 248:190 249:191 250:192 251:193 252:194 253:195 254:195 255:196 256:196 257:197 258:198 259:199 260:199 261:199 262:200 263:201 264:202 265:203 266:204 267:205 268:206 269:207 270:208 271:209 272:209 273:210 274:211 275:211 276:212 277:213 278:214 279:215 280:215 281:216 282:217 283:218 284:219 285:219 286:220 287:221 288:222 289:223 290:224 291:225 292:225 293:225 294:226 295:227 296:228 297:229 298:230 299:231 300:232 301:233 302:234 303:234 304:234 305:234 306:235 307:236 308:236 309:237 310:238 311:239 312:240 313:241 314:242 315:243 316:244 317:245 318:246 319:247 320:248 321:249 322:249 323:250 324:251 325:251 326:252 327:253 328:254 329:255 330:256 331:257 332:258 333:259 334:260 335:260 336:260 337:260 338:261 339:262 340:263 341:263 342:263 343:264 344:265 345:266 346:267 347:268 348:269 349:270 350:271 351:271 352:272 353:272 354:273 355:274 356:274 357:275 358:276 359:277 360:278 361:279 362:280 363:281 364:281 365:282 366:283 367:283 368:284 369:285 370:286 371:287 372:288 373:289 374:290 375:291 376:292 377:293 378:294 379:295 380:296 381:297 382:298\n",
            "INFO:tensorflow:token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.635159 139789930788736 set_essential_params.py:440] token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 102\n",
            "I0703 18:12:03.635792 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.733531 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.733782 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.736662 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000029\n",
            "I0703 18:12:03.736819 139789930788736 set_essential_params.py:432] unique_id: 1000000029\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:03.736875 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "I0703 18:12:03.736922 139789930788736 set_essential_params.py:434] doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , [SEP]\n",
            "I0703 18:12:03.737081 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:99 8:100 9:101 10:102 11:103 12:104 13:105 14:105 15:106 16:107 17:108 18:109 19:110 20:111 21:112 22:113 23:114 24:114 25:115 26:116 27:117 28:117 29:118 30:119 31:120 32:121 33:122 34:123 35:124 36:124 37:124 38:125 39:126 40:127 41:128 42:128 43:129 44:130 45:130 46:131 47:132 48:133 49:134 50:135 51:136 52:137 53:137 54:138 55:139 56:140 57:141 58:141 59:142 60:143 61:144 62:145 63:145 64:146 65:146 66:147 67:148 68:148 69:149 70:150 71:151 72:152 73:153 74:153 75:153 76:154 77:155 78:156 79:157 80:158 81:158 82:158 83:159 84:160 85:161 86:162 87:163 88:163 89:164 90:165 91:166 92:166 93:167 94:168 95:169 96:170 97:171 98:172 99:173 100:174 101:175 102:175 103:176 104:177 105:177 106:178 107:179 108:180 109:181 110:182 111:183 112:184 113:185 114:186 115:186 116:186 117:187 118:188 119:189 120:190 121:191 122:192 123:193 124:194 125:195 126:195 127:196 128:196 129:197 130:198 131:199 132:199 133:199 134:200 135:201 136:202 137:203 138:204 139:205 140:206 141:207 142:208 143:209 144:209 145:210 146:211 147:211 148:212 149:213 150:214 151:215 152:215 153:216 154:217 155:218 156:219 157:219 158:220 159:221 160:222 161:223 162:224 163:225 164:225 165:225 166:226 167:227 168:228 169:229 170:230 171:231 172:232 173:233 174:234 175:234 176:234 177:234 178:235 179:236 180:236 181:237 182:238 183:239 184:240 185:241 186:242 187:243 188:244 189:245 190:246 191:247 192:248 193:249 194:249 195:250 196:251 197:251 198:252 199:253 200:254 201:255 202:256 203:257 204:258 205:259 206:260 207:260 208:260 209:260 210:261 211:262 212:263 213:263 214:263 215:264 216:265 217:266 218:267 219:268 220:269 221:270 222:271 223:271 224:272 225:272 226:273 227:274 228:274 229:275 230:276 231:277 232:278 233:279 234:280 235:281 236:281 237:282 238:283 239:283 240:284 241:285 242:286 243:287 244:288 245:289 246:290 247:291 248:292 249:293 250:294 251:295 252:296 253:297 254:298 255:299 256:300 257:301 258:302 259:302 260:303 261:304 262:304 263:305 264:306 265:307 266:308 267:309 268:310 269:311 270:312 271:313 272:314 273:315 274:315 275:316 276:317 277:318 278:319 279:320 280:321 281:321 282:322 283:323 284:324 285:325 286:326 287:327 288:328 289:329 290:330 291:331 292:332 293:333 294:334 295:335 296:336 297:337 298:338 299:338 300:339 301:340 302:341 303:341 304:342 305:342 306:343 307:344 308:344 309:345 310:346 311:347 312:348 313:348 314:349 315:350 316:351 317:352 318:353 319:354 320:355 321:356 322:357 323:357 324:357 325:357 326:358 327:359 328:359 329:359 330:360 331:361 332:362 333:363 334:364 335:365 336:365 337:365 338:365 339:365 340:365 341:365 342:366 343:367 344:367 345:368 346:369 347:369 348:370 349:371 350:371 351:372 352:373 353:373 354:373 355:373 356:373 357:373 358:373 359:374 360:375 361:375 362:375 363:376 364:377 365:378 366:379 367:380 368:380 369:380 370:381 371:382 372:383 373:384 374:385 375:386 376:387 377:388 378:389 379:389 380:390 381:391 382:391\n",
            "I0703 18:12:03.738527 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:99 8:100 9:101 10:102 11:103 12:104 13:105 14:105 15:106 16:107 17:108 18:109 19:110 20:111 21:112 22:113 23:114 24:114 25:115 26:116 27:117 28:117 29:118 30:119 31:120 32:121 33:122 34:123 35:124 36:124 37:124 38:125 39:126 40:127 41:128 42:128 43:129 44:130 45:130 46:131 47:132 48:133 49:134 50:135 51:136 52:137 53:137 54:138 55:139 56:140 57:141 58:141 59:142 60:143 61:144 62:145 63:145 64:146 65:146 66:147 67:148 68:148 69:149 70:150 71:151 72:152 73:153 74:153 75:153 76:154 77:155 78:156 79:157 80:158 81:158 82:158 83:159 84:160 85:161 86:162 87:163 88:163 89:164 90:165 91:166 92:166 93:167 94:168 95:169 96:170 97:171 98:172 99:173 100:174 101:175 102:175 103:176 104:177 105:177 106:178 107:179 108:180 109:181 110:182 111:183 112:184 113:185 114:186 115:186 116:186 117:187 118:188 119:189 120:190 121:191 122:192 123:193 124:194 125:195 126:195 127:196 128:196 129:197 130:198 131:199 132:199 133:199 134:200 135:201 136:202 137:203 138:204 139:205 140:206 141:207 142:208 143:209 144:209 145:210 146:211 147:211 148:212 149:213 150:214 151:215 152:215 153:216 154:217 155:218 156:219 157:219 158:220 159:221 160:222 161:223 162:224 163:225 164:225 165:225 166:226 167:227 168:228 169:229 170:230 171:231 172:232 173:233 174:234 175:234 176:234 177:234 178:235 179:236 180:236 181:237 182:238 183:239 184:240 185:241 186:242 187:243 188:244 189:245 190:246 191:247 192:248 193:249 194:249 195:250 196:251 197:251 198:252 199:253 200:254 201:255 202:256 203:257 204:258 205:259 206:260 207:260 208:260 209:260 210:261 211:262 212:263 213:263 214:263 215:264 216:265 217:266 218:267 219:268 220:269 221:270 222:271 223:271 224:272 225:272 226:273 227:274 228:274 229:275 230:276 231:277 232:278 233:279 234:280 235:281 236:281 237:282 238:283 239:283 240:284 241:285 242:286 243:287 244:288 245:289 246:290 247:291 248:292 249:293 250:294 251:295 252:296 253:297 254:298 255:299 256:300 257:301 258:302 259:302 260:303 261:304 262:304 263:305 264:306 265:307 266:308 267:309 268:310 269:311 270:312 271:313 272:314 273:315 274:315 275:316 276:317 277:318 278:319 279:320 280:321 281:321 282:322 283:323 284:324 285:325 286:326 287:327 288:328 289:329 290:330 291:331 292:332 293:333 294:334 295:335 296:336 297:337 298:338 299:338 300:339 301:340 302:341 303:341 304:342 305:342 306:343 307:344 308:344 309:345 310:346 311:347 312:348 313:348 314:349 315:350 316:351 317:352 318:353 319:354 320:355 321:356 322:357 323:357 324:357 325:357 326:358 327:359 328:359 329:359 330:360 331:361 332:362 333:363 334:364 335:365 336:365 337:365 338:365 339:365 340:365 341:365 342:366 343:367 344:367 345:368 346:369 347:369 348:370 349:371 350:371 351:372 352:373 353:373 354:373 355:373 356:373 357:373 358:373 359:374 360:375 361:375 362:375 363:376 364:377 365:378 366:379 367:380 368:380 369:380 370:381 371:382 372:383 373:384 374:385 375:386 376:387 377:388 378:389 379:389 380:390 381:391 382:391\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.738732 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 102\n",
            "I0703 18:12:03.738929 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.841518 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.841832 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.848937 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000030\n",
            "I0703 18:12:03.849220 139789930788736 set_essential_params.py:432] unique_id: 1000000030\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:03.849314 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "I0703 18:12:03.849388 139789930788736 set_essential_params.py:434] doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . [SEP]\n",
            "I0703 18:12:03.849683 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:201 8:202 9:203 10:204 11:205 12:206 13:207 14:208 15:209 16:209 17:210 18:211 19:211 20:212 21:213 22:214 23:215 24:215 25:216 26:217 27:218 28:219 29:219 30:220 31:221 32:222 33:223 34:224 35:225 36:225 37:225 38:226 39:227 40:228 41:229 42:230 43:231 44:232 45:233 46:234 47:234 48:234 49:234 50:235 51:236 52:236 53:237 54:238 55:239 56:240 57:241 58:242 59:243 60:244 61:245 62:246 63:247 64:248 65:249 66:249 67:250 68:251 69:251 70:252 71:253 72:254 73:255 74:256 75:257 76:258 77:259 78:260 79:260 80:260 81:260 82:261 83:262 84:263 85:263 86:263 87:264 88:265 89:266 90:267 91:268 92:269 93:270 94:271 95:271 96:272 97:272 98:273 99:274 100:274 101:275 102:276 103:277 104:278 105:279 106:280 107:281 108:281 109:282 110:283 111:283 112:284 113:285 114:286 115:287 116:288 117:289 118:290 119:291 120:292 121:293 122:294 123:295 124:296 125:297 126:298 127:299 128:300 129:301 130:302 131:302 132:303 133:304 134:304 135:305 136:306 137:307 138:308 139:309 140:310 141:311 142:312 143:313 144:314 145:315 146:315 147:316 148:317 149:318 150:319 151:320 152:321 153:321 154:322 155:323 156:324 157:325 158:326 159:327 160:328 161:329 162:330 163:331 164:332 165:333 166:334 167:335 168:336 169:337 170:338 171:338 172:339 173:340 174:341 175:341 176:342 177:342 178:343 179:344 180:344 181:345 182:346 183:347 184:348 185:348 186:349 187:350 188:351 189:352 190:353 191:354 192:355 193:356 194:357 195:357 196:357 197:357 198:358 199:359 200:359 201:359 202:360 203:361 204:362 205:363 206:364 207:365 208:365 209:365 210:365 211:365 212:365 213:365 214:366 215:367 216:367 217:368 218:369 219:369 220:370 221:371 222:371 223:372 224:373 225:373 226:373 227:373 228:373 229:373 230:373 231:374 232:375 233:375 234:375 235:376 236:377 237:378 238:379 239:380 240:380 241:380 242:381 243:382 244:383 245:384 246:385 247:386 248:387 249:388 250:389 251:389 252:390 253:391 254:391 255:392 256:393 257:394 258:395 259:396 260:397 261:398 262:399 263:400 264:401 265:402 266:402 267:403 268:403 269:403 270:404 271:404 272:405 273:406 274:407 275:408 276:409 277:410 278:411 279:411 280:412 281:413 282:414 283:415 284:416 285:416 286:417 287:418 288:419 289:420 290:421 291:422 292:423 293:423 294:424 295:425 296:425 297:426 298:427 299:428 300:428 301:428 302:429 303:430 304:430 305:431 306:431 307:431 308:432 309:432 310:432 311:433 312:434 313:434 314:435 315:435 316:435 317:435 318:435 319:435 320:436 321:436 322:436 323:437 324:438 325:438 326:438 327:438 328:438 329:438 330:439 331:440 332:440 333:440 334:440 335:440 336:440 337:440 338:440 339:441 340:441 341:442 342:442 343:442 344:443 345:444 346:445 347:446 348:447 349:447 350:447 351:447 352:447 353:447 354:447 355:448 356:449 357:449 358:449 359:449 360:449 361:450 362:451 363:452 364:453 365:454 366:454 367:454 368:455 369:456 370:457 371:458 372:459 373:460 374:461 375:462 376:463 377:464 378:464 379:464 380:465 381:466 382:466\n",
            "I0703 18:12:03.850069 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:201 8:202 9:203 10:204 11:205 12:206 13:207 14:208 15:209 16:209 17:210 18:211 19:211 20:212 21:213 22:214 23:215 24:215 25:216 26:217 27:218 28:219 29:219 30:220 31:221 32:222 33:223 34:224 35:225 36:225 37:225 38:226 39:227 40:228 41:229 42:230 43:231 44:232 45:233 46:234 47:234 48:234 49:234 50:235 51:236 52:236 53:237 54:238 55:239 56:240 57:241 58:242 59:243 60:244 61:245 62:246 63:247 64:248 65:249 66:249 67:250 68:251 69:251 70:252 71:253 72:254 73:255 74:256 75:257 76:258 77:259 78:260 79:260 80:260 81:260 82:261 83:262 84:263 85:263 86:263 87:264 88:265 89:266 90:267 91:268 92:269 93:270 94:271 95:271 96:272 97:272 98:273 99:274 100:274 101:275 102:276 103:277 104:278 105:279 106:280 107:281 108:281 109:282 110:283 111:283 112:284 113:285 114:286 115:287 116:288 117:289 118:290 119:291 120:292 121:293 122:294 123:295 124:296 125:297 126:298 127:299 128:300 129:301 130:302 131:302 132:303 133:304 134:304 135:305 136:306 137:307 138:308 139:309 140:310 141:311 142:312 143:313 144:314 145:315 146:315 147:316 148:317 149:318 150:319 151:320 152:321 153:321 154:322 155:323 156:324 157:325 158:326 159:327 160:328 161:329 162:330 163:331 164:332 165:333 166:334 167:335 168:336 169:337 170:338 171:338 172:339 173:340 174:341 175:341 176:342 177:342 178:343 179:344 180:344 181:345 182:346 183:347 184:348 185:348 186:349 187:350 188:351 189:352 190:353 191:354 192:355 193:356 194:357 195:357 196:357 197:357 198:358 199:359 200:359 201:359 202:360 203:361 204:362 205:363 206:364 207:365 208:365 209:365 210:365 211:365 212:365 213:365 214:366 215:367 216:367 217:368 218:369 219:369 220:370 221:371 222:371 223:372 224:373 225:373 226:373 227:373 228:373 229:373 230:373 231:374 232:375 233:375 234:375 235:376 236:377 237:378 238:379 239:380 240:380 241:380 242:381 243:382 244:383 245:384 246:385 247:386 248:387 249:388 250:389 251:389 252:390 253:391 254:391 255:392 256:393 257:394 258:395 259:396 260:397 261:398 262:399 263:400 264:401 265:402 266:402 267:403 268:403 269:403 270:404 271:404 272:405 273:406 274:407 275:408 276:409 277:410 278:411 279:411 280:412 281:413 282:414 283:415 284:416 285:416 286:417 287:418 288:419 289:420 290:421 291:422 292:423 293:423 294:424 295:425 296:425 297:426 298:427 299:428 300:428 301:428 302:429 303:430 304:430 305:431 306:431 307:431 308:432 309:432 310:432 311:433 312:434 313:434 314:435 315:435 316:435 317:435 318:435 319:435 320:436 321:436 322:436 323:437 324:438 325:438 326:438 327:438 328:438 329:438 330:439 331:440 332:440 333:440 334:440 335:440 336:440 337:440 338:440 339:441 340:441 341:442 342:442 343:442 344:443 345:444 346:445 347:446 348:447 349:447 350:447 351:447 352:447 353:447 354:447 355:448 356:449 357:449 358:449 359:449 360:449 361:450 362:451 363:452 364:453 365:454 366:454 367:454 368:455 369:456 370:457 371:458 372:459 373:460 374:461 375:462 376:463 377:464 378:464 379:464 380:465 381:466 382:466\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.940027 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 102\n",
            "I0703 18:12:03.941171 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.941535 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:03.941810 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:03.945375 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000031\n",
            "I0703 18:12:03.945538 139789930788736 set_essential_params.py:432] unique_id: 1000000031\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:03.945635 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 3\n",
            "I0703 18:12:03.945721 139789930788736 set_essential_params.py:434] doc_span_index: 3\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens [SEP]\n",
            "I0703 18:12:03.945938 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:305 8:306 9:307 10:308 11:309 12:310 13:311 14:312 15:313 16:314 17:315 18:315 19:316 20:317 21:318 22:319 23:320 24:321 25:321 26:322 27:323 28:324 29:325 30:326 31:327 32:328 33:329 34:330 35:331 36:332 37:333 38:334 39:335 40:336 41:337 42:338 43:338 44:339 45:340 46:341 47:341 48:342 49:342 50:343 51:344 52:344 53:345 54:346 55:347 56:348 57:348 58:349 59:350 60:351 61:352 62:353 63:354 64:355 65:356 66:357 67:357 68:357 69:357 70:358 71:359 72:359 73:359 74:360 75:361 76:362 77:363 78:364 79:365 80:365 81:365 82:365 83:365 84:365 85:365 86:366 87:367 88:367 89:368 90:369 91:369 92:370 93:371 94:371 95:372 96:373 97:373 98:373 99:373 100:373 101:373 102:373 103:374 104:375 105:375 106:375 107:376 108:377 109:378 110:379 111:380 112:380 113:380 114:381 115:382 116:383 117:384 118:385 119:386 120:387 121:388 122:389 123:389 124:390 125:391 126:391 127:392 128:393 129:394 130:395 131:396 132:397 133:398 134:399 135:400 136:401 137:402 138:402 139:403 140:403 141:403 142:404 143:404 144:405 145:406 146:407 147:408 148:409 149:410 150:411 151:411 152:412 153:413 154:414 155:415 156:416 157:416 158:417 159:418 160:419 161:420 162:421 163:422 164:423 165:423 166:424 167:425 168:425 169:426 170:427 171:428 172:428 173:428 174:429 175:430 176:430 177:431 178:431 179:431 180:432 181:432 182:432 183:433 184:434 185:434 186:435 187:435 188:435 189:435 190:435 191:435 192:436 193:436 194:436 195:437 196:438 197:438 198:438 199:438 200:438 201:438 202:439 203:440 204:440 205:440 206:440 207:440 208:440 209:440 210:440 211:441 212:441 213:442 214:442 215:442 216:443 217:444 218:445 219:446 220:447 221:447 222:447 223:447 224:447 225:447 226:447 227:448 228:449 229:449 230:449 231:449 232:449 233:450 234:451 235:452 236:453 237:454 238:454 239:454 240:455 241:456 242:457 243:458 244:459 245:460 246:461 247:462 248:463 249:464 250:464 251:464 252:465 253:466 254:466 255:467 256:468 257:469 258:469 259:470 260:471 261:472 262:473 263:473 264:473 265:473 266:473 267:474 268:475 269:476 270:477 271:478 272:479 273:480 274:481 275:482 276:483 277:484 278:485 279:486 280:486 281:487 282:488 283:489 284:490 285:491 286:492 287:493 288:494 289:495 290:495 291:496 292:497 293:498 294:499 295:500 296:501 297:502 298:503 299:504 300:505 301:506 302:507 303:508 304:509 305:509 306:509 307:510 308:511 309:512 310:513 311:514 312:514 313:514 314:515 315:516 316:517 317:517 318:518 319:519 320:519 321:519 322:519 323:520 324:520 325:521 326:522 327:522 328:523 329:524 330:524 331:525 332:525 333:525 334:525 335:525 336:525 337:525 338:526 339:527 340:528 341:529 342:530 343:531 344:532 345:533 346:534 347:534 348:534 349:534 350:535 351:535 352:536 353:537 354:538 355:539 356:540 357:541 358:542 359:543 360:544 361:544 362:545 363:546 364:547 365:548 366:548 367:549 368:550 369:550 370:551 371:552 372:553 373:554 374:555 375:556 376:557 377:558 378:559 379:560 380:561 381:562 382:563\n",
            "I0703 18:12:03.946189 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:305 8:306 9:307 10:308 11:309 12:310 13:311 14:312 15:313 16:314 17:315 18:315 19:316 20:317 21:318 22:319 23:320 24:321 25:321 26:322 27:323 28:324 29:325 30:326 31:327 32:328 33:329 34:330 35:331 36:332 37:333 38:334 39:335 40:336 41:337 42:338 43:338 44:339 45:340 46:341 47:341 48:342 49:342 50:343 51:344 52:344 53:345 54:346 55:347 56:348 57:348 58:349 59:350 60:351 61:352 62:353 63:354 64:355 65:356 66:357 67:357 68:357 69:357 70:358 71:359 72:359 73:359 74:360 75:361 76:362 77:363 78:364 79:365 80:365 81:365 82:365 83:365 84:365 85:365 86:366 87:367 88:367 89:368 90:369 91:369 92:370 93:371 94:371 95:372 96:373 97:373 98:373 99:373 100:373 101:373 102:373 103:374 104:375 105:375 106:375 107:376 108:377 109:378 110:379 111:380 112:380 113:380 114:381 115:382 116:383 117:384 118:385 119:386 120:387 121:388 122:389 123:389 124:390 125:391 126:391 127:392 128:393 129:394 130:395 131:396 132:397 133:398 134:399 135:400 136:401 137:402 138:402 139:403 140:403 141:403 142:404 143:404 144:405 145:406 146:407 147:408 148:409 149:410 150:411 151:411 152:412 153:413 154:414 155:415 156:416 157:416 158:417 159:418 160:419 161:420 162:421 163:422 164:423 165:423 166:424 167:425 168:425 169:426 170:427 171:428 172:428 173:428 174:429 175:430 176:430 177:431 178:431 179:431 180:432 181:432 182:432 183:433 184:434 185:434 186:435 187:435 188:435 189:435 190:435 191:435 192:436 193:436 194:436 195:437 196:438 197:438 198:438 199:438 200:438 201:438 202:439 203:440 204:440 205:440 206:440 207:440 208:440 209:440 210:440 211:441 212:441 213:442 214:442 215:442 216:443 217:444 218:445 219:446 220:447 221:447 222:447 223:447 224:447 225:447 226:447 227:448 228:449 229:449 230:449 231:449 232:449 233:450 234:451 235:452 236:453 237:454 238:454 239:454 240:455 241:456 242:457 243:458 244:459 245:460 246:461 247:462 248:463 249:464 250:464 251:464 252:465 253:466 254:466 255:467 256:468 257:469 258:469 259:470 260:471 261:472 262:473 263:473 264:473 265:473 266:473 267:474 268:475 269:476 270:477 271:478 272:479 273:480 274:481 275:482 276:483 277:484 278:485 279:486 280:486 281:487 282:488 283:489 284:490 285:491 286:492 287:493 288:494 289:495 290:495 291:496 292:497 293:498 294:499 295:500 296:501 297:502 298:503 299:504 300:505 301:506 302:507 303:508 304:509 305:509 306:509 307:510 308:511 309:512 310:513 311:514 312:514 313:514 314:515 315:516 316:517 317:517 318:518 319:519 320:519 321:519 322:519 323:520 324:520 325:521 326:522 327:522 328:523 329:524 330:524 331:525 332:525 333:525 334:525 335:525 336:525 337:525 338:526 339:527 340:528 341:529 342:530 343:531 344:532 345:533 346:534 347:534 348:534 349:534 350:535 351:535 352:536 353:537 354:538 355:539 356:540 357:541 358:542 359:543 360:544 361:544 362:545 363:546 364:547 365:548 366:548 367:549 368:550 369:550 370:551 371:552 372:553 373:554 374:555 375:556 376:557 377:558 378:559 379:560 380:561 381:562 382:563\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:03.946431 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 102\n",
            "I0703 18:12:04.042874 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.046249 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.046643 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.052289 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000032\n",
            "I0703 18:12:04.052540 139789930788736 set_essential_params.py:432] unique_id: 1000000032\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.052665 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 4\n",
            "I0703 18:12:04.052761 139789930788736 set_essential_params.py:434] doc_span_index: 4\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n [SEP]\n",
            "I0703 18:12:04.053089 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:400 8:401 9:402 10:402 11:403 12:403 13:403 14:404 15:404 16:405 17:406 18:407 19:408 20:409 21:410 22:411 23:411 24:412 25:413 26:414 27:415 28:416 29:416 30:417 31:418 32:419 33:420 34:421 35:422 36:423 37:423 38:424 39:425 40:425 41:426 42:427 43:428 44:428 45:428 46:429 47:430 48:430 49:431 50:431 51:431 52:432 53:432 54:432 55:433 56:434 57:434 58:435 59:435 60:435 61:435 62:435 63:435 64:436 65:436 66:436 67:437 68:438 69:438 70:438 71:438 72:438 73:438 74:439 75:440 76:440 77:440 78:440 79:440 80:440 81:440 82:440 83:441 84:441 85:442 86:442 87:442 88:443 89:444 90:445 91:446 92:447 93:447 94:447 95:447 96:447 97:447 98:447 99:448 100:449 101:449 102:449 103:449 104:449 105:450 106:451 107:452 108:453 109:454 110:454 111:454 112:455 113:456 114:457 115:458 116:459 117:460 118:461 119:462 120:463 121:464 122:464 123:464 124:465 125:466 126:466 127:467 128:468 129:469 130:469 131:470 132:471 133:472 134:473 135:473 136:473 137:473 138:473 139:474 140:475 141:476 142:477 143:478 144:479 145:480 146:481 147:482 148:483 149:484 150:485 151:486 152:486 153:487 154:488 155:489 156:490 157:491 158:492 159:493 160:494 161:495 162:495 163:496 164:497 165:498 166:499 167:500 168:501 169:502 170:503 171:504 172:505 173:506 174:507 175:508 176:509 177:509 178:509 179:510 180:511 181:512 182:513 183:514 184:514 185:514 186:515 187:516 188:517 189:517 190:518 191:519 192:519 193:519 194:519 195:520 196:520 197:521 198:522 199:522 200:523 201:524 202:524 203:525 204:525 205:525 206:525 207:525 208:525 209:525 210:526 211:527 212:528 213:529 214:530 215:531 216:532 217:533 218:534 219:534 220:534 221:534 222:535 223:535 224:536 225:537 226:538 227:539 228:540 229:541 230:542 231:543 232:544 233:544 234:545 235:546 236:547 237:548 238:548 239:549 240:550 241:550 242:551 243:552 244:553 245:554 246:555 247:556 248:557 249:558 250:559 251:560 252:561 253:562 254:563 255:563 256:563 257:564 258:565 259:566 260:567 261:568 262:569 263:570 264:571 265:572 266:572 267:573 268:574 269:575 270:576 271:577 272:578 273:579 274:580 275:580 276:581 277:582 278:583 279:584 280:585 281:586 282:587 283:588 284:589 285:590 286:591 287:592 288:593 289:594 290:595 291:596 292:596 293:597 294:598 295:599 296:600 297:600 298:601 299:602 300:603 301:604 302:605 303:606 304:607 305:608 306:609 307:610 308:611 309:612 310:613 311:614 312:615 313:615 314:616 315:617 316:618 317:619 318:620 319:621 320:622 321:623 322:624 323:625 324:625 325:625 326:626 327:627 328:628 329:628 330:629 331:630 332:631 333:631 334:632 335:633 336:634 337:635 338:636 339:637 340:638 341:639 342:640 343:641 344:642 345:643 346:644 347:645 348:646 349:647 350:648 351:649 352:650 353:650 354:651 355:652 356:652 357:653 358:654 359:655 360:656 361:656 362:656 363:657 364:657 365:657 366:657 367:658 368:658 369:659 370:660 371:661 372:662 373:663 374:664 375:665 376:665 377:666 378:666 379:666 380:667 381:667 382:667\n",
            "I0703 18:12:04.053477 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:400 8:401 9:402 10:402 11:403 12:403 13:403 14:404 15:404 16:405 17:406 18:407 19:408 20:409 21:410 22:411 23:411 24:412 25:413 26:414 27:415 28:416 29:416 30:417 31:418 32:419 33:420 34:421 35:422 36:423 37:423 38:424 39:425 40:425 41:426 42:427 43:428 44:428 45:428 46:429 47:430 48:430 49:431 50:431 51:431 52:432 53:432 54:432 55:433 56:434 57:434 58:435 59:435 60:435 61:435 62:435 63:435 64:436 65:436 66:436 67:437 68:438 69:438 70:438 71:438 72:438 73:438 74:439 75:440 76:440 77:440 78:440 79:440 80:440 81:440 82:440 83:441 84:441 85:442 86:442 87:442 88:443 89:444 90:445 91:446 92:447 93:447 94:447 95:447 96:447 97:447 98:447 99:448 100:449 101:449 102:449 103:449 104:449 105:450 106:451 107:452 108:453 109:454 110:454 111:454 112:455 113:456 114:457 115:458 116:459 117:460 118:461 119:462 120:463 121:464 122:464 123:464 124:465 125:466 126:466 127:467 128:468 129:469 130:469 131:470 132:471 133:472 134:473 135:473 136:473 137:473 138:473 139:474 140:475 141:476 142:477 143:478 144:479 145:480 146:481 147:482 148:483 149:484 150:485 151:486 152:486 153:487 154:488 155:489 156:490 157:491 158:492 159:493 160:494 161:495 162:495 163:496 164:497 165:498 166:499 167:500 168:501 169:502 170:503 171:504 172:505 173:506 174:507 175:508 176:509 177:509 178:509 179:510 180:511 181:512 182:513 183:514 184:514 185:514 186:515 187:516 188:517 189:517 190:518 191:519 192:519 193:519 194:519 195:520 196:520 197:521 198:522 199:522 200:523 201:524 202:524 203:525 204:525 205:525 206:525 207:525 208:525 209:525 210:526 211:527 212:528 213:529 214:530 215:531 216:532 217:533 218:534 219:534 220:534 221:534 222:535 223:535 224:536 225:537 226:538 227:539 228:540 229:541 230:542 231:543 232:544 233:544 234:545 235:546 236:547 237:548 238:548 239:549 240:550 241:550 242:551 243:552 244:553 245:554 246:555 247:556 248:557 249:558 250:559 251:560 252:561 253:562 254:563 255:563 256:563 257:564 258:565 259:566 260:567 261:568 262:569 263:570 264:571 265:572 266:572 267:573 268:574 269:575 270:576 271:577 272:578 273:579 274:580 275:580 276:581 277:582 278:583 279:584 280:585 281:586 282:587 283:588 284:589 285:590 286:591 287:592 288:593 289:594 290:595 291:596 292:596 293:597 294:598 295:599 296:600 297:600 298:601 299:602 300:603 301:604 302:605 303:606 304:607 305:608 306:609 307:610 308:611 309:612 310:613 311:614 312:615 313:615 314:616 315:617 316:618 317:619 318:620 319:621 320:622 321:623 322:624 323:625 324:625 325:625 326:626 327:627 328:628 329:628 330:629 331:630 332:631 333:631 334:632 335:633 336:634 337:635 338:636 339:637 340:638 341:639 342:640 343:641 344:642 345:643 346:644 347:645 348:646 349:647 350:648 351:649 352:650 353:650 354:651 355:652 356:652 357:653 358:654 359:655 360:656 361:656 362:656 363:657 364:657 365:657 366:657 367:658 368:658 369:659 370:660 371:661 372:662 373:663 374:664 375:665 376:665 377:666 378:666 379:666 380:667 381:667 382:667\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.144686 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 102\n",
            "I0703 18:12:04.145828 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.146216 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.146512 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.150329 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000033\n",
            "I0703 18:12:04.150523 139789930788736 set_essential_params.py:432] unique_id: 1000000033\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.150624 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 5\n",
            "I0703 18:12:04.150712 139789930788736 set_essential_params.py:434] doc_span_index: 5\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s [SEP]\n",
            "I0703 18:12:04.150923 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:473 8:473 9:473 10:473 11:474 12:475 13:476 14:477 15:478 16:479 17:480 18:481 19:482 20:483 21:484 22:485 23:486 24:486 25:487 26:488 27:489 28:490 29:491 30:492 31:493 32:494 33:495 34:495 35:496 36:497 37:498 38:499 39:500 40:501 41:502 42:503 43:504 44:505 45:506 46:507 47:508 48:509 49:509 50:509 51:510 52:511 53:512 54:513 55:514 56:514 57:514 58:515 59:516 60:517 61:517 62:518 63:519 64:519 65:519 66:519 67:520 68:520 69:521 70:522 71:522 72:523 73:524 74:524 75:525 76:525 77:525 78:525 79:525 80:525 81:525 82:526 83:527 84:528 85:529 86:530 87:531 88:532 89:533 90:534 91:534 92:534 93:534 94:535 95:535 96:536 97:537 98:538 99:539 100:540 101:541 102:542 103:543 104:544 105:544 106:545 107:546 108:547 109:548 110:548 111:549 112:550 113:550 114:551 115:552 116:553 117:554 118:555 119:556 120:557 121:558 122:559 123:560 124:561 125:562 126:563 127:563 128:563 129:564 130:565 131:566 132:567 133:568 134:569 135:570 136:571 137:572 138:572 139:573 140:574 141:575 142:576 143:577 144:578 145:579 146:580 147:580 148:581 149:582 150:583 151:584 152:585 153:586 154:587 155:588 156:589 157:590 158:591 159:592 160:593 161:594 162:595 163:596 164:596 165:597 166:598 167:599 168:600 169:600 170:601 171:602 172:603 173:604 174:605 175:606 176:607 177:608 178:609 179:610 180:611 181:612 182:613 183:614 184:615 185:615 186:616 187:617 188:618 189:619 190:620 191:621 192:622 193:623 194:624 195:625 196:625 197:625 198:626 199:627 200:628 201:628 202:629 203:630 204:631 205:631 206:632 207:633 208:634 209:635 210:636 211:637 212:638 213:639 214:640 215:641 216:642 217:643 218:644 219:645 220:646 221:647 222:648 223:649 224:650 225:650 226:651 227:652 228:652 229:653 230:654 231:655 232:656 233:656 234:656 235:657 236:657 237:657 238:657 239:658 240:658 241:659 242:660 243:661 244:662 245:663 246:664 247:665 248:665 249:666 250:666 251:666 252:667 253:667 254:667 255:668 256:668 257:668 258:669 259:670 260:671 261:672 262:673 263:674 264:675 265:676 266:677 267:678 268:679 269:680 270:681 271:682 272:683 273:684 274:685 275:685 276:686 277:687 278:688 279:689 280:689 281:690 282:691 283:692 284:693 285:694 286:695 287:696 288:697 289:698 290:699 291:700 292:701 293:701 294:702 295:703 296:704 297:705 298:706 299:707 300:707 301:708 302:709 303:709 304:709 305:709 306:710 307:711 308:712 309:713 310:713 311:714 312:714 313:715 314:716 315:717 316:718 317:719 318:720 319:721 320:722 321:723 322:724 323:724 324:725 325:725 326:726 327:727 328:728 329:729 330:730 331:730 332:731 333:732 334:733 335:734 336:735 337:735 338:736 339:737 340:737 341:737 342:738 343:738 344:739 345:740 346:741 347:741 348:742 349:743 350:744 351:745 352:746 353:747 354:748 355:748 356:749 357:749 358:749 359:750 360:751 361:752 362:753 363:753 364:754 365:755 366:755 367:756 368:757 369:757 370:758 371:759 372:759 373:759 374:760 375:761 376:761 377:762 378:763 379:764 380:764 381:765 382:765\n",
            "I0703 18:12:04.151177 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:473 8:473 9:473 10:473 11:474 12:475 13:476 14:477 15:478 16:479 17:480 18:481 19:482 20:483 21:484 22:485 23:486 24:486 25:487 26:488 27:489 28:490 29:491 30:492 31:493 32:494 33:495 34:495 35:496 36:497 37:498 38:499 39:500 40:501 41:502 42:503 43:504 44:505 45:506 46:507 47:508 48:509 49:509 50:509 51:510 52:511 53:512 54:513 55:514 56:514 57:514 58:515 59:516 60:517 61:517 62:518 63:519 64:519 65:519 66:519 67:520 68:520 69:521 70:522 71:522 72:523 73:524 74:524 75:525 76:525 77:525 78:525 79:525 80:525 81:525 82:526 83:527 84:528 85:529 86:530 87:531 88:532 89:533 90:534 91:534 92:534 93:534 94:535 95:535 96:536 97:537 98:538 99:539 100:540 101:541 102:542 103:543 104:544 105:544 106:545 107:546 108:547 109:548 110:548 111:549 112:550 113:550 114:551 115:552 116:553 117:554 118:555 119:556 120:557 121:558 122:559 123:560 124:561 125:562 126:563 127:563 128:563 129:564 130:565 131:566 132:567 133:568 134:569 135:570 136:571 137:572 138:572 139:573 140:574 141:575 142:576 143:577 144:578 145:579 146:580 147:580 148:581 149:582 150:583 151:584 152:585 153:586 154:587 155:588 156:589 157:590 158:591 159:592 160:593 161:594 162:595 163:596 164:596 165:597 166:598 167:599 168:600 169:600 170:601 171:602 172:603 173:604 174:605 175:606 176:607 177:608 178:609 179:610 180:611 181:612 182:613 183:614 184:615 185:615 186:616 187:617 188:618 189:619 190:620 191:621 192:622 193:623 194:624 195:625 196:625 197:625 198:626 199:627 200:628 201:628 202:629 203:630 204:631 205:631 206:632 207:633 208:634 209:635 210:636 211:637 212:638 213:639 214:640 215:641 216:642 217:643 218:644 219:645 220:646 221:647 222:648 223:649 224:650 225:650 226:651 227:652 228:652 229:653 230:654 231:655 232:656 233:656 234:656 235:657 236:657 237:657 238:657 239:658 240:658 241:659 242:660 243:661 244:662 245:663 246:664 247:665 248:665 249:666 250:666 251:666 252:667 253:667 254:667 255:668 256:668 257:668 258:669 259:670 260:671 261:672 262:673 263:674 264:675 265:676 266:677 267:678 268:679 269:680 270:681 271:682 272:683 273:684 274:685 275:685 276:686 277:687 278:688 279:689 280:689 281:690 282:691 283:692 284:693 285:694 286:695 287:696 288:697 289:698 290:699 291:700 292:701 293:701 294:702 295:703 296:704 297:705 298:706 299:707 300:707 301:708 302:709 303:709 304:709 305:709 306:710 307:711 308:712 309:713 310:713 311:714 312:714 313:715 314:716 315:717 316:718 317:719 318:720 319:721 320:722 321:723 322:724 323:724 324:725 325:725 326:726 327:727 328:728 329:729 330:730 331:730 332:731 333:732 334:733 335:734 336:735 337:735 338:736 339:737 340:737 341:737 342:738 343:738 344:739 345:740 346:741 347:741 348:742 349:743 350:744 351:745 352:746 353:747 354:748 355:748 356:749 357:749 358:749 359:750 360:751 361:752 362:753 363:753 364:754 365:755 366:755 367:756 368:757 369:757 370:758 371:759 372:759 373:759 374:760 375:761 376:761 377:762 378:763 379:764 380:764 381:765 382:765\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.151388 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 102\n",
            "I0703 18:12:04.248781 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.249234 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.249558 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.254941 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000034\n",
            "I0703 18:12:04.255219 139789930788736 set_essential_params.py:432] unique_id: 1000000034\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.255327 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 6\n",
            "I0703 18:12:04.255420 139789930788736 set_essential_params.py:434] doc_span_index: 6\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the [SEP]\n",
            "I0703 18:12:04.255708 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:570 8:571 9:572 10:572 11:573 12:574 13:575 14:576 15:577 16:578 17:579 18:580 19:580 20:581 21:582 22:583 23:584 24:585 25:586 26:587 27:588 28:589 29:590 30:591 31:592 32:593 33:594 34:595 35:596 36:596 37:597 38:598 39:599 40:600 41:600 42:601 43:602 44:603 45:604 46:605 47:606 48:607 49:608 50:609 51:610 52:611 53:612 54:613 55:614 56:615 57:615 58:616 59:617 60:618 61:619 62:620 63:621 64:622 65:623 66:624 67:625 68:625 69:625 70:626 71:627 72:628 73:628 74:629 75:630 76:631 77:631 78:632 79:633 80:634 81:635 82:636 83:637 84:638 85:639 86:640 87:641 88:642 89:643 90:644 91:645 92:646 93:647 94:648 95:649 96:650 97:650 98:651 99:652 100:652 101:653 102:654 103:655 104:656 105:656 106:656 107:657 108:657 109:657 110:657 111:658 112:658 113:659 114:660 115:661 116:662 117:663 118:664 119:665 120:665 121:666 122:666 123:666 124:667 125:667 126:667 127:668 128:668 129:668 130:669 131:670 132:671 133:672 134:673 135:674 136:675 137:676 138:677 139:678 140:679 141:680 142:681 143:682 144:683 145:684 146:685 147:685 148:686 149:687 150:688 151:689 152:689 153:690 154:691 155:692 156:693 157:694 158:695 159:696 160:697 161:698 162:699 163:700 164:701 165:701 166:702 167:703 168:704 169:705 170:706 171:707 172:707 173:708 174:709 175:709 176:709 177:709 178:710 179:711 180:712 181:713 182:713 183:714 184:714 185:715 186:716 187:717 188:718 189:719 190:720 191:721 192:722 193:723 194:724 195:724 196:725 197:725 198:726 199:727 200:728 201:729 202:730 203:730 204:731 205:732 206:733 207:734 208:735 209:735 210:736 211:737 212:737 213:737 214:738 215:738 216:739 217:740 218:741 219:741 220:742 221:743 222:744 223:745 224:746 225:747 226:748 227:748 228:749 229:749 230:749 231:750 232:751 233:752 234:753 235:753 236:754 237:755 238:755 239:756 240:757 241:757 242:758 243:759 244:759 245:759 246:760 247:761 248:761 249:762 250:763 251:764 252:764 253:765 254:765 255:765 256:765 257:765 258:766 259:767 260:768 261:768 262:768 263:769 264:769 265:769 266:769 267:769 268:769 269:769 270:769 271:770 272:770 273:770 274:770 275:771 276:772 277:773 278:773 279:774 280:775 281:775 282:775 283:775 284:775 285:775 286:775 287:776 288:776 289:776 290:776 291:777 292:778 293:779 294:779 295:780 296:781 297:782 298:783 299:784 300:784 301:785 302:786 303:786 304:787 305:788 306:789 307:789 308:790 309:791 310:792 311:792 312:793 313:794 314:794 315:795 316:796 317:797 318:798 319:798 320:799 321:800 322:801 323:802 324:803 325:804 326:805 327:806 328:807 329:808 330:809 331:810 332:811 333:812 334:812 335:813 336:814 337:814 338:815 339:816 340:816 341:816 342:817 343:818 344:819 345:820 346:821 347:822 348:823 349:824 350:824 351:825 352:826 353:826 354:827 355:828 356:829 357:829 358:830 359:831 360:832 361:833 362:834 363:835 364:836 365:837 366:837 367:837 368:837 369:838 370:838 371:838 372:838 373:838 374:839 375:840 376:841 377:841 378:842 379:843 380:844 381:845 382:846\n",
            "I0703 18:12:04.256175 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:570 8:571 9:572 10:572 11:573 12:574 13:575 14:576 15:577 16:578 17:579 18:580 19:580 20:581 21:582 22:583 23:584 24:585 25:586 26:587 27:588 28:589 29:590 30:591 31:592 32:593 33:594 34:595 35:596 36:596 37:597 38:598 39:599 40:600 41:600 42:601 43:602 44:603 45:604 46:605 47:606 48:607 49:608 50:609 51:610 52:611 53:612 54:613 55:614 56:615 57:615 58:616 59:617 60:618 61:619 62:620 63:621 64:622 65:623 66:624 67:625 68:625 69:625 70:626 71:627 72:628 73:628 74:629 75:630 76:631 77:631 78:632 79:633 80:634 81:635 82:636 83:637 84:638 85:639 86:640 87:641 88:642 89:643 90:644 91:645 92:646 93:647 94:648 95:649 96:650 97:650 98:651 99:652 100:652 101:653 102:654 103:655 104:656 105:656 106:656 107:657 108:657 109:657 110:657 111:658 112:658 113:659 114:660 115:661 116:662 117:663 118:664 119:665 120:665 121:666 122:666 123:666 124:667 125:667 126:667 127:668 128:668 129:668 130:669 131:670 132:671 133:672 134:673 135:674 136:675 137:676 138:677 139:678 140:679 141:680 142:681 143:682 144:683 145:684 146:685 147:685 148:686 149:687 150:688 151:689 152:689 153:690 154:691 155:692 156:693 157:694 158:695 159:696 160:697 161:698 162:699 163:700 164:701 165:701 166:702 167:703 168:704 169:705 170:706 171:707 172:707 173:708 174:709 175:709 176:709 177:709 178:710 179:711 180:712 181:713 182:713 183:714 184:714 185:715 186:716 187:717 188:718 189:719 190:720 191:721 192:722 193:723 194:724 195:724 196:725 197:725 198:726 199:727 200:728 201:729 202:730 203:730 204:731 205:732 206:733 207:734 208:735 209:735 210:736 211:737 212:737 213:737 214:738 215:738 216:739 217:740 218:741 219:741 220:742 221:743 222:744 223:745 224:746 225:747 226:748 227:748 228:749 229:749 230:749 231:750 232:751 233:752 234:753 235:753 236:754 237:755 238:755 239:756 240:757 241:757 242:758 243:759 244:759 245:759 246:760 247:761 248:761 249:762 250:763 251:764 252:764 253:765 254:765 255:765 256:765 257:765 258:766 259:767 260:768 261:768 262:768 263:769 264:769 265:769 266:769 267:769 268:769 269:769 270:769 271:770 272:770 273:770 274:770 275:771 276:772 277:773 278:773 279:774 280:775 281:775 282:775 283:775 284:775 285:775 286:775 287:776 288:776 289:776 290:776 291:777 292:778 293:779 294:779 295:780 296:781 297:782 298:783 299:784 300:784 301:785 302:786 303:786 304:787 305:788 306:789 307:789 308:790 309:791 310:792 311:792 312:793 313:794 314:794 315:795 316:796 317:797 318:798 319:798 320:799 321:800 322:801 323:802 324:803 325:804 326:805 327:806 328:807 329:808 330:809 331:810 332:811 333:812 334:812 335:813 336:814 337:814 338:815 339:816 340:816 341:816 342:817 343:818 344:819 345:820 346:821 347:822 348:823 349:824 350:824 351:825 352:826 353:826 354:827 355:828 356:829 357:829 358:830 359:831 360:832 361:833 362:834 363:835 364:836 365:837 366:837 367:837 368:837 369:838 370:838 371:838 372:838 373:838 374:839 375:840 376:841 377:841 378:842 379:843 380:844 381:845 382:846\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.349192 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 102\n",
            "I0703 18:12:04.350140 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.350492 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.350911 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.354950 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000035\n",
            "I0703 18:12:04.355134 139789930788736 set_essential_params.py:432] unique_id: 1000000035\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.355248 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 7\n",
            "I0703 18:12:04.355336 139789930788736 set_essential_params.py:434] doc_span_index: 7\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces [SEP]\n",
            "I0703 18:12:04.355561 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:674 8:675 9:676 10:677 11:678 12:679 13:680 14:681 15:682 16:683 17:684 18:685 19:685 20:686 21:687 22:688 23:689 24:689 25:690 26:691 27:692 28:693 29:694 30:695 31:696 32:697 33:698 34:699 35:700 36:701 37:701 38:702 39:703 40:704 41:705 42:706 43:707 44:707 45:708 46:709 47:709 48:709 49:709 50:710 51:711 52:712 53:713 54:713 55:714 56:714 57:715 58:716 59:717 60:718 61:719 62:720 63:721 64:722 65:723 66:724 67:724 68:725 69:725 70:726 71:727 72:728 73:729 74:730 75:730 76:731 77:732 78:733 79:734 80:735 81:735 82:736 83:737 84:737 85:737 86:738 87:738 88:739 89:740 90:741 91:741 92:742 93:743 94:744 95:745 96:746 97:747 98:748 99:748 100:749 101:749 102:749 103:750 104:751 105:752 106:753 107:753 108:754 109:755 110:755 111:756 112:757 113:757 114:758 115:759 116:759 117:759 118:760 119:761 120:761 121:762 122:763 123:764 124:764 125:765 126:765 127:765 128:765 129:765 130:766 131:767 132:768 133:768 134:768 135:769 136:769 137:769 138:769 139:769 140:769 141:769 142:769 143:770 144:770 145:770 146:770 147:771 148:772 149:773 150:773 151:774 152:775 153:775 154:775 155:775 156:775 157:775 158:775 159:776 160:776 161:776 162:776 163:777 164:778 165:779 166:779 167:780 168:781 169:782 170:783 171:784 172:784 173:785 174:786 175:786 176:787 177:788 178:789 179:789 180:790 181:791 182:792 183:792 184:793 185:794 186:794 187:795 188:796 189:797 190:798 191:798 192:799 193:800 194:801 195:802 196:803 197:804 198:805 199:806 200:807 201:808 202:809 203:810 204:811 205:812 206:812 207:813 208:814 209:814 210:815 211:816 212:816 213:816 214:817 215:818 216:819 217:820 218:821 219:822 220:823 221:824 222:824 223:825 224:826 225:826 226:827 227:828 228:829 229:829 230:830 231:831 232:832 233:833 234:834 235:835 236:836 237:837 238:837 239:837 240:837 241:838 242:838 243:838 244:838 245:838 246:839 247:840 248:841 249:841 250:842 251:843 252:844 253:845 254:846 255:847 256:847 257:847 258:847 259:848 260:849 261:850 262:851 263:852 264:852 265:852 266:853 267:854 268:854 269:854 270:854 271:855 272:856 273:856 274:857 275:858 276:859 277:860 278:860 279:860 280:860 281:861 282:862 283:863 284:864 285:865 286:866 287:867 288:867 289:868 290:869 291:870 292:871 293:872 294:873 295:874 296:875 297:876 298:877 299:878 300:879 301:879 302:880 303:881 304:882 305:882 306:883 307:884 308:884 309:884 310:884 311:885 312:885 313:886 314:887 315:888 316:889 317:890 318:890 319:891 320:892 321:893 322:894 323:895 324:896 325:897 326:897 327:898 328:899 329:900 330:901 331:902 332:903 333:904 334:905 335:906 336:907 337:907 338:907 339:907 340:908 341:909 342:910 343:911 344:912 345:913 346:914 347:914 348:915 349:916 350:916 351:917 352:918 353:919 354:920 355:920 356:920 357:920 358:921 359:922 360:923 361:924 362:924 363:925 364:926 365:927 366:928 367:929 368:929 369:929 370:929 371:930 372:930 373:930 374:931 375:931 376:931 377:932 378:932 379:932 380:933 381:933 382:933\n",
            "I0703 18:12:04.355794 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:674 8:675 9:676 10:677 11:678 12:679 13:680 14:681 15:682 16:683 17:684 18:685 19:685 20:686 21:687 22:688 23:689 24:689 25:690 26:691 27:692 28:693 29:694 30:695 31:696 32:697 33:698 34:699 35:700 36:701 37:701 38:702 39:703 40:704 41:705 42:706 43:707 44:707 45:708 46:709 47:709 48:709 49:709 50:710 51:711 52:712 53:713 54:713 55:714 56:714 57:715 58:716 59:717 60:718 61:719 62:720 63:721 64:722 65:723 66:724 67:724 68:725 69:725 70:726 71:727 72:728 73:729 74:730 75:730 76:731 77:732 78:733 79:734 80:735 81:735 82:736 83:737 84:737 85:737 86:738 87:738 88:739 89:740 90:741 91:741 92:742 93:743 94:744 95:745 96:746 97:747 98:748 99:748 100:749 101:749 102:749 103:750 104:751 105:752 106:753 107:753 108:754 109:755 110:755 111:756 112:757 113:757 114:758 115:759 116:759 117:759 118:760 119:761 120:761 121:762 122:763 123:764 124:764 125:765 126:765 127:765 128:765 129:765 130:766 131:767 132:768 133:768 134:768 135:769 136:769 137:769 138:769 139:769 140:769 141:769 142:769 143:770 144:770 145:770 146:770 147:771 148:772 149:773 150:773 151:774 152:775 153:775 154:775 155:775 156:775 157:775 158:775 159:776 160:776 161:776 162:776 163:777 164:778 165:779 166:779 167:780 168:781 169:782 170:783 171:784 172:784 173:785 174:786 175:786 176:787 177:788 178:789 179:789 180:790 181:791 182:792 183:792 184:793 185:794 186:794 187:795 188:796 189:797 190:798 191:798 192:799 193:800 194:801 195:802 196:803 197:804 198:805 199:806 200:807 201:808 202:809 203:810 204:811 205:812 206:812 207:813 208:814 209:814 210:815 211:816 212:816 213:816 214:817 215:818 216:819 217:820 218:821 219:822 220:823 221:824 222:824 223:825 224:826 225:826 226:827 227:828 228:829 229:829 230:830 231:831 232:832 233:833 234:834 235:835 236:836 237:837 238:837 239:837 240:837 241:838 242:838 243:838 244:838 245:838 246:839 247:840 248:841 249:841 250:842 251:843 252:844 253:845 254:846 255:847 256:847 257:847 258:847 259:848 260:849 261:850 262:851 263:852 264:852 265:852 266:853 267:854 268:854 269:854 270:854 271:855 272:856 273:856 274:857 275:858 276:859 277:860 278:860 279:860 280:860 281:861 282:862 283:863 284:864 285:865 286:866 287:867 288:867 289:868 290:869 291:870 292:871 293:872 294:873 295:874 296:875 297:876 298:877 299:878 300:879 301:879 302:880 303:881 304:882 305:882 306:883 307:884 308:884 309:884 310:884 311:885 312:885 313:886 314:887 315:888 316:889 317:890 318:890 319:891 320:892 321:893 322:894 323:895 324:896 325:897 326:897 327:898 328:899 329:900 330:901 331:902 332:903 333:904 334:905 335:906 336:907 337:907 338:907 339:907 340:908 341:909 342:910 343:911 344:912 345:913 346:914 347:914 348:915 349:916 350:916 351:917 352:918 353:919 354:920 355:920 356:920 357:920 358:921 359:922 360:923 361:924 362:924 363:925 364:926 365:927 366:928 367:929 368:929 369:929 370:929 371:930 372:930 373:930 374:931 375:931 376:931 377:932 378:932 379:932 380:933 381:933 382:933\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.356045 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 102\n",
            "I0703 18:12:04.454490 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.454943 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.455279 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.460552 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000036\n",
            "I0703 18:12:04.460792 139789930788736 set_essential_params.py:432] unique_id: 1000000036\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.460890 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 8\n",
            "I0703 18:12:04.460973 139789930788736 set_essential_params.py:434] doc_span_index: 8\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , [SEP]\n",
            "I0703 18:12:04.461273 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:769 8:769 9:769 10:769 11:769 12:769 13:769 14:769 15:770 16:770 17:770 18:770 19:771 20:772 21:773 22:773 23:774 24:775 25:775 26:775 27:775 28:775 29:775 30:775 31:776 32:776 33:776 34:776 35:777 36:778 37:779 38:779 39:780 40:781 41:782 42:783 43:784 44:784 45:785 46:786 47:786 48:787 49:788 50:789 51:789 52:790 53:791 54:792 55:792 56:793 57:794 58:794 59:795 60:796 61:797 62:798 63:798 64:799 65:800 66:801 67:802 68:803 69:804 70:805 71:806 72:807 73:808 74:809 75:810 76:811 77:812 78:812 79:813 80:814 81:814 82:815 83:816 84:816 85:816 86:817 87:818 88:819 89:820 90:821 91:822 92:823 93:824 94:824 95:825 96:826 97:826 98:827 99:828 100:829 101:829 102:830 103:831 104:832 105:833 106:834 107:835 108:836 109:837 110:837 111:837 112:837 113:838 114:838 115:838 116:838 117:838 118:839 119:840 120:841 121:841 122:842 123:843 124:844 125:845 126:846 127:847 128:847 129:847 130:847 131:848 132:849 133:850 134:851 135:852 136:852 137:852 138:853 139:854 140:854 141:854 142:854 143:855 144:856 145:856 146:857 147:858 148:859 149:860 150:860 151:860 152:860 153:861 154:862 155:863 156:864 157:865 158:866 159:867 160:867 161:868 162:869 163:870 164:871 165:872 166:873 167:874 168:875 169:876 170:877 171:878 172:879 173:879 174:880 175:881 176:882 177:882 178:883 179:884 180:884 181:884 182:884 183:885 184:885 185:886 186:887 187:888 188:889 189:890 190:890 191:891 192:892 193:893 194:894 195:895 196:896 197:897 198:897 199:898 200:899 201:900 202:901 203:902 204:903 205:904 206:905 207:906 208:907 209:907 210:907 211:907 212:908 213:909 214:910 215:911 216:912 217:913 218:914 219:914 220:915 221:916 222:916 223:917 224:918 225:919 226:920 227:920 228:920 229:920 230:921 231:922 232:923 233:924 234:924 235:925 236:926 237:927 238:928 239:929 240:929 241:929 242:929 243:930 244:930 245:930 246:931 247:931 248:931 249:932 250:932 251:932 252:933 253:933 254:933 255:933 256:933 257:933 258:934 259:935 260:936 261:937 262:937 263:938 264:939 265:940 266:941 267:942 268:943 269:943 270:943 271:944 272:944 273:945 274:946 275:947 276:947 277:948 278:949 279:950 280:951 281:952 282:953 283:954 284:954 285:955 286:955 287:956 288:957 289:958 290:959 291:960 292:961 293:962 294:963 295:964 296:965 297:966 298:967 299:968 300:968 301:968 302:969 303:970 304:970 305:971 306:971 307:971 308:971 309:971 310:971 311:972 312:973 313:973 314:974 315:975 316:976 317:976 318:976 319:976 320:976 321:977 322:978 323:979 324:980 325:981 326:982 327:982 328:982 329:982 330:983 331:983 332:984 333:984 334:985 335:986 336:987 337:988 338:989 339:989 340:990 341:991 342:992 343:993 344:994 345:994 346:995 347:996 348:997 349:998 350:998 351:999 352:1000 353:1000 354:1001 355:1002 356:1002 357:1002 358:1002 359:1003 360:1003 361:1004 362:1004 363:1005 364:1006 365:1007 366:1008 367:1009 368:1010 369:1010 370:1011 371:1012 372:1012 373:1013 374:1014 375:1015 376:1016 377:1017 378:1017 379:1017 380:1017 381:1018 382:1018\n",
            "I0703 18:12:04.461669 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:769 8:769 9:769 10:769 11:769 12:769 13:769 14:769 15:770 16:770 17:770 18:770 19:771 20:772 21:773 22:773 23:774 24:775 25:775 26:775 27:775 28:775 29:775 30:775 31:776 32:776 33:776 34:776 35:777 36:778 37:779 38:779 39:780 40:781 41:782 42:783 43:784 44:784 45:785 46:786 47:786 48:787 49:788 50:789 51:789 52:790 53:791 54:792 55:792 56:793 57:794 58:794 59:795 60:796 61:797 62:798 63:798 64:799 65:800 66:801 67:802 68:803 69:804 70:805 71:806 72:807 73:808 74:809 75:810 76:811 77:812 78:812 79:813 80:814 81:814 82:815 83:816 84:816 85:816 86:817 87:818 88:819 89:820 90:821 91:822 92:823 93:824 94:824 95:825 96:826 97:826 98:827 99:828 100:829 101:829 102:830 103:831 104:832 105:833 106:834 107:835 108:836 109:837 110:837 111:837 112:837 113:838 114:838 115:838 116:838 117:838 118:839 119:840 120:841 121:841 122:842 123:843 124:844 125:845 126:846 127:847 128:847 129:847 130:847 131:848 132:849 133:850 134:851 135:852 136:852 137:852 138:853 139:854 140:854 141:854 142:854 143:855 144:856 145:856 146:857 147:858 148:859 149:860 150:860 151:860 152:860 153:861 154:862 155:863 156:864 157:865 158:866 159:867 160:867 161:868 162:869 163:870 164:871 165:872 166:873 167:874 168:875 169:876 170:877 171:878 172:879 173:879 174:880 175:881 176:882 177:882 178:883 179:884 180:884 181:884 182:884 183:885 184:885 185:886 186:887 187:888 188:889 189:890 190:890 191:891 192:892 193:893 194:894 195:895 196:896 197:897 198:897 199:898 200:899 201:900 202:901 203:902 204:903 205:904 206:905 207:906 208:907 209:907 210:907 211:907 212:908 213:909 214:910 215:911 216:912 217:913 218:914 219:914 220:915 221:916 222:916 223:917 224:918 225:919 226:920 227:920 228:920 229:920 230:921 231:922 232:923 233:924 234:924 235:925 236:926 237:927 238:928 239:929 240:929 241:929 242:929 243:930 244:930 245:930 246:931 247:931 248:931 249:932 250:932 251:932 252:933 253:933 254:933 255:933 256:933 257:933 258:934 259:935 260:936 261:937 262:937 263:938 264:939 265:940 266:941 267:942 268:943 269:943 270:943 271:944 272:944 273:945 274:946 275:947 276:947 277:948 278:949 279:950 280:951 281:952 282:953 283:954 284:954 285:955 286:955 287:956 288:957 289:958 290:959 291:960 292:961 293:962 294:963 295:964 296:965 297:966 298:967 299:968 300:968 301:968 302:969 303:970 304:970 305:971 306:971 307:971 308:971 309:971 310:971 311:972 312:973 313:973 314:974 315:975 316:976 317:976 318:976 319:976 320:976 321:977 322:978 323:979 324:980 325:981 326:982 327:982 328:982 329:982 330:983 331:983 332:984 333:984 334:985 335:986 336:987 337:988 338:989 339:989 340:990 341:991 342:992 343:993 344:994 345:994 346:995 347:996 348:997 349:998 350:998 351:999 352:1000 353:1000 354:1001 355:1002 356:1002 357:1002 358:1002 359:1003 360:1003 361:1004 362:1004 363:1005 364:1006 365:1007 366:1008 367:1009 368:1010 369:1010 370:1011 371:1012 372:1012 373:1013 374:1014 375:1015 376:1016 377:1017 378:1017 379:1017 380:1017 381:1018 382:1018\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.555689 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 102\n",
            "I0703 18:12:04.557552 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.557958 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.558228 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.561380 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000037\n",
            "I0703 18:12:04.561596 139789930788736 set_essential_params.py:432] unique_id: 1000000037\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.561714 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 9\n",
            "I0703 18:12:04.561817 139789930788736 set_essential_params.py:434] doc_span_index: 9\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; [SEP]\n",
            "I0703 18:12:04.562129 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:852 8:852 9:852 10:853 11:854 12:854 13:854 14:854 15:855 16:856 17:856 18:857 19:858 20:859 21:860 22:860 23:860 24:860 25:861 26:862 27:863 28:864 29:865 30:866 31:867 32:867 33:868 34:869 35:870 36:871 37:872 38:873 39:874 40:875 41:876 42:877 43:878 44:879 45:879 46:880 47:881 48:882 49:882 50:883 51:884 52:884 53:884 54:884 55:885 56:885 57:886 58:887 59:888 60:889 61:890 62:890 63:891 64:892 65:893 66:894 67:895 68:896 69:897 70:897 71:898 72:899 73:900 74:901 75:902 76:903 77:904 78:905 79:906 80:907 81:907 82:907 83:907 84:908 85:909 86:910 87:911 88:912 89:913 90:914 91:914 92:915 93:916 94:916 95:917 96:918 97:919 98:920 99:920 100:920 101:920 102:921 103:922 104:923 105:924 106:924 107:925 108:926 109:927 110:928 111:929 112:929 113:929 114:929 115:930 116:930 117:930 118:931 119:931 120:931 121:932 122:932 123:932 124:933 125:933 126:933 127:933 128:933 129:933 130:934 131:935 132:936 133:937 134:937 135:938 136:939 137:940 138:941 139:942 140:943 141:943 142:943 143:944 144:944 145:945 146:946 147:947 148:947 149:948 150:949 151:950 152:951 153:952 154:953 155:954 156:954 157:955 158:955 159:956 160:957 161:958 162:959 163:960 164:961 165:962 166:963 167:964 168:965 169:966 170:967 171:968 172:968 173:968 174:969 175:970 176:970 177:971 178:971 179:971 180:971 181:971 182:971 183:972 184:973 185:973 186:974 187:975 188:976 189:976 190:976 191:976 192:976 193:977 194:978 195:979 196:980 197:981 198:982 199:982 200:982 201:982 202:983 203:983 204:984 205:984 206:985 207:986 208:987 209:988 210:989 211:989 212:990 213:991 214:992 215:993 216:994 217:994 218:995 219:996 220:997 221:998 222:998 223:999 224:1000 225:1000 226:1001 227:1002 228:1002 229:1002 230:1002 231:1003 232:1003 233:1004 234:1004 235:1005 236:1006 237:1007 238:1008 239:1009 240:1010 241:1010 242:1011 243:1012 244:1012 245:1013 246:1014 247:1015 248:1016 249:1017 250:1017 251:1017 252:1017 253:1018 254:1018 255:1019 256:1020 257:1021 258:1022 259:1023 260:1024 261:1024 262:1025 263:1026 264:1027 265:1028 266:1028 267:1029 268:1029 269:1030 270:1031 271:1032 272:1033 273:1034 274:1034 275:1034 276:1035 277:1036 278:1036 279:1037 280:1038 281:1039 282:1039 283:1040 284:1041 285:1042 286:1043 287:1044 288:1045 289:1046 290:1046 291:1047 292:1047 293:1047 294:1047 295:1048 296:1048 297:1049 298:1050 299:1051 300:1052 301:1053 302:1054 303:1054 304:1055 305:1056 306:1057 307:1057 308:1058 309:1059 310:1060 311:1061 312:1062 313:1063 314:1064 315:1065 316:1066 317:1066 318:1067 319:1067 320:1068 321:1069 322:1070 323:1071 324:1071 325:1072 326:1072 327:1073 328:1074 329:1075 330:1076 331:1077 332:1078 333:1079 334:1080 335:1080 336:1081 337:1081 338:1081 339:1082 340:1083 341:1084 342:1085 343:1086 344:1087 345:1088 346:1089 347:1090 348:1090 349:1091 350:1091 351:1092 352:1093 353:1093 354:1094 355:1095 356:1096 357:1097 358:1097 359:1097 360:1098 361:1099 362:1100 363:1100 364:1101 365:1101 366:1102 367:1103 368:1104 369:1105 370:1105 371:1106 372:1107 373:1108 374:1108 375:1108 376:1109 377:1110 378:1111 379:1111 380:1111 381:1112 382:1112\n",
            "I0703 18:12:04.562547 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:852 8:852 9:852 10:853 11:854 12:854 13:854 14:854 15:855 16:856 17:856 18:857 19:858 20:859 21:860 22:860 23:860 24:860 25:861 26:862 27:863 28:864 29:865 30:866 31:867 32:867 33:868 34:869 35:870 36:871 37:872 38:873 39:874 40:875 41:876 42:877 43:878 44:879 45:879 46:880 47:881 48:882 49:882 50:883 51:884 52:884 53:884 54:884 55:885 56:885 57:886 58:887 59:888 60:889 61:890 62:890 63:891 64:892 65:893 66:894 67:895 68:896 69:897 70:897 71:898 72:899 73:900 74:901 75:902 76:903 77:904 78:905 79:906 80:907 81:907 82:907 83:907 84:908 85:909 86:910 87:911 88:912 89:913 90:914 91:914 92:915 93:916 94:916 95:917 96:918 97:919 98:920 99:920 100:920 101:920 102:921 103:922 104:923 105:924 106:924 107:925 108:926 109:927 110:928 111:929 112:929 113:929 114:929 115:930 116:930 117:930 118:931 119:931 120:931 121:932 122:932 123:932 124:933 125:933 126:933 127:933 128:933 129:933 130:934 131:935 132:936 133:937 134:937 135:938 136:939 137:940 138:941 139:942 140:943 141:943 142:943 143:944 144:944 145:945 146:946 147:947 148:947 149:948 150:949 151:950 152:951 153:952 154:953 155:954 156:954 157:955 158:955 159:956 160:957 161:958 162:959 163:960 164:961 165:962 166:963 167:964 168:965 169:966 170:967 171:968 172:968 173:968 174:969 175:970 176:970 177:971 178:971 179:971 180:971 181:971 182:971 183:972 184:973 185:973 186:974 187:975 188:976 189:976 190:976 191:976 192:976 193:977 194:978 195:979 196:980 197:981 198:982 199:982 200:982 201:982 202:983 203:983 204:984 205:984 206:985 207:986 208:987 209:988 210:989 211:989 212:990 213:991 214:992 215:993 216:994 217:994 218:995 219:996 220:997 221:998 222:998 223:999 224:1000 225:1000 226:1001 227:1002 228:1002 229:1002 230:1002 231:1003 232:1003 233:1004 234:1004 235:1005 236:1006 237:1007 238:1008 239:1009 240:1010 241:1010 242:1011 243:1012 244:1012 245:1013 246:1014 247:1015 248:1016 249:1017 250:1017 251:1017 252:1017 253:1018 254:1018 255:1019 256:1020 257:1021 258:1022 259:1023 260:1024 261:1024 262:1025 263:1026 264:1027 265:1028 266:1028 267:1029 268:1029 269:1030 270:1031 271:1032 272:1033 273:1034 274:1034 275:1034 276:1035 277:1036 278:1036 279:1037 280:1038 281:1039 282:1039 283:1040 284:1041 285:1042 286:1043 287:1044 288:1045 289:1046 290:1046 291:1047 292:1047 293:1047 294:1047 295:1048 296:1048 297:1049 298:1050 299:1051 300:1052 301:1053 302:1054 303:1054 304:1055 305:1056 306:1057 307:1057 308:1058 309:1059 310:1060 311:1061 312:1062 313:1063 314:1064 315:1065 316:1066 317:1066 318:1067 319:1067 320:1068 321:1069 322:1070 323:1071 324:1071 325:1072 326:1072 327:1073 328:1074 329:1075 330:1076 331:1077 332:1078 333:1079 334:1080 335:1080 336:1081 337:1081 338:1081 339:1082 340:1083 341:1084 342:1085 343:1086 344:1087 345:1088 346:1089 347:1090 348:1090 349:1091 350:1091 351:1092 352:1093 353:1093 354:1094 355:1095 356:1096 357:1097 358:1097 359:1097 360:1098 361:1099 362:1100 363:1100 364:1101 365:1101 366:1102 367:1103 368:1104 369:1105 370:1105 371:1106 372:1107 373:1108 374:1108 375:1108 376:1109 377:1110 378:1111 379:1111 380:1111 381:1112 382:1112\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.562913 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 102\n",
            "I0703 18:12:04.659042 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.659434 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.659715 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.665030 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000038\n",
            "I0703 18:12:04.665243 139789930788736 set_essential_params.py:432] unique_id: 1000000038\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.665337 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 10\n",
            "I0703 18:12:04.665436 139789930788736 set_essential_params.py:434] doc_span_index: 10\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing [SEP]\n",
            "I0703 18:12:04.665735 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:938 8:939 9:940 10:941 11:942 12:943 13:943 14:943 15:944 16:944 17:945 18:946 19:947 20:947 21:948 22:949 23:950 24:951 25:952 26:953 27:954 28:954 29:955 30:955 31:956 32:957 33:958 34:959 35:960 36:961 37:962 38:963 39:964 40:965 41:966 42:967 43:968 44:968 45:968 46:969 47:970 48:970 49:971 50:971 51:971 52:971 53:971 54:971 55:972 56:973 57:973 58:974 59:975 60:976 61:976 62:976 63:976 64:976 65:977 66:978 67:979 68:980 69:981 70:982 71:982 72:982 73:982 74:983 75:983 76:984 77:984 78:985 79:986 80:987 81:988 82:989 83:989 84:990 85:991 86:992 87:993 88:994 89:994 90:995 91:996 92:997 93:998 94:998 95:999 96:1000 97:1000 98:1001 99:1002 100:1002 101:1002 102:1002 103:1003 104:1003 105:1004 106:1004 107:1005 108:1006 109:1007 110:1008 111:1009 112:1010 113:1010 114:1011 115:1012 116:1012 117:1013 118:1014 119:1015 120:1016 121:1017 122:1017 123:1017 124:1017 125:1018 126:1018 127:1019 128:1020 129:1021 130:1022 131:1023 132:1024 133:1024 134:1025 135:1026 136:1027 137:1028 138:1028 139:1029 140:1029 141:1030 142:1031 143:1032 144:1033 145:1034 146:1034 147:1034 148:1035 149:1036 150:1036 151:1037 152:1038 153:1039 154:1039 155:1040 156:1041 157:1042 158:1043 159:1044 160:1045 161:1046 162:1046 163:1047 164:1047 165:1047 166:1047 167:1048 168:1048 169:1049 170:1050 171:1051 172:1052 173:1053 174:1054 175:1054 176:1055 177:1056 178:1057 179:1057 180:1058 181:1059 182:1060 183:1061 184:1062 185:1063 186:1064 187:1065 188:1066 189:1066 190:1067 191:1067 192:1068 193:1069 194:1070 195:1071 196:1071 197:1072 198:1072 199:1073 200:1074 201:1075 202:1076 203:1077 204:1078 205:1079 206:1080 207:1080 208:1081 209:1081 210:1081 211:1082 212:1083 213:1084 214:1085 215:1086 216:1087 217:1088 218:1089 219:1090 220:1090 221:1091 222:1091 223:1092 224:1093 225:1093 226:1094 227:1095 228:1096 229:1097 230:1097 231:1097 232:1098 233:1099 234:1100 235:1100 236:1101 237:1101 238:1102 239:1103 240:1104 241:1105 242:1105 243:1106 244:1107 245:1108 246:1108 247:1108 248:1109 249:1110 250:1111 251:1111 252:1111 253:1112 254:1112 255:1113 256:1114 257:1115 258:1115 259:1116 260:1117 261:1118 262:1119 263:1120 264:1121 265:1122 266:1122 267:1123 268:1124 269:1124 270:1124 271:1124 272:1125 273:1126 274:1126 275:1126 276:1127 277:1128 278:1129 279:1130 280:1130 281:1130 282:1131 283:1132 284:1133 285:1134 286:1134 287:1134 288:1134 289:1135 290:1136 291:1137 292:1138 293:1139 294:1139 295:1140 296:1141 297:1141 298:1142 299:1143 300:1144 301:1145 302:1146 303:1147 304:1148 305:1149 306:1150 307:1151 308:1151 309:1151 310:1152 311:1153 312:1154 313:1155 314:1155 315:1155 316:1156 317:1157 318:1158 319:1159 320:1160 321:1160 322:1161 323:1161 324:1161 325:1161 326:1161 327:1162 328:1162 329:1163 330:1164 331:1165 332:1165 333:1166 334:1167 335:1168 336:1169 337:1170 338:1171 339:1172 340:1173 341:1174 342:1175 343:1175 344:1176 345:1177 346:1178 347:1178 348:1179 349:1180 350:1181 351:1182 352:1182 353:1182 354:1182 355:1183 356:1184 357:1185 358:1186 359:1187 360:1188 361:1189 362:1190 363:1191 364:1192 365:1193 366:1194 367:1195 368:1196 369:1197 370:1198 371:1199 372:1200 373:1201 374:1202 375:1202 376:1203 377:1204 378:1204 379:1205 380:1206 381:1207 382:1207\n",
            "I0703 18:12:04.666089 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:938 8:939 9:940 10:941 11:942 12:943 13:943 14:943 15:944 16:944 17:945 18:946 19:947 20:947 21:948 22:949 23:950 24:951 25:952 26:953 27:954 28:954 29:955 30:955 31:956 32:957 33:958 34:959 35:960 36:961 37:962 38:963 39:964 40:965 41:966 42:967 43:968 44:968 45:968 46:969 47:970 48:970 49:971 50:971 51:971 52:971 53:971 54:971 55:972 56:973 57:973 58:974 59:975 60:976 61:976 62:976 63:976 64:976 65:977 66:978 67:979 68:980 69:981 70:982 71:982 72:982 73:982 74:983 75:983 76:984 77:984 78:985 79:986 80:987 81:988 82:989 83:989 84:990 85:991 86:992 87:993 88:994 89:994 90:995 91:996 92:997 93:998 94:998 95:999 96:1000 97:1000 98:1001 99:1002 100:1002 101:1002 102:1002 103:1003 104:1003 105:1004 106:1004 107:1005 108:1006 109:1007 110:1008 111:1009 112:1010 113:1010 114:1011 115:1012 116:1012 117:1013 118:1014 119:1015 120:1016 121:1017 122:1017 123:1017 124:1017 125:1018 126:1018 127:1019 128:1020 129:1021 130:1022 131:1023 132:1024 133:1024 134:1025 135:1026 136:1027 137:1028 138:1028 139:1029 140:1029 141:1030 142:1031 143:1032 144:1033 145:1034 146:1034 147:1034 148:1035 149:1036 150:1036 151:1037 152:1038 153:1039 154:1039 155:1040 156:1041 157:1042 158:1043 159:1044 160:1045 161:1046 162:1046 163:1047 164:1047 165:1047 166:1047 167:1048 168:1048 169:1049 170:1050 171:1051 172:1052 173:1053 174:1054 175:1054 176:1055 177:1056 178:1057 179:1057 180:1058 181:1059 182:1060 183:1061 184:1062 185:1063 186:1064 187:1065 188:1066 189:1066 190:1067 191:1067 192:1068 193:1069 194:1070 195:1071 196:1071 197:1072 198:1072 199:1073 200:1074 201:1075 202:1076 203:1077 204:1078 205:1079 206:1080 207:1080 208:1081 209:1081 210:1081 211:1082 212:1083 213:1084 214:1085 215:1086 216:1087 217:1088 218:1089 219:1090 220:1090 221:1091 222:1091 223:1092 224:1093 225:1093 226:1094 227:1095 228:1096 229:1097 230:1097 231:1097 232:1098 233:1099 234:1100 235:1100 236:1101 237:1101 238:1102 239:1103 240:1104 241:1105 242:1105 243:1106 244:1107 245:1108 246:1108 247:1108 248:1109 249:1110 250:1111 251:1111 252:1111 253:1112 254:1112 255:1113 256:1114 257:1115 258:1115 259:1116 260:1117 261:1118 262:1119 263:1120 264:1121 265:1122 266:1122 267:1123 268:1124 269:1124 270:1124 271:1124 272:1125 273:1126 274:1126 275:1126 276:1127 277:1128 278:1129 279:1130 280:1130 281:1130 282:1131 283:1132 284:1133 285:1134 286:1134 287:1134 288:1134 289:1135 290:1136 291:1137 292:1138 293:1139 294:1139 295:1140 296:1141 297:1141 298:1142 299:1143 300:1144 301:1145 302:1146 303:1147 304:1148 305:1149 306:1150 307:1151 308:1151 309:1151 310:1152 311:1153 312:1154 313:1155 314:1155 315:1155 316:1156 317:1157 318:1158 319:1159 320:1160 321:1160 322:1161 323:1161 324:1161 325:1161 326:1161 327:1162 328:1162 329:1163 330:1164 331:1165 332:1165 333:1166 334:1167 335:1168 336:1169 337:1170 338:1171 339:1172 340:1173 341:1174 342:1175 343:1175 344:1176 345:1177 346:1178 347:1178 348:1179 349:1180 350:1181 351:1182 352:1182 353:1182 354:1182 355:1183 356:1184 357:1185 358:1186 359:1187 360:1188 361:1189 362:1190 363:1191 364:1192 365:1193 366:1194 367:1195 368:1196 369:1197 370:1198 371:1199 372:1200 373:1201 374:1202 375:1202 376:1203 377:1204 378:1204 379:1205 380:1206 381:1207 382:1207\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.759972 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 102\n",
            "I0703 18:12:04.760643 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.761798 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.762503 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.766431 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000039\n",
            "I0703 18:12:04.766593 139789930788736 set_essential_params.py:432] unique_id: 1000000039\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.766690 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 11\n",
            "I0703 18:12:04.766779 139789930788736 set_essential_params.py:434] doc_span_index: 11\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win [SEP]\n",
            "I0703 18:12:04.767003 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:1026 8:1027 9:1028 10:1028 11:1029 12:1029 13:1030 14:1031 15:1032 16:1033 17:1034 18:1034 19:1034 20:1035 21:1036 22:1036 23:1037 24:1038 25:1039 26:1039 27:1040 28:1041 29:1042 30:1043 31:1044 32:1045 33:1046 34:1046 35:1047 36:1047 37:1047 38:1047 39:1048 40:1048 41:1049 42:1050 43:1051 44:1052 45:1053 46:1054 47:1054 48:1055 49:1056 50:1057 51:1057 52:1058 53:1059 54:1060 55:1061 56:1062 57:1063 58:1064 59:1065 60:1066 61:1066 62:1067 63:1067 64:1068 65:1069 66:1070 67:1071 68:1071 69:1072 70:1072 71:1073 72:1074 73:1075 74:1076 75:1077 76:1078 77:1079 78:1080 79:1080 80:1081 81:1081 82:1081 83:1082 84:1083 85:1084 86:1085 87:1086 88:1087 89:1088 90:1089 91:1090 92:1090 93:1091 94:1091 95:1092 96:1093 97:1093 98:1094 99:1095 100:1096 101:1097 102:1097 103:1097 104:1098 105:1099 106:1100 107:1100 108:1101 109:1101 110:1102 111:1103 112:1104 113:1105 114:1105 115:1106 116:1107 117:1108 118:1108 119:1108 120:1109 121:1110 122:1111 123:1111 124:1111 125:1112 126:1112 127:1113 128:1114 129:1115 130:1115 131:1116 132:1117 133:1118 134:1119 135:1120 136:1121 137:1122 138:1122 139:1123 140:1124 141:1124 142:1124 143:1124 144:1125 145:1126 146:1126 147:1126 148:1127 149:1128 150:1129 151:1130 152:1130 153:1130 154:1131 155:1132 156:1133 157:1134 158:1134 159:1134 160:1134 161:1135 162:1136 163:1137 164:1138 165:1139 166:1139 167:1140 168:1141 169:1141 170:1142 171:1143 172:1144 173:1145 174:1146 175:1147 176:1148 177:1149 178:1150 179:1151 180:1151 181:1151 182:1152 183:1153 184:1154 185:1155 186:1155 187:1155 188:1156 189:1157 190:1158 191:1159 192:1160 193:1160 194:1161 195:1161 196:1161 197:1161 198:1161 199:1162 200:1162 201:1163 202:1164 203:1165 204:1165 205:1166 206:1167 207:1168 208:1169 209:1170 210:1171 211:1172 212:1173 213:1174 214:1175 215:1175 216:1176 217:1177 218:1178 219:1178 220:1179 221:1180 222:1181 223:1182 224:1182 225:1182 226:1182 227:1183 228:1184 229:1185 230:1186 231:1187 232:1188 233:1189 234:1190 235:1191 236:1192 237:1193 238:1194 239:1195 240:1196 241:1197 242:1198 243:1199 244:1200 245:1201 246:1202 247:1202 248:1203 249:1204 250:1204 251:1205 252:1206 253:1207 254:1207 255:1207 256:1208 257:1209 258:1210 259:1211 260:1212 261:1213 262:1213 263:1213 264:1213 265:1214 266:1215 267:1216 268:1217 269:1218 270:1219 271:1220 272:1221 273:1222 274:1223 275:1224 276:1225 277:1226 278:1227 279:1228 280:1229 281:1230 282:1231 283:1231 284:1232 285:1233 286:1233 287:1234 288:1234 289:1235 290:1236 291:1237 292:1238 293:1239 294:1240 295:1241 296:1242 297:1243 298:1244 299:1245 300:1245 301:1245 302:1246 303:1246 304:1247 305:1248 306:1248 307:1248 308:1248 309:1249 310:1250 311:1251 312:1252 313:1253 314:1254 315:1255 316:1256 317:1257 318:1257 319:1258 320:1259 321:1259 322:1259 323:1259 324:1260 325:1261 326:1262 327:1263 328:1263 329:1264 330:1264 331:1265 332:1265 333:1265 334:1266 335:1267 336:1268 337:1268 338:1269 339:1270 340:1271 341:1272 342:1272 343:1273 344:1274 345:1275 346:1276 347:1277 348:1277 349:1277 350:1277 351:1278 352:1278 353:1279 354:1280 355:1281 356:1282 357:1282 358:1283 359:1284 360:1284 361:1285 362:1285 363:1285 364:1285 365:1286 366:1287 367:1288 368:1289 369:1290 370:1290 371:1291 372:1292 373:1293 374:1293 375:1294 376:1295 377:1296 378:1297 379:1298 380:1299 381:1300 382:1301\n",
            "I0703 18:12:04.767237 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:1026 8:1027 9:1028 10:1028 11:1029 12:1029 13:1030 14:1031 15:1032 16:1033 17:1034 18:1034 19:1034 20:1035 21:1036 22:1036 23:1037 24:1038 25:1039 26:1039 27:1040 28:1041 29:1042 30:1043 31:1044 32:1045 33:1046 34:1046 35:1047 36:1047 37:1047 38:1047 39:1048 40:1048 41:1049 42:1050 43:1051 44:1052 45:1053 46:1054 47:1054 48:1055 49:1056 50:1057 51:1057 52:1058 53:1059 54:1060 55:1061 56:1062 57:1063 58:1064 59:1065 60:1066 61:1066 62:1067 63:1067 64:1068 65:1069 66:1070 67:1071 68:1071 69:1072 70:1072 71:1073 72:1074 73:1075 74:1076 75:1077 76:1078 77:1079 78:1080 79:1080 80:1081 81:1081 82:1081 83:1082 84:1083 85:1084 86:1085 87:1086 88:1087 89:1088 90:1089 91:1090 92:1090 93:1091 94:1091 95:1092 96:1093 97:1093 98:1094 99:1095 100:1096 101:1097 102:1097 103:1097 104:1098 105:1099 106:1100 107:1100 108:1101 109:1101 110:1102 111:1103 112:1104 113:1105 114:1105 115:1106 116:1107 117:1108 118:1108 119:1108 120:1109 121:1110 122:1111 123:1111 124:1111 125:1112 126:1112 127:1113 128:1114 129:1115 130:1115 131:1116 132:1117 133:1118 134:1119 135:1120 136:1121 137:1122 138:1122 139:1123 140:1124 141:1124 142:1124 143:1124 144:1125 145:1126 146:1126 147:1126 148:1127 149:1128 150:1129 151:1130 152:1130 153:1130 154:1131 155:1132 156:1133 157:1134 158:1134 159:1134 160:1134 161:1135 162:1136 163:1137 164:1138 165:1139 166:1139 167:1140 168:1141 169:1141 170:1142 171:1143 172:1144 173:1145 174:1146 175:1147 176:1148 177:1149 178:1150 179:1151 180:1151 181:1151 182:1152 183:1153 184:1154 185:1155 186:1155 187:1155 188:1156 189:1157 190:1158 191:1159 192:1160 193:1160 194:1161 195:1161 196:1161 197:1161 198:1161 199:1162 200:1162 201:1163 202:1164 203:1165 204:1165 205:1166 206:1167 207:1168 208:1169 209:1170 210:1171 211:1172 212:1173 213:1174 214:1175 215:1175 216:1176 217:1177 218:1178 219:1178 220:1179 221:1180 222:1181 223:1182 224:1182 225:1182 226:1182 227:1183 228:1184 229:1185 230:1186 231:1187 232:1188 233:1189 234:1190 235:1191 236:1192 237:1193 238:1194 239:1195 240:1196 241:1197 242:1198 243:1199 244:1200 245:1201 246:1202 247:1202 248:1203 249:1204 250:1204 251:1205 252:1206 253:1207 254:1207 255:1207 256:1208 257:1209 258:1210 259:1211 260:1212 261:1213 262:1213 263:1213 264:1213 265:1214 266:1215 267:1216 268:1217 269:1218 270:1219 271:1220 272:1221 273:1222 274:1223 275:1224 276:1225 277:1226 278:1227 279:1228 280:1229 281:1230 282:1231 283:1231 284:1232 285:1233 286:1233 287:1234 288:1234 289:1235 290:1236 291:1237 292:1238 293:1239 294:1240 295:1241 296:1242 297:1243 298:1244 299:1245 300:1245 301:1245 302:1246 303:1246 304:1247 305:1248 306:1248 307:1248 308:1248 309:1249 310:1250 311:1251 312:1252 313:1253 314:1254 315:1255 316:1256 317:1257 318:1257 319:1258 320:1259 321:1259 322:1259 323:1259 324:1260 325:1261 326:1262 327:1263 328:1263 329:1264 330:1264 331:1265 332:1265 333:1265 334:1266 335:1267 336:1268 337:1268 338:1269 339:1270 340:1271 341:1272 342:1272 343:1273 344:1274 345:1275 346:1276 347:1277 348:1277 349:1277 350:1277 351:1278 352:1278 353:1279 354:1280 355:1281 356:1282 357:1282 358:1283 359:1284 360:1284 361:1285 362:1285 363:1285 364:1285 365:1286 366:1287 367:1288 368:1289 369:1290 370:1290 371:1291 372:1292 373:1293 374:1293 375:1294 376:1295 377:1296 378:1297 379:1298 380:1299 381:1300 382:1301\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.767679 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:False 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 102\n",
            "I0703 18:12:04.865802 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.866241 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.866568 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.872684 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000040\n",
            "I0703 18:12:04.872914 139789930788736 set_essential_params.py:432] unique_id: 1000000040\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.873015 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 12\n",
            "I0703 18:12:04.873103 139789930788736 set_essential_params.py:434] doc_span_index: 12\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh [SEP]\n",
            "I0703 18:12:04.873395 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:1120 8:1121 9:1122 10:1122 11:1123 12:1124 13:1124 14:1124 15:1124 16:1125 17:1126 18:1126 19:1126 20:1127 21:1128 22:1129 23:1130 24:1130 25:1130 26:1131 27:1132 28:1133 29:1134 30:1134 31:1134 32:1134 33:1135 34:1136 35:1137 36:1138 37:1139 38:1139 39:1140 40:1141 41:1141 42:1142 43:1143 44:1144 45:1145 46:1146 47:1147 48:1148 49:1149 50:1150 51:1151 52:1151 53:1151 54:1152 55:1153 56:1154 57:1155 58:1155 59:1155 60:1156 61:1157 62:1158 63:1159 64:1160 65:1160 66:1161 67:1161 68:1161 69:1161 70:1161 71:1162 72:1162 73:1163 74:1164 75:1165 76:1165 77:1166 78:1167 79:1168 80:1169 81:1170 82:1171 83:1172 84:1173 85:1174 86:1175 87:1175 88:1176 89:1177 90:1178 91:1178 92:1179 93:1180 94:1181 95:1182 96:1182 97:1182 98:1182 99:1183 100:1184 101:1185 102:1186 103:1187 104:1188 105:1189 106:1190 107:1191 108:1192 109:1193 110:1194 111:1195 112:1196 113:1197 114:1198 115:1199 116:1200 117:1201 118:1202 119:1202 120:1203 121:1204 122:1204 123:1205 124:1206 125:1207 126:1207 127:1207 128:1208 129:1209 130:1210 131:1211 132:1212 133:1213 134:1213 135:1213 136:1213 137:1214 138:1215 139:1216 140:1217 141:1218 142:1219 143:1220 144:1221 145:1222 146:1223 147:1224 148:1225 149:1226 150:1227 151:1228 152:1229 153:1230 154:1231 155:1231 156:1232 157:1233 158:1233 159:1234 160:1234 161:1235 162:1236 163:1237 164:1238 165:1239 166:1240 167:1241 168:1242 169:1243 170:1244 171:1245 172:1245 173:1245 174:1246 175:1246 176:1247 177:1248 178:1248 179:1248 180:1248 181:1249 182:1250 183:1251 184:1252 185:1253 186:1254 187:1255 188:1256 189:1257 190:1257 191:1258 192:1259 193:1259 194:1259 195:1259 196:1260 197:1261 198:1262 199:1263 200:1263 201:1264 202:1264 203:1265 204:1265 205:1265 206:1266 207:1267 208:1268 209:1268 210:1269 211:1270 212:1271 213:1272 214:1272 215:1273 216:1274 217:1275 218:1276 219:1277 220:1277 221:1277 222:1277 223:1278 224:1278 225:1279 226:1280 227:1281 228:1282 229:1282 230:1283 231:1284 232:1284 233:1285 234:1285 235:1285 236:1285 237:1286 238:1287 239:1288 240:1289 241:1290 242:1290 243:1291 244:1292 245:1293 246:1293 247:1294 248:1295 249:1296 250:1297 251:1298 252:1299 253:1300 254:1301 255:1301 256:1302 257:1302 258:1302 259:1303 260:1304 261:1304 262:1305 263:1306 264:1307 265:1308 266:1309 267:1310 268:1311 269:1312 270:1313 271:1313 272:1314 273:1315 274:1316 275:1316 276:1317 277:1318 278:1319 279:1320 280:1321 281:1322 282:1323 283:1323 284:1324 285:1325 286:1326 287:1326 288:1327 289:1327 290:1327 291:1327 292:1327 293:1327 294:1328 295:1329 296:1330 297:1331 298:1331 299:1332 300:1333 301:1334 302:1335 303:1335 304:1336 305:1337 306:1338 307:1339 308:1340 309:1340 310:1341 311:1342 312:1343 313:1344 314:1344 315:1345 316:1345 317:1346 318:1346 319:1346 320:1347 321:1347 322:1348 323:1349 324:1350 325:1351 326:1352 327:1353 328:1354 329:1355 330:1355 331:1356 332:1357 333:1357 334:1358 335:1358 336:1359 337:1359 338:1359 339:1360 340:1360 341:1361 342:1362 343:1363 344:1364 345:1365 346:1366 347:1367 348:1368 349:1369 350:1370 351:1370 352:1371 353:1371 354:1372 355:1372 356:1372 357:1373 358:1373 359:1374 360:1374 361:1374 362:1375 363:1376 364:1377 365:1378 366:1379 367:1380 368:1381 369:1382 370:1383 371:1383 372:1384 373:1385 374:1386 375:1387 376:1388 377:1389 378:1390 379:1391 380:1392 381:1393 382:1394\n",
            "I0703 18:12:04.966204 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:1120 8:1121 9:1122 10:1122 11:1123 12:1124 13:1124 14:1124 15:1124 16:1125 17:1126 18:1126 19:1126 20:1127 21:1128 22:1129 23:1130 24:1130 25:1130 26:1131 27:1132 28:1133 29:1134 30:1134 31:1134 32:1134 33:1135 34:1136 35:1137 36:1138 37:1139 38:1139 39:1140 40:1141 41:1141 42:1142 43:1143 44:1144 45:1145 46:1146 47:1147 48:1148 49:1149 50:1150 51:1151 52:1151 53:1151 54:1152 55:1153 56:1154 57:1155 58:1155 59:1155 60:1156 61:1157 62:1158 63:1159 64:1160 65:1160 66:1161 67:1161 68:1161 69:1161 70:1161 71:1162 72:1162 73:1163 74:1164 75:1165 76:1165 77:1166 78:1167 79:1168 80:1169 81:1170 82:1171 83:1172 84:1173 85:1174 86:1175 87:1175 88:1176 89:1177 90:1178 91:1178 92:1179 93:1180 94:1181 95:1182 96:1182 97:1182 98:1182 99:1183 100:1184 101:1185 102:1186 103:1187 104:1188 105:1189 106:1190 107:1191 108:1192 109:1193 110:1194 111:1195 112:1196 113:1197 114:1198 115:1199 116:1200 117:1201 118:1202 119:1202 120:1203 121:1204 122:1204 123:1205 124:1206 125:1207 126:1207 127:1207 128:1208 129:1209 130:1210 131:1211 132:1212 133:1213 134:1213 135:1213 136:1213 137:1214 138:1215 139:1216 140:1217 141:1218 142:1219 143:1220 144:1221 145:1222 146:1223 147:1224 148:1225 149:1226 150:1227 151:1228 152:1229 153:1230 154:1231 155:1231 156:1232 157:1233 158:1233 159:1234 160:1234 161:1235 162:1236 163:1237 164:1238 165:1239 166:1240 167:1241 168:1242 169:1243 170:1244 171:1245 172:1245 173:1245 174:1246 175:1246 176:1247 177:1248 178:1248 179:1248 180:1248 181:1249 182:1250 183:1251 184:1252 185:1253 186:1254 187:1255 188:1256 189:1257 190:1257 191:1258 192:1259 193:1259 194:1259 195:1259 196:1260 197:1261 198:1262 199:1263 200:1263 201:1264 202:1264 203:1265 204:1265 205:1265 206:1266 207:1267 208:1268 209:1268 210:1269 211:1270 212:1271 213:1272 214:1272 215:1273 216:1274 217:1275 218:1276 219:1277 220:1277 221:1277 222:1277 223:1278 224:1278 225:1279 226:1280 227:1281 228:1282 229:1282 230:1283 231:1284 232:1284 233:1285 234:1285 235:1285 236:1285 237:1286 238:1287 239:1288 240:1289 241:1290 242:1290 243:1291 244:1292 245:1293 246:1293 247:1294 248:1295 249:1296 250:1297 251:1298 252:1299 253:1300 254:1301 255:1301 256:1302 257:1302 258:1302 259:1303 260:1304 261:1304 262:1305 263:1306 264:1307 265:1308 266:1309 267:1310 268:1311 269:1312 270:1313 271:1313 272:1314 273:1315 274:1316 275:1316 276:1317 277:1318 278:1319 279:1320 280:1321 281:1322 282:1323 283:1323 284:1324 285:1325 286:1326 287:1326 288:1327 289:1327 290:1327 291:1327 292:1327 293:1327 294:1328 295:1329 296:1330 297:1331 298:1331 299:1332 300:1333 301:1334 302:1335 303:1335 304:1336 305:1337 306:1338 307:1339 308:1340 309:1340 310:1341 311:1342 312:1343 313:1344 314:1344 315:1345 316:1345 317:1346 318:1346 319:1346 320:1347 321:1347 322:1348 323:1349 324:1350 325:1351 326:1352 327:1353 328:1354 329:1355 330:1355 331:1356 332:1357 333:1357 334:1358 335:1358 336:1359 337:1359 338:1359 339:1360 340:1360 341:1361 342:1362 343:1363 344:1364 345:1365 346:1366 347:1367 348:1368 349:1369 350:1370 351:1370 352:1371 353:1371 354:1372 355:1372 356:1372 357:1373 358:1373 359:1374 360:1374 361:1374 362:1375 363:1376 364:1377 365:1378 366:1379 367:1380 368:1381 369:1382 370:1383 371:1383 372:1384 373:1385 374:1386 375:1387 376:1388 377:1389 378:1390 379:1391 380:1392 381:1393 382:1394\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:04.967287 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 102\n",
            "I0703 18:12:04.967781 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.968905 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:04.969480 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:04.972548 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000041\n",
            "I0703 18:12:04.972715 139789930788736 set_essential_params.py:432] unique_id: 1000000041\n",
            "INFO:tensorflow:example_index: 2\n",
            "I0703 18:12:04.972811 139789930788736 set_essential_params.py:433] example_index: 2\n",
            "INFO:tensorflow:doc_span_index: 13\n",
            "I0703 18:12:04.972898 139789930788736 set_essential_params.py:434] doc_span_index: 13\n",
            "INFO:tensorflow:tokens: [CLS] when was siemens founded ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "I0703 18:12:04.973091 139789930788736 set_essential_params.py:436] tokens: [CLS] when was siemens founded ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 7:1213 8:1213 9:1214 10:1215 11:1216 12:1217 13:1218 14:1219 15:1220 16:1221 17:1222 18:1223 19:1224 20:1225 21:1226 22:1227 23:1228 24:1229 25:1230 26:1231 27:1231 28:1232 29:1233 30:1233 31:1234 32:1234 33:1235 34:1236 35:1237 36:1238 37:1239 38:1240 39:1241 40:1242 41:1243 42:1244 43:1245 44:1245 45:1245 46:1246 47:1246 48:1247 49:1248 50:1248 51:1248 52:1248 53:1249 54:1250 55:1251 56:1252 57:1253 58:1254 59:1255 60:1256 61:1257 62:1257 63:1258 64:1259 65:1259 66:1259 67:1259 68:1260 69:1261 70:1262 71:1263 72:1263 73:1264 74:1264 75:1265 76:1265 77:1265 78:1266 79:1267 80:1268 81:1268 82:1269 83:1270 84:1271 85:1272 86:1272 87:1273 88:1274 89:1275 90:1276 91:1277 92:1277 93:1277 94:1277 95:1278 96:1278 97:1279 98:1280 99:1281 100:1282 101:1282 102:1283 103:1284 104:1284 105:1285 106:1285 107:1285 108:1285 109:1286 110:1287 111:1288 112:1289 113:1290 114:1290 115:1291 116:1292 117:1293 118:1293 119:1294 120:1295 121:1296 122:1297 123:1298 124:1299 125:1300 126:1301 127:1301 128:1302 129:1302 130:1302 131:1303 132:1304 133:1304 134:1305 135:1306 136:1307 137:1308 138:1309 139:1310 140:1311 141:1312 142:1313 143:1313 144:1314 145:1315 146:1316 147:1316 148:1317 149:1318 150:1319 151:1320 152:1321 153:1322 154:1323 155:1323 156:1324 157:1325 158:1326 159:1326 160:1327 161:1327 162:1327 163:1327 164:1327 165:1327 166:1328 167:1329 168:1330 169:1331 170:1331 171:1332 172:1333 173:1334 174:1335 175:1335 176:1336 177:1337 178:1338 179:1339 180:1340 181:1340 182:1341 183:1342 184:1343 185:1344 186:1344 187:1345 188:1345 189:1346 190:1346 191:1346 192:1347 193:1347 194:1348 195:1349 196:1350 197:1351 198:1352 199:1353 200:1354 201:1355 202:1355 203:1356 204:1357 205:1357 206:1358 207:1358 208:1359 209:1359 210:1359 211:1360 212:1360 213:1361 214:1362 215:1363 216:1364 217:1365 218:1366 219:1367 220:1368 221:1369 222:1370 223:1370 224:1371 225:1371 226:1372 227:1372 228:1372 229:1373 230:1373 231:1374 232:1374 233:1374 234:1375 235:1376 236:1377 237:1378 238:1379 239:1380 240:1381 241:1382 242:1383 243:1383 244:1384 245:1385 246:1386 247:1387 248:1388 249:1389 250:1390 251:1391 252:1392 253:1393 254:1394 255:1395 256:1396 257:1397 258:1398 259:1398 260:1399 261:1399 262:1400 263:1401 264:1402 265:1402 266:1403 267:1404 268:1405 269:1405 270:1406 271:1407 272:1408 273:1409 274:1410 275:1411 276:1412 277:1413 278:1414 279:1414 280:1415 281:1415\n",
            "I0703 18:12:04.973298 139789930788736 set_essential_params.py:438] token_to_orig_map: 7:1213 8:1213 9:1214 10:1215 11:1216 12:1217 13:1218 14:1219 15:1220 16:1221 17:1222 18:1223 19:1224 20:1225 21:1226 22:1227 23:1228 24:1229 25:1230 26:1231 27:1231 28:1232 29:1233 30:1233 31:1234 32:1234 33:1235 34:1236 35:1237 36:1238 37:1239 38:1240 39:1241 40:1242 41:1243 42:1244 43:1245 44:1245 45:1245 46:1246 47:1246 48:1247 49:1248 50:1248 51:1248 52:1248 53:1249 54:1250 55:1251 56:1252 57:1253 58:1254 59:1255 60:1256 61:1257 62:1257 63:1258 64:1259 65:1259 66:1259 67:1259 68:1260 69:1261 70:1262 71:1263 72:1263 73:1264 74:1264 75:1265 76:1265 77:1265 78:1266 79:1267 80:1268 81:1268 82:1269 83:1270 84:1271 85:1272 86:1272 87:1273 88:1274 89:1275 90:1276 91:1277 92:1277 93:1277 94:1277 95:1278 96:1278 97:1279 98:1280 99:1281 100:1282 101:1282 102:1283 103:1284 104:1284 105:1285 106:1285 107:1285 108:1285 109:1286 110:1287 111:1288 112:1289 113:1290 114:1290 115:1291 116:1292 117:1293 118:1293 119:1294 120:1295 121:1296 122:1297 123:1298 124:1299 125:1300 126:1301 127:1301 128:1302 129:1302 130:1302 131:1303 132:1304 133:1304 134:1305 135:1306 136:1307 137:1308 138:1309 139:1310 140:1311 141:1312 142:1313 143:1313 144:1314 145:1315 146:1316 147:1316 148:1317 149:1318 150:1319 151:1320 152:1321 153:1322 154:1323 155:1323 156:1324 157:1325 158:1326 159:1326 160:1327 161:1327 162:1327 163:1327 164:1327 165:1327 166:1328 167:1329 168:1330 169:1331 170:1331 171:1332 172:1333 173:1334 174:1335 175:1335 176:1336 177:1337 178:1338 179:1339 180:1340 181:1340 182:1341 183:1342 184:1343 185:1344 186:1344 187:1345 188:1345 189:1346 190:1346 191:1346 192:1347 193:1347 194:1348 195:1349 196:1350 197:1351 198:1352 199:1353 200:1354 201:1355 202:1355 203:1356 204:1357 205:1357 206:1358 207:1358 208:1359 209:1359 210:1359 211:1360 212:1360 213:1361 214:1362 215:1363 216:1364 217:1365 218:1366 219:1367 220:1368 221:1369 222:1370 223:1370 224:1371 225:1371 226:1372 227:1372 228:1372 229:1373 230:1373 231:1374 232:1374 233:1374 234:1375 235:1376 236:1377 237:1378 238:1379 239:1380 240:1381 241:1382 242:1383 243:1383 244:1384 245:1385 246:1386 247:1387 248:1388 249:1389 250:1390 251:1391 252:1392 253:1393 254:1394 255:1395 256:1396 257:1397 258:1398 259:1398 260:1399 261:1399 262:1400 263:1401 264:1402 265:1402 266:1403 267:1404 268:1405 269:1405 270:1406 271:1407 272:1408 273:1409 274:1410 275:1411 276:1412 277:1413 278:1414 279:1414 280:1415 281:1415\n",
            "INFO:tensorflow:token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True\n",
            "I0703 18:12:04.973507 139789930788736 set_essential_params.py:440] token_is_max_context: 7:False 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 22108 2631 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:04.973738 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 22108 2631 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:05.073270 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:05.073662 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.124425 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000042\n",
            "I0703 18:12:05.124705 139789930788736 set_essential_params.py:432] unique_id: 1000000042\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.124813 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:12:05.124902 139789930788736 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to [SEP]\n",
            "I0703 18:12:05.125125 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:12 26:13 27:14 28:15 29:16 30:16 31:17 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:39 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:42 65:42 66:42 67:43 68:44 69:45 70:46 71:46 72:46 73:47 74:48 75:49 76:50 77:51 78:52 79:53 80:54 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:64 93:65 94:65 95:66 96:67 97:67 98:68 99:69 100:70 101:71 102:72 103:73 104:73 105:73 106:74 107:75 108:76 109:77 110:77 111:78 112:79 113:80 114:81 115:82 116:83 117:84 118:85 119:85 120:86 121:87 122:87 123:88 124:89 125:89 126:89 127:90 128:91 129:91 130:92 131:93 132:94 133:94 134:95 135:96 136:97 137:98 138:98 139:99 140:100 141:101 142:102 143:103 144:104 145:105 146:105 147:106 148:107 149:108 150:109 151:110 152:111 153:112 154:113 155:114 156:114 157:115 158:116 159:117 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:124 169:124 170:125 171:126 172:127 173:128 174:128 175:129 176:130 177:130 178:131 179:132 180:133 181:134 182:135 183:136 184:137 185:137 186:138 187:139 188:140 189:141 190:141 191:142 192:143 193:144 194:145 195:145 196:146 197:146 198:147 199:148 200:148 201:149 202:150 203:151 204:152 205:153 206:153 207:153 208:154 209:155 210:156 211:157 212:158 213:158 214:158 215:159 216:160 217:161 218:162 219:163 220:163 221:164 222:165 223:166 224:166 225:167 226:168 227:169 228:170 229:171 230:172 231:173 232:174 233:175 234:175 235:176 236:177 237:177 238:178 239:179 240:180 241:181 242:182 243:183 244:184 245:185 246:186 247:186 248:186 249:187 250:188 251:189 252:190 253:191 254:192 255:193 256:194 257:195 258:195 259:196 260:196 261:197 262:198 263:199 264:199 265:199 266:200 267:201 268:202 269:203 270:204 271:205 272:206 273:207 274:208 275:209 276:209 277:210 278:211 279:211 280:212 281:213 282:214 283:215 284:215 285:216 286:217 287:218 288:219 289:219 290:220 291:221 292:222 293:223 294:224 295:225 296:225 297:225 298:226 299:227 300:228 301:229 302:230 303:231 304:232 305:233 306:234 307:234 308:234 309:234 310:235 311:236 312:236 313:237 314:238 315:239 316:240 317:241 318:242 319:243 320:244 321:245 322:246 323:247 324:248 325:249 326:249 327:250 328:251 329:251 330:252 331:253 332:254 333:255 334:256 335:257 336:258 337:259 338:260 339:260 340:260 341:260 342:261 343:262 344:263 345:263 346:263 347:264 348:265 349:266 350:267 351:268 352:269 353:270 354:271 355:271 356:272 357:272 358:273 359:274 360:274 361:275 362:276 363:277 364:278 365:279 366:280 367:281 368:281 369:282 370:283 371:283 372:284 373:285 374:286 375:287 376:288 377:289 378:290 379:291 380:292 381:293 382:294\n",
            "I0703 18:12:05.125371 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:0 12:1 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:12 26:13 27:14 28:15 29:16 30:16 31:17 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:39 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:42 65:42 66:42 67:43 68:44 69:45 70:46 71:46 72:46 73:47 74:48 75:49 76:50 77:51 78:52 79:53 80:54 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:64 93:65 94:65 95:66 96:67 97:67 98:68 99:69 100:70 101:71 102:72 103:73 104:73 105:73 106:74 107:75 108:76 109:77 110:77 111:78 112:79 113:80 114:81 115:82 116:83 117:84 118:85 119:85 120:86 121:87 122:87 123:88 124:89 125:89 126:89 127:90 128:91 129:91 130:92 131:93 132:94 133:94 134:95 135:96 136:97 137:98 138:98 139:99 140:100 141:101 142:102 143:103 144:104 145:105 146:105 147:106 148:107 149:108 150:109 151:110 152:111 153:112 154:113 155:114 156:114 157:115 158:116 159:117 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:124 169:124 170:125 171:126 172:127 173:128 174:128 175:129 176:130 177:130 178:131 179:132 180:133 181:134 182:135 183:136 184:137 185:137 186:138 187:139 188:140 189:141 190:141 191:142 192:143 193:144 194:145 195:145 196:146 197:146 198:147 199:148 200:148 201:149 202:150 203:151 204:152 205:153 206:153 207:153 208:154 209:155 210:156 211:157 212:158 213:158 214:158 215:159 216:160 217:161 218:162 219:163 220:163 221:164 222:165 223:166 224:166 225:167 226:168 227:169 228:170 229:171 230:172 231:173 232:174 233:175 234:175 235:176 236:177 237:177 238:178 239:179 240:180 241:181 242:182 243:183 244:184 245:185 246:186 247:186 248:186 249:187 250:188 251:189 252:190 253:191 254:192 255:193 256:194 257:195 258:195 259:196 260:196 261:197 262:198 263:199 264:199 265:199 266:200 267:201 268:202 269:203 270:204 271:205 272:206 273:207 274:208 275:209 276:209 277:210 278:211 279:211 280:212 281:213 282:214 283:215 284:215 285:216 286:217 287:218 288:219 289:219 290:220 291:221 292:222 293:223 294:224 295:225 296:225 297:225 298:226 299:227 300:228 301:229 302:230 303:231 304:232 305:233 306:234 307:234 308:234 309:234 310:235 311:236 312:236 313:237 314:238 315:239 316:240 317:241 318:242 319:243 320:244 321:245 322:246 323:247 324:248 325:249 326:249 327:250 328:251 329:251 330:252 331:253 332:254 333:255 334:256 335:257 336:258 337:259 338:260 339:260 340:260 341:260 342:261 343:262 344:263 345:263 346:263 347:264 348:265 349:266 350:267 351:268 352:269 353:270 354:271 355:271 356:272 357:272 358:273 359:274 360:274 361:275 362:276 363:277 364:278 365:279 366:280 367:281 368:281 369:282 370:283 371:283 372:284 373:285 374:286 375:287 376:288 377:289 378:290 379:291 380:292 381:293 382:294\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.172452 139789930788736 set_essential_params.py:440] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 102\n",
            "I0703 18:12:05.173034 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.173597 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.173904 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.177907 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000043\n",
            "I0703 18:12:05.178091 139789930788736 set_essential_params.py:432] unique_id: 1000000043\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.178188 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "I0703 18:12:05.178272 139789930788736 set_essential_params.py:434] doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees [SEP]\n",
            "I0703 18:12:05.178652 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:99 12:100 13:101 14:102 15:103 16:104 17:105 18:105 19:106 20:107 21:108 22:109 23:110 24:111 25:112 26:113 27:114 28:114 29:115 30:116 31:117 32:117 33:118 34:119 35:120 36:121 37:122 38:123 39:124 40:124 41:124 42:125 43:126 44:127 45:128 46:128 47:129 48:130 49:130 50:131 51:132 52:133 53:134 54:135 55:136 56:137 57:137 58:138 59:139 60:140 61:141 62:141 63:142 64:143 65:144 66:145 67:145 68:146 69:146 70:147 71:148 72:148 73:149 74:150 75:151 76:152 77:153 78:153 79:153 80:154 81:155 82:156 83:157 84:158 85:158 86:158 87:159 88:160 89:161 90:162 91:163 92:163 93:164 94:165 95:166 96:166 97:167 98:168 99:169 100:170 101:171 102:172 103:173 104:174 105:175 106:175 107:176 108:177 109:177 110:178 111:179 112:180 113:181 114:182 115:183 116:184 117:185 118:186 119:186 120:186 121:187 122:188 123:189 124:190 125:191 126:192 127:193 128:194 129:195 130:195 131:196 132:196 133:197 134:198 135:199 136:199 137:199 138:200 139:201 140:202 141:203 142:204 143:205 144:206 145:207 146:208 147:209 148:209 149:210 150:211 151:211 152:212 153:213 154:214 155:215 156:215 157:216 158:217 159:218 160:219 161:219 162:220 163:221 164:222 165:223 166:224 167:225 168:225 169:225 170:226 171:227 172:228 173:229 174:230 175:231 176:232 177:233 178:234 179:234 180:234 181:234 182:235 183:236 184:236 185:237 186:238 187:239 188:240 189:241 190:242 191:243 192:244 193:245 194:246 195:247 196:248 197:249 198:249 199:250 200:251 201:251 202:252 203:253 204:254 205:255 206:256 207:257 208:258 209:259 210:260 211:260 212:260 213:260 214:261 215:262 216:263 217:263 218:263 219:264 220:265 221:266 222:267 223:268 224:269 225:270 226:271 227:271 228:272 229:272 230:273 231:274 232:274 233:275 234:276 235:277 236:278 237:279 238:280 239:281 240:281 241:282 242:283 243:283 244:284 245:285 246:286 247:287 248:288 249:289 250:290 251:291 252:292 253:293 254:294 255:295 256:296 257:297 258:298 259:299 260:300 261:301 262:302 263:302 264:303 265:304 266:304 267:305 268:306 269:307 270:308 271:309 272:310 273:311 274:312 275:313 276:314 277:315 278:315 279:316 280:317 281:318 282:319 283:320 284:321 285:321 286:322 287:323 288:324 289:325 290:326 291:327 292:328 293:329 294:330 295:331 296:332 297:333 298:334 299:335 300:336 301:337 302:338 303:338 304:339 305:340 306:341 307:341 308:342 309:342 310:343 311:344 312:344 313:345 314:346 315:347 316:348 317:348 318:349 319:350 320:351 321:352 322:353 323:354 324:355 325:356 326:357 327:357 328:357 329:357 330:358 331:359 332:359 333:359 334:360 335:361 336:362 337:363 338:364 339:365 340:365 341:365 342:365 343:365 344:365 345:365 346:366 347:367 348:367 349:368 350:369 351:369 352:370 353:371 354:371 355:372 356:373 357:373 358:373 359:373 360:373 361:373 362:373 363:374 364:375 365:375 366:375 367:376 368:377 369:378 370:379 371:380 372:380 373:380 374:381 375:382 376:383 377:384 378:385 379:386 380:387 381:388 382:389\n",
            "I0703 18:12:05.179015 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:99 12:100 13:101 14:102 15:103 16:104 17:105 18:105 19:106 20:107 21:108 22:109 23:110 24:111 25:112 26:113 27:114 28:114 29:115 30:116 31:117 32:117 33:118 34:119 35:120 36:121 37:122 38:123 39:124 40:124 41:124 42:125 43:126 44:127 45:128 46:128 47:129 48:130 49:130 50:131 51:132 52:133 53:134 54:135 55:136 56:137 57:137 58:138 59:139 60:140 61:141 62:141 63:142 64:143 65:144 66:145 67:145 68:146 69:146 70:147 71:148 72:148 73:149 74:150 75:151 76:152 77:153 78:153 79:153 80:154 81:155 82:156 83:157 84:158 85:158 86:158 87:159 88:160 89:161 90:162 91:163 92:163 93:164 94:165 95:166 96:166 97:167 98:168 99:169 100:170 101:171 102:172 103:173 104:174 105:175 106:175 107:176 108:177 109:177 110:178 111:179 112:180 113:181 114:182 115:183 116:184 117:185 118:186 119:186 120:186 121:187 122:188 123:189 124:190 125:191 126:192 127:193 128:194 129:195 130:195 131:196 132:196 133:197 134:198 135:199 136:199 137:199 138:200 139:201 140:202 141:203 142:204 143:205 144:206 145:207 146:208 147:209 148:209 149:210 150:211 151:211 152:212 153:213 154:214 155:215 156:215 157:216 158:217 159:218 160:219 161:219 162:220 163:221 164:222 165:223 166:224 167:225 168:225 169:225 170:226 171:227 172:228 173:229 174:230 175:231 176:232 177:233 178:234 179:234 180:234 181:234 182:235 183:236 184:236 185:237 186:238 187:239 188:240 189:241 190:242 191:243 192:244 193:245 194:246 195:247 196:248 197:249 198:249 199:250 200:251 201:251 202:252 203:253 204:254 205:255 206:256 207:257 208:258 209:259 210:260 211:260 212:260 213:260 214:261 215:262 216:263 217:263 218:263 219:264 220:265 221:266 222:267 223:268 224:269 225:270 226:271 227:271 228:272 229:272 230:273 231:274 232:274 233:275 234:276 235:277 236:278 237:279 238:280 239:281 240:281 241:282 242:283 243:283 244:284 245:285 246:286 247:287 248:288 249:289 250:290 251:291 252:292 253:293 254:294 255:295 256:296 257:297 258:298 259:299 260:300 261:301 262:302 263:302 264:303 265:304 266:304 267:305 268:306 269:307 270:308 271:309 272:310 273:311 274:312 275:313 276:314 277:315 278:315 279:316 280:317 281:318 282:319 283:320 284:321 285:321 286:322 287:323 288:324 289:325 290:326 291:327 292:328 293:329 294:330 295:331 296:332 297:333 298:334 299:335 300:336 301:337 302:338 303:338 304:339 305:340 306:341 307:341 308:342 309:342 310:343 311:344 312:344 313:345 314:346 315:347 316:348 317:348 318:349 319:350 320:351 321:352 322:353 323:354 324:355 325:356 326:357 327:357 328:357 329:357 330:358 331:359 332:359 333:359 334:360 335:361 336:362 337:363 338:364 339:365 340:365 341:365 342:365 343:365 344:365 345:365 346:366 347:367 348:367 349:368 350:369 351:369 352:370 353:371 354:371 355:372 356:373 357:373 358:373 359:373 360:373 361:373 362:373 363:374 364:375 365:375 366:375 367:376 368:377 369:378 370:379 371:380 372:380 373:380 374:381 375:382 376:383 377:384 378:385 379:386 380:387 381:388 382:389\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.179255 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 102\n",
            "I0703 18:12:05.278285 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.278754 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.279047 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.284227 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000044\n",
            "I0703 18:12:05.284504 139789930788736 set_essential_params.py:432] unique_id: 1000000044\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.284597 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "I0703 18:12:05.284675 139789930788736 set_essential_params.py:434] doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - [SEP]\n",
            "I0703 18:12:05.284949 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:201 12:202 13:203 14:204 15:205 16:206 17:207 18:208 19:209 20:209 21:210 22:211 23:211 24:212 25:213 26:214 27:215 28:215 29:216 30:217 31:218 32:219 33:219 34:220 35:221 36:222 37:223 38:224 39:225 40:225 41:225 42:226 43:227 44:228 45:229 46:230 47:231 48:232 49:233 50:234 51:234 52:234 53:234 54:235 55:236 56:236 57:237 58:238 59:239 60:240 61:241 62:242 63:243 64:244 65:245 66:246 67:247 68:248 69:249 70:249 71:250 72:251 73:251 74:252 75:253 76:254 77:255 78:256 79:257 80:258 81:259 82:260 83:260 84:260 85:260 86:261 87:262 88:263 89:263 90:263 91:264 92:265 93:266 94:267 95:268 96:269 97:270 98:271 99:271 100:272 101:272 102:273 103:274 104:274 105:275 106:276 107:277 108:278 109:279 110:280 111:281 112:281 113:282 114:283 115:283 116:284 117:285 118:286 119:287 120:288 121:289 122:290 123:291 124:292 125:293 126:294 127:295 128:296 129:297 130:298 131:299 132:300 133:301 134:302 135:302 136:303 137:304 138:304 139:305 140:306 141:307 142:308 143:309 144:310 145:311 146:312 147:313 148:314 149:315 150:315 151:316 152:317 153:318 154:319 155:320 156:321 157:321 158:322 159:323 160:324 161:325 162:326 163:327 164:328 165:329 166:330 167:331 168:332 169:333 170:334 171:335 172:336 173:337 174:338 175:338 176:339 177:340 178:341 179:341 180:342 181:342 182:343 183:344 184:344 185:345 186:346 187:347 188:348 189:348 190:349 191:350 192:351 193:352 194:353 195:354 196:355 197:356 198:357 199:357 200:357 201:357 202:358 203:359 204:359 205:359 206:360 207:361 208:362 209:363 210:364 211:365 212:365 213:365 214:365 215:365 216:365 217:365 218:366 219:367 220:367 221:368 222:369 223:369 224:370 225:371 226:371 227:372 228:373 229:373 230:373 231:373 232:373 233:373 234:373 235:374 236:375 237:375 238:375 239:376 240:377 241:378 242:379 243:380 244:380 245:380 246:381 247:382 248:383 249:384 250:385 251:386 252:387 253:388 254:389 255:389 256:390 257:391 258:391 259:392 260:393 261:394 262:395 263:396 264:397 265:398 266:399 267:400 268:401 269:402 270:402 271:403 272:403 273:403 274:404 275:404 276:405 277:406 278:407 279:408 280:409 281:410 282:411 283:411 284:412 285:413 286:414 287:415 288:416 289:416 290:417 291:418 292:419 293:420 294:421 295:422 296:423 297:423 298:424 299:425 300:425 301:426 302:427 303:428 304:428 305:428 306:429 307:430 308:430 309:431 310:431 311:431 312:432 313:432 314:432 315:433 316:434 317:434 318:435 319:435 320:435 321:435 322:435 323:435 324:436 325:436 326:436 327:437 328:438 329:438 330:438 331:438 332:438 333:438 334:439 335:440 336:440 337:440 338:440 339:440 340:440 341:440 342:440 343:441 344:441 345:442 346:442 347:442 348:443 349:444 350:445 351:446 352:447 353:447 354:447 355:447 356:447 357:447 358:447 359:448 360:449 361:449 362:449 363:449 364:449 365:450 366:451 367:452 368:453 369:454 370:454 371:454 372:455 373:456 374:457 375:458 376:459 377:460 378:461 379:462 380:463 381:464 382:464\n",
            "I0703 18:12:05.285300 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:201 12:202 13:203 14:204 15:205 16:206 17:207 18:208 19:209 20:209 21:210 22:211 23:211 24:212 25:213 26:214 27:215 28:215 29:216 30:217 31:218 32:219 33:219 34:220 35:221 36:222 37:223 38:224 39:225 40:225 41:225 42:226 43:227 44:228 45:229 46:230 47:231 48:232 49:233 50:234 51:234 52:234 53:234 54:235 55:236 56:236 57:237 58:238 59:239 60:240 61:241 62:242 63:243 64:244 65:245 66:246 67:247 68:248 69:249 70:249 71:250 72:251 73:251 74:252 75:253 76:254 77:255 78:256 79:257 80:258 81:259 82:260 83:260 84:260 85:260 86:261 87:262 88:263 89:263 90:263 91:264 92:265 93:266 94:267 95:268 96:269 97:270 98:271 99:271 100:272 101:272 102:273 103:274 104:274 105:275 106:276 107:277 108:278 109:279 110:280 111:281 112:281 113:282 114:283 115:283 116:284 117:285 118:286 119:287 120:288 121:289 122:290 123:291 124:292 125:293 126:294 127:295 128:296 129:297 130:298 131:299 132:300 133:301 134:302 135:302 136:303 137:304 138:304 139:305 140:306 141:307 142:308 143:309 144:310 145:311 146:312 147:313 148:314 149:315 150:315 151:316 152:317 153:318 154:319 155:320 156:321 157:321 158:322 159:323 160:324 161:325 162:326 163:327 164:328 165:329 166:330 167:331 168:332 169:333 170:334 171:335 172:336 173:337 174:338 175:338 176:339 177:340 178:341 179:341 180:342 181:342 182:343 183:344 184:344 185:345 186:346 187:347 188:348 189:348 190:349 191:350 192:351 193:352 194:353 195:354 196:355 197:356 198:357 199:357 200:357 201:357 202:358 203:359 204:359 205:359 206:360 207:361 208:362 209:363 210:364 211:365 212:365 213:365 214:365 215:365 216:365 217:365 218:366 219:367 220:367 221:368 222:369 223:369 224:370 225:371 226:371 227:372 228:373 229:373 230:373 231:373 232:373 233:373 234:373 235:374 236:375 237:375 238:375 239:376 240:377 241:378 242:379 243:380 244:380 245:380 246:381 247:382 248:383 249:384 250:385 251:386 252:387 253:388 254:389 255:389 256:390 257:391 258:391 259:392 260:393 261:394 262:395 263:396 264:397 265:398 266:399 267:400 268:401 269:402 270:402 271:403 272:403 273:403 274:404 275:404 276:405 277:406 278:407 279:408 280:409 281:410 282:411 283:411 284:412 285:413 286:414 287:415 288:416 289:416 290:417 291:418 292:419 293:420 294:421 295:422 296:423 297:423 298:424 299:425 300:425 301:426 302:427 303:428 304:428 305:428 306:429 307:430 308:430 309:431 310:431 311:431 312:432 313:432 314:432 315:433 316:434 317:434 318:435 319:435 320:435 321:435 322:435 323:435 324:436 325:436 326:436 327:437 328:438 329:438 330:438 331:438 332:438 333:438 334:439 335:440 336:440 337:440 338:440 339:440 340:440 341:440 342:440 343:441 344:441 345:442 346:442 347:442 348:443 349:444 350:445 351:446 352:447 353:447 354:447 355:447 356:447 357:447 358:447 359:448 360:449 361:449 362:449 363:449 364:449 365:450 366:451 367:452 368:453 369:454 370:454 371:454 372:455 373:456 374:457 375:458 376:459 377:460 378:461 379:462 380:463 381:464 382:464\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.377949 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 102\n",
            "I0703 18:12:05.380245 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.380599 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.380813 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.383894 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000045\n",
            "I0703 18:12:05.384084 139789930788736 set_essential_params.py:432] unique_id: 1000000045\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.384196 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 3\n",
            "I0703 18:12:05.384293 139789930788736 set_essential_params.py:434] doc_span_index: 3\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the [SEP]\n",
            "I0703 18:12:05.384616 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:305 12:306 13:307 14:308 15:309 16:310 17:311 18:312 19:313 20:314 21:315 22:315 23:316 24:317 25:318 26:319 27:320 28:321 29:321 30:322 31:323 32:324 33:325 34:326 35:327 36:328 37:329 38:330 39:331 40:332 41:333 42:334 43:335 44:336 45:337 46:338 47:338 48:339 49:340 50:341 51:341 52:342 53:342 54:343 55:344 56:344 57:345 58:346 59:347 60:348 61:348 62:349 63:350 64:351 65:352 66:353 67:354 68:355 69:356 70:357 71:357 72:357 73:357 74:358 75:359 76:359 77:359 78:360 79:361 80:362 81:363 82:364 83:365 84:365 85:365 86:365 87:365 88:365 89:365 90:366 91:367 92:367 93:368 94:369 95:369 96:370 97:371 98:371 99:372 100:373 101:373 102:373 103:373 104:373 105:373 106:373 107:374 108:375 109:375 110:375 111:376 112:377 113:378 114:379 115:380 116:380 117:380 118:381 119:382 120:383 121:384 122:385 123:386 124:387 125:388 126:389 127:389 128:390 129:391 130:391 131:392 132:393 133:394 134:395 135:396 136:397 137:398 138:399 139:400 140:401 141:402 142:402 143:403 144:403 145:403 146:404 147:404 148:405 149:406 150:407 151:408 152:409 153:410 154:411 155:411 156:412 157:413 158:414 159:415 160:416 161:416 162:417 163:418 164:419 165:420 166:421 167:422 168:423 169:423 170:424 171:425 172:425 173:426 174:427 175:428 176:428 177:428 178:429 179:430 180:430 181:431 182:431 183:431 184:432 185:432 186:432 187:433 188:434 189:434 190:435 191:435 192:435 193:435 194:435 195:435 196:436 197:436 198:436 199:437 200:438 201:438 202:438 203:438 204:438 205:438 206:439 207:440 208:440 209:440 210:440 211:440 212:440 213:440 214:440 215:441 216:441 217:442 218:442 219:442 220:443 221:444 222:445 223:446 224:447 225:447 226:447 227:447 228:447 229:447 230:447 231:448 232:449 233:449 234:449 235:449 236:449 237:450 238:451 239:452 240:453 241:454 242:454 243:454 244:455 245:456 246:457 247:458 248:459 249:460 250:461 251:462 252:463 253:464 254:464 255:464 256:465 257:466 258:466 259:467 260:468 261:469 262:469 263:470 264:471 265:472 266:473 267:473 268:473 269:473 270:473 271:474 272:475 273:476 274:477 275:478 276:479 277:480 278:481 279:482 280:483 281:484 282:485 283:486 284:486 285:487 286:488 287:489 288:490 289:491 290:492 291:493 292:494 293:495 294:495 295:496 296:497 297:498 298:499 299:500 300:501 301:502 302:503 303:504 304:505 305:506 306:507 307:508 308:509 309:509 310:509 311:510 312:511 313:512 314:513 315:514 316:514 317:514 318:515 319:516 320:517 321:517 322:518 323:519 324:519 325:519 326:519 327:520 328:520 329:521 330:522 331:522 332:523 333:524 334:524 335:525 336:525 337:525 338:525 339:525 340:525 341:525 342:526 343:527 344:528 345:529 346:530 347:531 348:532 349:533 350:534 351:534 352:534 353:534 354:535 355:535 356:536 357:537 358:538 359:539 360:540 361:541 362:542 363:543 364:544 365:544 366:545 367:546 368:547 369:548 370:548 371:549 372:550 373:550 374:551 375:552 376:553 377:554 378:555 379:556 380:557 381:558 382:559\n",
            "I0703 18:12:05.385013 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:305 12:306 13:307 14:308 15:309 16:310 17:311 18:312 19:313 20:314 21:315 22:315 23:316 24:317 25:318 26:319 27:320 28:321 29:321 30:322 31:323 32:324 33:325 34:326 35:327 36:328 37:329 38:330 39:331 40:332 41:333 42:334 43:335 44:336 45:337 46:338 47:338 48:339 49:340 50:341 51:341 52:342 53:342 54:343 55:344 56:344 57:345 58:346 59:347 60:348 61:348 62:349 63:350 64:351 65:352 66:353 67:354 68:355 69:356 70:357 71:357 72:357 73:357 74:358 75:359 76:359 77:359 78:360 79:361 80:362 81:363 82:364 83:365 84:365 85:365 86:365 87:365 88:365 89:365 90:366 91:367 92:367 93:368 94:369 95:369 96:370 97:371 98:371 99:372 100:373 101:373 102:373 103:373 104:373 105:373 106:373 107:374 108:375 109:375 110:375 111:376 112:377 113:378 114:379 115:380 116:380 117:380 118:381 119:382 120:383 121:384 122:385 123:386 124:387 125:388 126:389 127:389 128:390 129:391 130:391 131:392 132:393 133:394 134:395 135:396 136:397 137:398 138:399 139:400 140:401 141:402 142:402 143:403 144:403 145:403 146:404 147:404 148:405 149:406 150:407 151:408 152:409 153:410 154:411 155:411 156:412 157:413 158:414 159:415 160:416 161:416 162:417 163:418 164:419 165:420 166:421 167:422 168:423 169:423 170:424 171:425 172:425 173:426 174:427 175:428 176:428 177:428 178:429 179:430 180:430 181:431 182:431 183:431 184:432 185:432 186:432 187:433 188:434 189:434 190:435 191:435 192:435 193:435 194:435 195:435 196:436 197:436 198:436 199:437 200:438 201:438 202:438 203:438 204:438 205:438 206:439 207:440 208:440 209:440 210:440 211:440 212:440 213:440 214:440 215:441 216:441 217:442 218:442 219:442 220:443 221:444 222:445 223:446 224:447 225:447 226:447 227:447 228:447 229:447 230:447 231:448 232:449 233:449 234:449 235:449 236:449 237:450 238:451 239:452 240:453 241:454 242:454 243:454 244:455 245:456 246:457 247:458 248:459 249:460 250:461 251:462 252:463 253:464 254:464 255:464 256:465 257:466 258:466 259:467 260:468 261:469 262:469 263:470 264:471 265:472 266:473 267:473 268:473 269:473 270:473 271:474 272:475 273:476 274:477 275:478 276:479 277:480 278:481 279:482 280:483 281:484 282:485 283:486 284:486 285:487 286:488 287:489 288:490 289:491 290:492 291:493 292:494 293:495 294:495 295:496 296:497 297:498 298:499 299:500 300:501 301:502 302:503 303:504 304:505 305:506 306:507 307:508 308:509 309:509 310:509 311:510 312:511 313:512 314:513 315:514 316:514 317:514 318:515 319:516 320:517 321:517 322:518 323:519 324:519 325:519 326:519 327:520 328:520 329:521 330:522 331:522 332:523 333:524 334:524 335:525 336:525 337:525 338:525 339:525 340:525 341:525 342:526 343:527 344:528 345:529 346:530 347:531 348:532 349:533 350:534 351:534 352:534 353:534 354:535 355:535 356:536 357:537 358:538 359:539 360:540 361:541 362:542 363:543 364:544 365:544 366:545 367:546 368:547 369:548 370:548 371:549 372:550 373:550 374:551 375:552 376:553 377:554 378:555 379:556 380:557 381:558 382:559\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.481121 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 102\n",
            "I0703 18:12:05.481912 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.482300 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.482652 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.487198 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000046\n",
            "I0703 18:12:05.487541 139789930788736 set_essential_params.py:432] unique_id: 1000000046\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.487696 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 4\n",
            "I0703 18:12:05.487802 139789930788736 set_essential_params.py:434] doc_span_index: 4\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser [SEP]\n",
            "I0703 18:12:05.488125 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:400 12:401 13:402 14:402 15:403 16:403 17:403 18:404 19:404 20:405 21:406 22:407 23:408 24:409 25:410 26:411 27:411 28:412 29:413 30:414 31:415 32:416 33:416 34:417 35:418 36:419 37:420 38:421 39:422 40:423 41:423 42:424 43:425 44:425 45:426 46:427 47:428 48:428 49:428 50:429 51:430 52:430 53:431 54:431 55:431 56:432 57:432 58:432 59:433 60:434 61:434 62:435 63:435 64:435 65:435 66:435 67:435 68:436 69:436 70:436 71:437 72:438 73:438 74:438 75:438 76:438 77:438 78:439 79:440 80:440 81:440 82:440 83:440 84:440 85:440 86:440 87:441 88:441 89:442 90:442 91:442 92:443 93:444 94:445 95:446 96:447 97:447 98:447 99:447 100:447 101:447 102:447 103:448 104:449 105:449 106:449 107:449 108:449 109:450 110:451 111:452 112:453 113:454 114:454 115:454 116:455 117:456 118:457 119:458 120:459 121:460 122:461 123:462 124:463 125:464 126:464 127:464 128:465 129:466 130:466 131:467 132:468 133:469 134:469 135:470 136:471 137:472 138:473 139:473 140:473 141:473 142:473 143:474 144:475 145:476 146:477 147:478 148:479 149:480 150:481 151:482 152:483 153:484 154:485 155:486 156:486 157:487 158:488 159:489 160:490 161:491 162:492 163:493 164:494 165:495 166:495 167:496 168:497 169:498 170:499 171:500 172:501 173:502 174:503 175:504 176:505 177:506 178:507 179:508 180:509 181:509 182:509 183:510 184:511 185:512 186:513 187:514 188:514 189:514 190:515 191:516 192:517 193:517 194:518 195:519 196:519 197:519 198:519 199:520 200:520 201:521 202:522 203:522 204:523 205:524 206:524 207:525 208:525 209:525 210:525 211:525 212:525 213:525 214:526 215:527 216:528 217:529 218:530 219:531 220:532 221:533 222:534 223:534 224:534 225:534 226:535 227:535 228:536 229:537 230:538 231:539 232:540 233:541 234:542 235:543 236:544 237:544 238:545 239:546 240:547 241:548 242:548 243:549 244:550 245:550 246:551 247:552 248:553 249:554 250:555 251:556 252:557 253:558 254:559 255:560 256:561 257:562 258:563 259:563 260:563 261:564 262:565 263:566 264:567 265:568 266:569 267:570 268:571 269:572 270:572 271:573 272:574 273:575 274:576 275:577 276:578 277:579 278:580 279:580 280:581 281:582 282:583 283:584 284:585 285:586 286:587 287:588 288:589 289:590 290:591 291:592 292:593 293:594 294:595 295:596 296:596 297:597 298:598 299:599 300:600 301:600 302:601 303:602 304:603 305:604 306:605 307:606 308:607 309:608 310:609 311:610 312:611 313:612 314:613 315:614 316:615 317:615 318:616 319:617 320:618 321:619 322:620 323:621 324:622 325:623 326:624 327:625 328:625 329:625 330:626 331:627 332:628 333:628 334:629 335:630 336:631 337:631 338:632 339:633 340:634 341:635 342:636 343:637 344:638 345:639 346:640 347:641 348:642 349:643 350:644 351:645 352:646 353:647 354:648 355:649 356:650 357:650 358:651 359:652 360:652 361:653 362:654 363:655 364:656 365:656 366:656 367:657 368:657 369:657 370:657 371:658 372:658 373:659 374:660 375:661 376:662 377:663 378:664 379:665 380:665 381:666 382:666\n",
            "I0703 18:12:05.488535 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:400 12:401 13:402 14:402 15:403 16:403 17:403 18:404 19:404 20:405 21:406 22:407 23:408 24:409 25:410 26:411 27:411 28:412 29:413 30:414 31:415 32:416 33:416 34:417 35:418 36:419 37:420 38:421 39:422 40:423 41:423 42:424 43:425 44:425 45:426 46:427 47:428 48:428 49:428 50:429 51:430 52:430 53:431 54:431 55:431 56:432 57:432 58:432 59:433 60:434 61:434 62:435 63:435 64:435 65:435 66:435 67:435 68:436 69:436 70:436 71:437 72:438 73:438 74:438 75:438 76:438 77:438 78:439 79:440 80:440 81:440 82:440 83:440 84:440 85:440 86:440 87:441 88:441 89:442 90:442 91:442 92:443 93:444 94:445 95:446 96:447 97:447 98:447 99:447 100:447 101:447 102:447 103:448 104:449 105:449 106:449 107:449 108:449 109:450 110:451 111:452 112:453 113:454 114:454 115:454 116:455 117:456 118:457 119:458 120:459 121:460 122:461 123:462 124:463 125:464 126:464 127:464 128:465 129:466 130:466 131:467 132:468 133:469 134:469 135:470 136:471 137:472 138:473 139:473 140:473 141:473 142:473 143:474 144:475 145:476 146:477 147:478 148:479 149:480 150:481 151:482 152:483 153:484 154:485 155:486 156:486 157:487 158:488 159:489 160:490 161:491 162:492 163:493 164:494 165:495 166:495 167:496 168:497 169:498 170:499 171:500 172:501 173:502 174:503 175:504 176:505 177:506 178:507 179:508 180:509 181:509 182:509 183:510 184:511 185:512 186:513 187:514 188:514 189:514 190:515 191:516 192:517 193:517 194:518 195:519 196:519 197:519 198:519 199:520 200:520 201:521 202:522 203:522 204:523 205:524 206:524 207:525 208:525 209:525 210:525 211:525 212:525 213:525 214:526 215:527 216:528 217:529 218:530 219:531 220:532 221:533 222:534 223:534 224:534 225:534 226:535 227:535 228:536 229:537 230:538 231:539 232:540 233:541 234:542 235:543 236:544 237:544 238:545 239:546 240:547 241:548 242:548 243:549 244:550 245:550 246:551 247:552 248:553 249:554 250:555 251:556 252:557 253:558 254:559 255:560 256:561 257:562 258:563 259:563 260:563 261:564 262:565 263:566 264:567 265:568 266:569 267:570 268:571 269:572 270:572 271:573 272:574 273:575 274:576 275:577 276:578 277:579 278:580 279:580 280:581 281:582 282:583 283:584 284:585 285:586 286:587 287:588 288:589 289:590 290:591 291:592 292:593 293:594 294:595 295:596 296:596 297:597 298:598 299:599 300:600 301:600 302:601 303:602 304:603 305:604 306:605 307:606 308:607 309:608 310:609 311:610 312:611 313:612 314:613 315:614 316:615 317:615 318:616 319:617 320:618 321:619 322:620 323:621 324:622 325:623 326:624 327:625 328:625 329:625 330:626 331:627 332:628 333:628 334:629 335:630 336:631 337:631 338:632 339:633 340:634 341:635 342:636 343:637 344:638 345:639 346:640 347:641 348:642 349:643 350:644 351:645 352:646 353:647 354:648 355:649 356:650 357:650 358:651 359:652 360:652 361:653 362:654 363:655 364:656 365:656 366:656 367:657 368:657 369:657 370:657 371:658 372:658 373:659 374:660 375:661 376:662 377:663 378:664 379:665 380:665 381:666 382:666\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.488896 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 102\n",
            "I0703 18:12:05.583296 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.584949 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.585160 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.588312 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000047\n",
            "I0703 18:12:05.589079 139789930788736 set_essential_params.py:432] unique_id: 1000000047\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.589427 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 5\n",
            "I0703 18:12:05.589887 139789930788736 set_essential_params.py:434] doc_span_index: 5\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & [SEP]\n",
            "I0703 18:12:05.590337 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:473 12:473 13:473 14:473 15:474 16:475 17:476 18:477 19:478 20:479 21:480 22:481 23:482 24:483 25:484 26:485 27:486 28:486 29:487 30:488 31:489 32:490 33:491 34:492 35:493 36:494 37:495 38:495 39:496 40:497 41:498 42:499 43:500 44:501 45:502 46:503 47:504 48:505 49:506 50:507 51:508 52:509 53:509 54:509 55:510 56:511 57:512 58:513 59:514 60:514 61:514 62:515 63:516 64:517 65:517 66:518 67:519 68:519 69:519 70:519 71:520 72:520 73:521 74:522 75:522 76:523 77:524 78:524 79:525 80:525 81:525 82:525 83:525 84:525 85:525 86:526 87:527 88:528 89:529 90:530 91:531 92:532 93:533 94:534 95:534 96:534 97:534 98:535 99:535 100:536 101:537 102:538 103:539 104:540 105:541 106:542 107:543 108:544 109:544 110:545 111:546 112:547 113:548 114:548 115:549 116:550 117:550 118:551 119:552 120:553 121:554 122:555 123:556 124:557 125:558 126:559 127:560 128:561 129:562 130:563 131:563 132:563 133:564 134:565 135:566 136:567 137:568 138:569 139:570 140:571 141:572 142:572 143:573 144:574 145:575 146:576 147:577 148:578 149:579 150:580 151:580 152:581 153:582 154:583 155:584 156:585 157:586 158:587 159:588 160:589 161:590 162:591 163:592 164:593 165:594 166:595 167:596 168:596 169:597 170:598 171:599 172:600 173:600 174:601 175:602 176:603 177:604 178:605 179:606 180:607 181:608 182:609 183:610 184:611 185:612 186:613 187:614 188:615 189:615 190:616 191:617 192:618 193:619 194:620 195:621 196:622 197:623 198:624 199:625 200:625 201:625 202:626 203:627 204:628 205:628 206:629 207:630 208:631 209:631 210:632 211:633 212:634 213:635 214:636 215:637 216:638 217:639 218:640 219:641 220:642 221:643 222:644 223:645 224:646 225:647 226:648 227:649 228:650 229:650 230:651 231:652 232:652 233:653 234:654 235:655 236:656 237:656 238:656 239:657 240:657 241:657 242:657 243:658 244:658 245:659 246:660 247:661 248:662 249:663 250:664 251:665 252:665 253:666 254:666 255:666 256:667 257:667 258:667 259:668 260:668 261:668 262:669 263:670 264:671 265:672 266:673 267:674 268:675 269:676 270:677 271:678 272:679 273:680 274:681 275:682 276:683 277:684 278:685 279:685 280:686 281:687 282:688 283:689 284:689 285:690 286:691 287:692 288:693 289:694 290:695 291:696 292:697 293:698 294:699 295:700 296:701 297:701 298:702 299:703 300:704 301:705 302:706 303:707 304:707 305:708 306:709 307:709 308:709 309:709 310:710 311:711 312:712 313:713 314:713 315:714 316:714 317:715 318:716 319:717 320:718 321:719 322:720 323:721 324:722 325:723 326:724 327:724 328:725 329:725 330:726 331:727 332:728 333:729 334:730 335:730 336:731 337:732 338:733 339:734 340:735 341:735 342:736 343:737 344:737 345:737 346:738 347:738 348:739 349:740 350:741 351:741 352:742 353:743 354:744 355:745 356:746 357:747 358:748 359:748 360:749 361:749 362:749 363:750 364:751 365:752 366:753 367:753 368:754 369:755 370:755 371:756 372:757 373:757 374:758 375:759 376:759 377:759 378:760 379:761 380:761 381:762 382:763\n",
            "I0703 18:12:05.590768 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:473 12:473 13:473 14:473 15:474 16:475 17:476 18:477 19:478 20:479 21:480 22:481 23:482 24:483 25:484 26:485 27:486 28:486 29:487 30:488 31:489 32:490 33:491 34:492 35:493 36:494 37:495 38:495 39:496 40:497 41:498 42:499 43:500 44:501 45:502 46:503 47:504 48:505 49:506 50:507 51:508 52:509 53:509 54:509 55:510 56:511 57:512 58:513 59:514 60:514 61:514 62:515 63:516 64:517 65:517 66:518 67:519 68:519 69:519 70:519 71:520 72:520 73:521 74:522 75:522 76:523 77:524 78:524 79:525 80:525 81:525 82:525 83:525 84:525 85:525 86:526 87:527 88:528 89:529 90:530 91:531 92:532 93:533 94:534 95:534 96:534 97:534 98:535 99:535 100:536 101:537 102:538 103:539 104:540 105:541 106:542 107:543 108:544 109:544 110:545 111:546 112:547 113:548 114:548 115:549 116:550 117:550 118:551 119:552 120:553 121:554 122:555 123:556 124:557 125:558 126:559 127:560 128:561 129:562 130:563 131:563 132:563 133:564 134:565 135:566 136:567 137:568 138:569 139:570 140:571 141:572 142:572 143:573 144:574 145:575 146:576 147:577 148:578 149:579 150:580 151:580 152:581 153:582 154:583 155:584 156:585 157:586 158:587 159:588 160:589 161:590 162:591 163:592 164:593 165:594 166:595 167:596 168:596 169:597 170:598 171:599 172:600 173:600 174:601 175:602 176:603 177:604 178:605 179:606 180:607 181:608 182:609 183:610 184:611 185:612 186:613 187:614 188:615 189:615 190:616 191:617 192:618 193:619 194:620 195:621 196:622 197:623 198:624 199:625 200:625 201:625 202:626 203:627 204:628 205:628 206:629 207:630 208:631 209:631 210:632 211:633 212:634 213:635 214:636 215:637 216:638 217:639 218:640 219:641 220:642 221:643 222:644 223:645 224:646 225:647 226:648 227:649 228:650 229:650 230:651 231:652 232:652 233:653 234:654 235:655 236:656 237:656 238:656 239:657 240:657 241:657 242:657 243:658 244:658 245:659 246:660 247:661 248:662 249:663 250:664 251:665 252:665 253:666 254:666 255:666 256:667 257:667 258:667 259:668 260:668 261:668 262:669 263:670 264:671 265:672 266:673 267:674 268:675 269:676 270:677 271:678 272:679 273:680 274:681 275:682 276:683 277:684 278:685 279:685 280:686 281:687 282:688 283:689 284:689 285:690 286:691 287:692 288:693 289:694 290:695 291:696 292:697 293:698 294:699 295:700 296:701 297:701 298:702 299:703 300:704 301:705 302:706 303:707 304:707 305:708 306:709 307:709 308:709 309:709 310:710 311:711 312:712 313:713 314:713 315:714 316:714 317:715 318:716 319:717 320:718 321:719 322:720 323:721 324:722 325:723 326:724 327:724 328:725 329:725 330:726 331:727 332:728 333:729 334:730 335:730 336:731 337:732 338:733 339:734 340:735 341:735 342:736 343:737 344:737 345:737 346:738 347:738 348:739 349:740 350:741 351:741 352:742 353:743 354:744 355:745 356:746 357:747 358:748 359:748 360:749 361:749 362:749 363:750 364:751 365:752 366:753 367:753 368:754 369:755 370:755 371:756 372:757 373:757 374:758 375:759 376:759 377:759 378:760 379:761 380:761 381:762 382:763\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.591038 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 102\n",
            "I0703 18:12:05.691088 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.691554 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.691843 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.695907 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000048\n",
            "I0703 18:12:05.696089 139789930788736 set_essential_params.py:432] unique_id: 1000000048\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.696157 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 6\n",
            "I0703 18:12:05.696213 139789930788736 set_essential_params.py:434] doc_span_index: 6\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and [SEP]\n",
            "I0703 18:12:05.696376 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:570 12:571 13:572 14:572 15:573 16:574 17:575 18:576 19:577 20:578 21:579 22:580 23:580 24:581 25:582 26:583 27:584 28:585 29:586 30:587 31:588 32:589 33:590 34:591 35:592 36:593 37:594 38:595 39:596 40:596 41:597 42:598 43:599 44:600 45:600 46:601 47:602 48:603 49:604 50:605 51:606 52:607 53:608 54:609 55:610 56:611 57:612 58:613 59:614 60:615 61:615 62:616 63:617 64:618 65:619 66:620 67:621 68:622 69:623 70:624 71:625 72:625 73:625 74:626 75:627 76:628 77:628 78:629 79:630 80:631 81:631 82:632 83:633 84:634 85:635 86:636 87:637 88:638 89:639 90:640 91:641 92:642 93:643 94:644 95:645 96:646 97:647 98:648 99:649 100:650 101:650 102:651 103:652 104:652 105:653 106:654 107:655 108:656 109:656 110:656 111:657 112:657 113:657 114:657 115:658 116:658 117:659 118:660 119:661 120:662 121:663 122:664 123:665 124:665 125:666 126:666 127:666 128:667 129:667 130:667 131:668 132:668 133:668 134:669 135:670 136:671 137:672 138:673 139:674 140:675 141:676 142:677 143:678 144:679 145:680 146:681 147:682 148:683 149:684 150:685 151:685 152:686 153:687 154:688 155:689 156:689 157:690 158:691 159:692 160:693 161:694 162:695 163:696 164:697 165:698 166:699 167:700 168:701 169:701 170:702 171:703 172:704 173:705 174:706 175:707 176:707 177:708 178:709 179:709 180:709 181:709 182:710 183:711 184:712 185:713 186:713 187:714 188:714 189:715 190:716 191:717 192:718 193:719 194:720 195:721 196:722 197:723 198:724 199:724 200:725 201:725 202:726 203:727 204:728 205:729 206:730 207:730 208:731 209:732 210:733 211:734 212:735 213:735 214:736 215:737 216:737 217:737 218:738 219:738 220:739 221:740 222:741 223:741 224:742 225:743 226:744 227:745 228:746 229:747 230:748 231:748 232:749 233:749 234:749 235:750 236:751 237:752 238:753 239:753 240:754 241:755 242:755 243:756 244:757 245:757 246:758 247:759 248:759 249:759 250:760 251:761 252:761 253:762 254:763 255:764 256:764 257:765 258:765 259:765 260:765 261:765 262:766 263:767 264:768 265:768 266:768 267:769 268:769 269:769 270:769 271:769 272:769 273:769 274:769 275:770 276:770 277:770 278:770 279:771 280:772 281:773 282:773 283:774 284:775 285:775 286:775 287:775 288:775 289:775 290:775 291:776 292:776 293:776 294:776 295:777 296:778 297:779 298:779 299:780 300:781 301:782 302:783 303:784 304:784 305:785 306:786 307:786 308:787 309:788 310:789 311:789 312:790 313:791 314:792 315:792 316:793 317:794 318:794 319:795 320:796 321:797 322:798 323:798 324:799 325:800 326:801 327:802 328:803 329:804 330:805 331:806 332:807 333:808 334:809 335:810 336:811 337:812 338:812 339:813 340:814 341:814 342:815 343:816 344:816 345:816 346:817 347:818 348:819 349:820 350:821 351:822 352:823 353:824 354:824 355:825 356:826 357:826 358:827 359:828 360:829 361:829 362:830 363:831 364:832 365:833 366:834 367:835 368:836 369:837 370:837 371:837 372:837 373:838 374:838 375:838 376:838 377:838 378:839 379:840 380:841 381:841 382:842\n",
            "I0703 18:12:05.696605 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:570 12:571 13:572 14:572 15:573 16:574 17:575 18:576 19:577 20:578 21:579 22:580 23:580 24:581 25:582 26:583 27:584 28:585 29:586 30:587 31:588 32:589 33:590 34:591 35:592 36:593 37:594 38:595 39:596 40:596 41:597 42:598 43:599 44:600 45:600 46:601 47:602 48:603 49:604 50:605 51:606 52:607 53:608 54:609 55:610 56:611 57:612 58:613 59:614 60:615 61:615 62:616 63:617 64:618 65:619 66:620 67:621 68:622 69:623 70:624 71:625 72:625 73:625 74:626 75:627 76:628 77:628 78:629 79:630 80:631 81:631 82:632 83:633 84:634 85:635 86:636 87:637 88:638 89:639 90:640 91:641 92:642 93:643 94:644 95:645 96:646 97:647 98:648 99:649 100:650 101:650 102:651 103:652 104:652 105:653 106:654 107:655 108:656 109:656 110:656 111:657 112:657 113:657 114:657 115:658 116:658 117:659 118:660 119:661 120:662 121:663 122:664 123:665 124:665 125:666 126:666 127:666 128:667 129:667 130:667 131:668 132:668 133:668 134:669 135:670 136:671 137:672 138:673 139:674 140:675 141:676 142:677 143:678 144:679 145:680 146:681 147:682 148:683 149:684 150:685 151:685 152:686 153:687 154:688 155:689 156:689 157:690 158:691 159:692 160:693 161:694 162:695 163:696 164:697 165:698 166:699 167:700 168:701 169:701 170:702 171:703 172:704 173:705 174:706 175:707 176:707 177:708 178:709 179:709 180:709 181:709 182:710 183:711 184:712 185:713 186:713 187:714 188:714 189:715 190:716 191:717 192:718 193:719 194:720 195:721 196:722 197:723 198:724 199:724 200:725 201:725 202:726 203:727 204:728 205:729 206:730 207:730 208:731 209:732 210:733 211:734 212:735 213:735 214:736 215:737 216:737 217:737 218:738 219:738 220:739 221:740 222:741 223:741 224:742 225:743 226:744 227:745 228:746 229:747 230:748 231:748 232:749 233:749 234:749 235:750 236:751 237:752 238:753 239:753 240:754 241:755 242:755 243:756 244:757 245:757 246:758 247:759 248:759 249:759 250:760 251:761 252:761 253:762 254:763 255:764 256:764 257:765 258:765 259:765 260:765 261:765 262:766 263:767 264:768 265:768 266:768 267:769 268:769 269:769 270:769 271:769 272:769 273:769 274:769 275:770 276:770 277:770 278:770 279:771 280:772 281:773 282:773 283:774 284:775 285:775 286:775 287:775 288:775 289:775 290:775 291:776 292:776 293:776 294:776 295:777 296:778 297:779 298:779 299:780 300:781 301:782 302:783 303:784 304:784 305:785 306:786 307:786 308:787 309:788 310:789 311:789 312:790 313:791 314:792 315:792 316:793 317:794 318:794 319:795 320:796 321:797 322:798 323:798 324:799 325:800 326:801 327:802 328:803 329:804 330:805 331:806 332:807 333:808 334:809 335:810 336:811 337:812 338:812 339:813 340:814 341:814 342:815 343:816 344:816 345:816 346:817 347:818 348:819 349:820 350:821 351:822 352:823 353:824 354:824 355:825 356:826 357:826 358:827 359:828 360:829 361:829 362:830 363:831 364:832 365:833 366:834 367:835 368:836 369:837 370:837 371:837 372:837 373:838 374:838 375:838 376:838 377:838 378:839 379:840 380:841 381:841 382:842\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.696839 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 102\n",
            "I0703 18:12:05.793132 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.794588 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.794950 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.801631 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000049\n",
            "I0703 18:12:05.803549 139789930788736 set_essential_params.py:432] unique_id: 1000000049\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.803672 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 7\n",
            "I0703 18:12:05.803754 139789930788736 set_essential_params.py:434] doc_span_index: 7\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 [SEP]\n",
            "I0703 18:12:05.804013 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:674 12:675 13:676 14:677 15:678 16:679 17:680 18:681 19:682 20:683 21:684 22:685 23:685 24:686 25:687 26:688 27:689 28:689 29:690 30:691 31:692 32:693 33:694 34:695 35:696 36:697 37:698 38:699 39:700 40:701 41:701 42:702 43:703 44:704 45:705 46:706 47:707 48:707 49:708 50:709 51:709 52:709 53:709 54:710 55:711 56:712 57:713 58:713 59:714 60:714 61:715 62:716 63:717 64:718 65:719 66:720 67:721 68:722 69:723 70:724 71:724 72:725 73:725 74:726 75:727 76:728 77:729 78:730 79:730 80:731 81:732 82:733 83:734 84:735 85:735 86:736 87:737 88:737 89:737 90:738 91:738 92:739 93:740 94:741 95:741 96:742 97:743 98:744 99:745 100:746 101:747 102:748 103:748 104:749 105:749 106:749 107:750 108:751 109:752 110:753 111:753 112:754 113:755 114:755 115:756 116:757 117:757 118:758 119:759 120:759 121:759 122:760 123:761 124:761 125:762 126:763 127:764 128:764 129:765 130:765 131:765 132:765 133:765 134:766 135:767 136:768 137:768 138:768 139:769 140:769 141:769 142:769 143:769 144:769 145:769 146:769 147:770 148:770 149:770 150:770 151:771 152:772 153:773 154:773 155:774 156:775 157:775 158:775 159:775 160:775 161:775 162:775 163:776 164:776 165:776 166:776 167:777 168:778 169:779 170:779 171:780 172:781 173:782 174:783 175:784 176:784 177:785 178:786 179:786 180:787 181:788 182:789 183:789 184:790 185:791 186:792 187:792 188:793 189:794 190:794 191:795 192:796 193:797 194:798 195:798 196:799 197:800 198:801 199:802 200:803 201:804 202:805 203:806 204:807 205:808 206:809 207:810 208:811 209:812 210:812 211:813 212:814 213:814 214:815 215:816 216:816 217:816 218:817 219:818 220:819 221:820 222:821 223:822 224:823 225:824 226:824 227:825 228:826 229:826 230:827 231:828 232:829 233:829 234:830 235:831 236:832 237:833 238:834 239:835 240:836 241:837 242:837 243:837 244:837 245:838 246:838 247:838 248:838 249:838 250:839 251:840 252:841 253:841 254:842 255:843 256:844 257:845 258:846 259:847 260:847 261:847 262:847 263:848 264:849 265:850 266:851 267:852 268:852 269:852 270:853 271:854 272:854 273:854 274:854 275:855 276:856 277:856 278:857 279:858 280:859 281:860 282:860 283:860 284:860 285:861 286:862 287:863 288:864 289:865 290:866 291:867 292:867 293:868 294:869 295:870 296:871 297:872 298:873 299:874 300:875 301:876 302:877 303:878 304:879 305:879 306:880 307:881 308:882 309:882 310:883 311:884 312:884 313:884 314:884 315:885 316:885 317:886 318:887 319:888 320:889 321:890 322:890 323:891 324:892 325:893 326:894 327:895 328:896 329:897 330:897 331:898 332:899 333:900 334:901 335:902 336:903 337:904 338:905 339:906 340:907 341:907 342:907 343:907 344:908 345:909 346:910 347:911 348:912 349:913 350:914 351:914 352:915 353:916 354:916 355:917 356:918 357:919 358:920 359:920 360:920 361:920 362:921 363:922 364:923 365:924 366:924 367:925 368:926 369:927 370:928 371:929 372:929 373:929 374:929 375:930 376:930 377:930 378:931 379:931 380:931 381:932 382:932\n",
            "I0703 18:12:05.804359 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:674 12:675 13:676 14:677 15:678 16:679 17:680 18:681 19:682 20:683 21:684 22:685 23:685 24:686 25:687 26:688 27:689 28:689 29:690 30:691 31:692 32:693 33:694 34:695 35:696 36:697 37:698 38:699 39:700 40:701 41:701 42:702 43:703 44:704 45:705 46:706 47:707 48:707 49:708 50:709 51:709 52:709 53:709 54:710 55:711 56:712 57:713 58:713 59:714 60:714 61:715 62:716 63:717 64:718 65:719 66:720 67:721 68:722 69:723 70:724 71:724 72:725 73:725 74:726 75:727 76:728 77:729 78:730 79:730 80:731 81:732 82:733 83:734 84:735 85:735 86:736 87:737 88:737 89:737 90:738 91:738 92:739 93:740 94:741 95:741 96:742 97:743 98:744 99:745 100:746 101:747 102:748 103:748 104:749 105:749 106:749 107:750 108:751 109:752 110:753 111:753 112:754 113:755 114:755 115:756 116:757 117:757 118:758 119:759 120:759 121:759 122:760 123:761 124:761 125:762 126:763 127:764 128:764 129:765 130:765 131:765 132:765 133:765 134:766 135:767 136:768 137:768 138:768 139:769 140:769 141:769 142:769 143:769 144:769 145:769 146:769 147:770 148:770 149:770 150:770 151:771 152:772 153:773 154:773 155:774 156:775 157:775 158:775 159:775 160:775 161:775 162:775 163:776 164:776 165:776 166:776 167:777 168:778 169:779 170:779 171:780 172:781 173:782 174:783 175:784 176:784 177:785 178:786 179:786 180:787 181:788 182:789 183:789 184:790 185:791 186:792 187:792 188:793 189:794 190:794 191:795 192:796 193:797 194:798 195:798 196:799 197:800 198:801 199:802 200:803 201:804 202:805 203:806 204:807 205:808 206:809 207:810 208:811 209:812 210:812 211:813 212:814 213:814 214:815 215:816 216:816 217:816 218:817 219:818 220:819 221:820 222:821 223:822 224:823 225:824 226:824 227:825 228:826 229:826 230:827 231:828 232:829 233:829 234:830 235:831 236:832 237:833 238:834 239:835 240:836 241:837 242:837 243:837 244:837 245:838 246:838 247:838 248:838 249:838 250:839 251:840 252:841 253:841 254:842 255:843 256:844 257:845 258:846 259:847 260:847 261:847 262:847 263:848 264:849 265:850 266:851 267:852 268:852 269:852 270:853 271:854 272:854 273:854 274:854 275:855 276:856 277:856 278:857 279:858 280:859 281:860 282:860 283:860 284:860 285:861 286:862 287:863 288:864 289:865 290:866 291:867 292:867 293:868 294:869 295:870 296:871 297:872 298:873 299:874 300:875 301:876 302:877 303:878 304:879 305:879 306:880 307:881 308:882 309:882 310:883 311:884 312:884 313:884 314:884 315:885 316:885 317:886 318:887 319:888 320:889 321:890 322:890 323:891 324:892 325:893 326:894 327:895 328:896 329:897 330:897 331:898 332:899 333:900 334:901 335:902 336:903 337:904 338:905 339:906 340:907 341:907 342:907 343:907 344:908 345:909 346:910 347:911 348:912 349:913 350:914 351:914 352:915 353:916 354:916 355:917 356:918 357:919 358:920 359:920 360:920 361:920 362:921 363:922 364:923 365:924 366:924 367:925 368:926 369:927 370:928 371:929 372:929 373:929 374:929 375:930 376:930 377:930 378:931 379:931 380:931 381:932 382:932\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.804637 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 102\n",
            "I0703 18:12:05.900653 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.901817 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:05.903124 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:05.906286 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000050\n",
            "I0703 18:12:05.906485 139789930788736 set_essential_params.py:432] unique_id: 1000000050\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:05.906586 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 8\n",
            "I0703 18:12:05.906673 139789930788736 set_essential_params.py:434] doc_span_index: 8\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo [SEP]\n",
            "I0703 18:12:05.906890 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:769 12:769 13:769 14:769 15:769 16:769 17:769 18:769 19:770 20:770 21:770 22:770 23:771 24:772 25:773 26:773 27:774 28:775 29:775 30:775 31:775 32:775 33:775 34:775 35:776 36:776 37:776 38:776 39:777 40:778 41:779 42:779 43:780 44:781 45:782 46:783 47:784 48:784 49:785 50:786 51:786 52:787 53:788 54:789 55:789 56:790 57:791 58:792 59:792 60:793 61:794 62:794 63:795 64:796 65:797 66:798 67:798 68:799 69:800 70:801 71:802 72:803 73:804 74:805 75:806 76:807 77:808 78:809 79:810 80:811 81:812 82:812 83:813 84:814 85:814 86:815 87:816 88:816 89:816 90:817 91:818 92:819 93:820 94:821 95:822 96:823 97:824 98:824 99:825 100:826 101:826 102:827 103:828 104:829 105:829 106:830 107:831 108:832 109:833 110:834 111:835 112:836 113:837 114:837 115:837 116:837 117:838 118:838 119:838 120:838 121:838 122:839 123:840 124:841 125:841 126:842 127:843 128:844 129:845 130:846 131:847 132:847 133:847 134:847 135:848 136:849 137:850 138:851 139:852 140:852 141:852 142:853 143:854 144:854 145:854 146:854 147:855 148:856 149:856 150:857 151:858 152:859 153:860 154:860 155:860 156:860 157:861 158:862 159:863 160:864 161:865 162:866 163:867 164:867 165:868 166:869 167:870 168:871 169:872 170:873 171:874 172:875 173:876 174:877 175:878 176:879 177:879 178:880 179:881 180:882 181:882 182:883 183:884 184:884 185:884 186:884 187:885 188:885 189:886 190:887 191:888 192:889 193:890 194:890 195:891 196:892 197:893 198:894 199:895 200:896 201:897 202:897 203:898 204:899 205:900 206:901 207:902 208:903 209:904 210:905 211:906 212:907 213:907 214:907 215:907 216:908 217:909 218:910 219:911 220:912 221:913 222:914 223:914 224:915 225:916 226:916 227:917 228:918 229:919 230:920 231:920 232:920 233:920 234:921 235:922 236:923 237:924 238:924 239:925 240:926 241:927 242:928 243:929 244:929 245:929 246:929 247:930 248:930 249:930 250:931 251:931 252:931 253:932 254:932 255:932 256:933 257:933 258:933 259:933 260:933 261:933 262:934 263:935 264:936 265:937 266:937 267:938 268:939 269:940 270:941 271:942 272:943 273:943 274:943 275:944 276:944 277:945 278:946 279:947 280:947 281:948 282:949 283:950 284:951 285:952 286:953 287:954 288:954 289:955 290:955 291:956 292:957 293:958 294:959 295:960 296:961 297:962 298:963 299:964 300:965 301:966 302:967 303:968 304:968 305:968 306:969 307:970 308:970 309:971 310:971 311:971 312:971 313:971 314:971 315:972 316:973 317:973 318:974 319:975 320:976 321:976 322:976 323:976 324:976 325:977 326:978 327:979 328:980 329:981 330:982 331:982 332:982 333:982 334:983 335:983 336:984 337:984 338:985 339:986 340:987 341:988 342:989 343:989 344:990 345:991 346:992 347:993 348:994 349:994 350:995 351:996 352:997 353:998 354:998 355:999 356:1000 357:1000 358:1001 359:1002 360:1002 361:1002 362:1002 363:1003 364:1003 365:1004 366:1004 367:1005 368:1006 369:1007 370:1008 371:1009 372:1010 373:1010 374:1011 375:1012 376:1012 377:1013 378:1014 379:1015 380:1016 381:1017 382:1017\n",
            "I0703 18:12:05.907164 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:769 12:769 13:769 14:769 15:769 16:769 17:769 18:769 19:770 20:770 21:770 22:770 23:771 24:772 25:773 26:773 27:774 28:775 29:775 30:775 31:775 32:775 33:775 34:775 35:776 36:776 37:776 38:776 39:777 40:778 41:779 42:779 43:780 44:781 45:782 46:783 47:784 48:784 49:785 50:786 51:786 52:787 53:788 54:789 55:789 56:790 57:791 58:792 59:792 60:793 61:794 62:794 63:795 64:796 65:797 66:798 67:798 68:799 69:800 70:801 71:802 72:803 73:804 74:805 75:806 76:807 77:808 78:809 79:810 80:811 81:812 82:812 83:813 84:814 85:814 86:815 87:816 88:816 89:816 90:817 91:818 92:819 93:820 94:821 95:822 96:823 97:824 98:824 99:825 100:826 101:826 102:827 103:828 104:829 105:829 106:830 107:831 108:832 109:833 110:834 111:835 112:836 113:837 114:837 115:837 116:837 117:838 118:838 119:838 120:838 121:838 122:839 123:840 124:841 125:841 126:842 127:843 128:844 129:845 130:846 131:847 132:847 133:847 134:847 135:848 136:849 137:850 138:851 139:852 140:852 141:852 142:853 143:854 144:854 145:854 146:854 147:855 148:856 149:856 150:857 151:858 152:859 153:860 154:860 155:860 156:860 157:861 158:862 159:863 160:864 161:865 162:866 163:867 164:867 165:868 166:869 167:870 168:871 169:872 170:873 171:874 172:875 173:876 174:877 175:878 176:879 177:879 178:880 179:881 180:882 181:882 182:883 183:884 184:884 185:884 186:884 187:885 188:885 189:886 190:887 191:888 192:889 193:890 194:890 195:891 196:892 197:893 198:894 199:895 200:896 201:897 202:897 203:898 204:899 205:900 206:901 207:902 208:903 209:904 210:905 211:906 212:907 213:907 214:907 215:907 216:908 217:909 218:910 219:911 220:912 221:913 222:914 223:914 224:915 225:916 226:916 227:917 228:918 229:919 230:920 231:920 232:920 233:920 234:921 235:922 236:923 237:924 238:924 239:925 240:926 241:927 242:928 243:929 244:929 245:929 246:929 247:930 248:930 249:930 250:931 251:931 252:931 253:932 254:932 255:932 256:933 257:933 258:933 259:933 260:933 261:933 262:934 263:935 264:936 265:937 266:937 267:938 268:939 269:940 270:941 271:942 272:943 273:943 274:943 275:944 276:944 277:945 278:946 279:947 280:947 281:948 282:949 283:950 284:951 285:952 286:953 287:954 288:954 289:955 290:955 291:956 292:957 293:958 294:959 295:960 296:961 297:962 298:963 299:964 300:965 301:966 302:967 303:968 304:968 305:968 306:969 307:970 308:970 309:971 310:971 311:971 312:971 313:971 314:971 315:972 316:973 317:973 318:974 319:975 320:976 321:976 322:976 323:976 324:976 325:977 326:978 327:979 328:980 329:981 330:982 331:982 332:982 333:982 334:983 335:983 336:984 337:984 338:985 339:986 340:987 341:988 342:989 343:989 344:990 345:991 346:992 347:993 348:994 349:994 350:995 351:996 352:997 353:998 354:998 355:999 356:1000 357:1000 358:1001 359:1002 360:1002 361:1002 362:1002 363:1003 364:1003 365:1004 366:1004 367:1005 368:1006 369:1007 370:1008 371:1009 372:1010 373:1010 374:1011 375:1012 376:1012 377:1013 378:1014 379:1015 380:1016 381:1017 382:1017\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:05.907428 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 102\n",
            "I0703 18:12:06.006369 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.007164 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.007452 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.012612 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000051\n",
            "I0703 18:12:06.012867 139789930788736 set_essential_params.py:432] unique_id: 1000000051\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:06.013039 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 9\n",
            "I0703 18:12:06.013141 139789930788736 set_essential_params.py:434] doc_span_index: 9\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens [SEP]\n",
            "I0703 18:12:06.013460 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:852 12:852 13:852 14:853 15:854 16:854 17:854 18:854 19:855 20:856 21:856 22:857 23:858 24:859 25:860 26:860 27:860 28:860 29:861 30:862 31:863 32:864 33:865 34:866 35:867 36:867 37:868 38:869 39:870 40:871 41:872 42:873 43:874 44:875 45:876 46:877 47:878 48:879 49:879 50:880 51:881 52:882 53:882 54:883 55:884 56:884 57:884 58:884 59:885 60:885 61:886 62:887 63:888 64:889 65:890 66:890 67:891 68:892 69:893 70:894 71:895 72:896 73:897 74:897 75:898 76:899 77:900 78:901 79:902 80:903 81:904 82:905 83:906 84:907 85:907 86:907 87:907 88:908 89:909 90:910 91:911 92:912 93:913 94:914 95:914 96:915 97:916 98:916 99:917 100:918 101:919 102:920 103:920 104:920 105:920 106:921 107:922 108:923 109:924 110:924 111:925 112:926 113:927 114:928 115:929 116:929 117:929 118:929 119:930 120:930 121:930 122:931 123:931 124:931 125:932 126:932 127:932 128:933 129:933 130:933 131:933 132:933 133:933 134:934 135:935 136:936 137:937 138:937 139:938 140:939 141:940 142:941 143:942 144:943 145:943 146:943 147:944 148:944 149:945 150:946 151:947 152:947 153:948 154:949 155:950 156:951 157:952 158:953 159:954 160:954 161:955 162:955 163:956 164:957 165:958 166:959 167:960 168:961 169:962 170:963 171:964 172:965 173:966 174:967 175:968 176:968 177:968 178:969 179:970 180:970 181:971 182:971 183:971 184:971 185:971 186:971 187:972 188:973 189:973 190:974 191:975 192:976 193:976 194:976 195:976 196:976 197:977 198:978 199:979 200:980 201:981 202:982 203:982 204:982 205:982 206:983 207:983 208:984 209:984 210:985 211:986 212:987 213:988 214:989 215:989 216:990 217:991 218:992 219:993 220:994 221:994 222:995 223:996 224:997 225:998 226:998 227:999 228:1000 229:1000 230:1001 231:1002 232:1002 233:1002 234:1002 235:1003 236:1003 237:1004 238:1004 239:1005 240:1006 241:1007 242:1008 243:1009 244:1010 245:1010 246:1011 247:1012 248:1012 249:1013 250:1014 251:1015 252:1016 253:1017 254:1017 255:1017 256:1017 257:1018 258:1018 259:1019 260:1020 261:1021 262:1022 263:1023 264:1024 265:1024 266:1025 267:1026 268:1027 269:1028 270:1028 271:1029 272:1029 273:1030 274:1031 275:1032 276:1033 277:1034 278:1034 279:1034 280:1035 281:1036 282:1036 283:1037 284:1038 285:1039 286:1039 287:1040 288:1041 289:1042 290:1043 291:1044 292:1045 293:1046 294:1046 295:1047 296:1047 297:1047 298:1047 299:1048 300:1048 301:1049 302:1050 303:1051 304:1052 305:1053 306:1054 307:1054 308:1055 309:1056 310:1057 311:1057 312:1058 313:1059 314:1060 315:1061 316:1062 317:1063 318:1064 319:1065 320:1066 321:1066 322:1067 323:1067 324:1068 325:1069 326:1070 327:1071 328:1071 329:1072 330:1072 331:1073 332:1074 333:1075 334:1076 335:1077 336:1078 337:1079 338:1080 339:1080 340:1081 341:1081 342:1081 343:1082 344:1083 345:1084 346:1085 347:1086 348:1087 349:1088 350:1089 351:1090 352:1090 353:1091 354:1091 355:1092 356:1093 357:1093 358:1094 359:1095 360:1096 361:1097 362:1097 363:1097 364:1098 365:1099 366:1100 367:1100 368:1101 369:1101 370:1102 371:1103 372:1104 373:1105 374:1105 375:1106 376:1107 377:1108 378:1108 379:1108 380:1109 381:1110 382:1111\n",
            "I0703 18:12:06.013824 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:852 12:852 13:852 14:853 15:854 16:854 17:854 18:854 19:855 20:856 21:856 22:857 23:858 24:859 25:860 26:860 27:860 28:860 29:861 30:862 31:863 32:864 33:865 34:866 35:867 36:867 37:868 38:869 39:870 40:871 41:872 42:873 43:874 44:875 45:876 46:877 47:878 48:879 49:879 50:880 51:881 52:882 53:882 54:883 55:884 56:884 57:884 58:884 59:885 60:885 61:886 62:887 63:888 64:889 65:890 66:890 67:891 68:892 69:893 70:894 71:895 72:896 73:897 74:897 75:898 76:899 77:900 78:901 79:902 80:903 81:904 82:905 83:906 84:907 85:907 86:907 87:907 88:908 89:909 90:910 91:911 92:912 93:913 94:914 95:914 96:915 97:916 98:916 99:917 100:918 101:919 102:920 103:920 104:920 105:920 106:921 107:922 108:923 109:924 110:924 111:925 112:926 113:927 114:928 115:929 116:929 117:929 118:929 119:930 120:930 121:930 122:931 123:931 124:931 125:932 126:932 127:932 128:933 129:933 130:933 131:933 132:933 133:933 134:934 135:935 136:936 137:937 138:937 139:938 140:939 141:940 142:941 143:942 144:943 145:943 146:943 147:944 148:944 149:945 150:946 151:947 152:947 153:948 154:949 155:950 156:951 157:952 158:953 159:954 160:954 161:955 162:955 163:956 164:957 165:958 166:959 167:960 168:961 169:962 170:963 171:964 172:965 173:966 174:967 175:968 176:968 177:968 178:969 179:970 180:970 181:971 182:971 183:971 184:971 185:971 186:971 187:972 188:973 189:973 190:974 191:975 192:976 193:976 194:976 195:976 196:976 197:977 198:978 199:979 200:980 201:981 202:982 203:982 204:982 205:982 206:983 207:983 208:984 209:984 210:985 211:986 212:987 213:988 214:989 215:989 216:990 217:991 218:992 219:993 220:994 221:994 222:995 223:996 224:997 225:998 226:998 227:999 228:1000 229:1000 230:1001 231:1002 232:1002 233:1002 234:1002 235:1003 236:1003 237:1004 238:1004 239:1005 240:1006 241:1007 242:1008 243:1009 244:1010 245:1010 246:1011 247:1012 248:1012 249:1013 250:1014 251:1015 252:1016 253:1017 254:1017 255:1017 256:1017 257:1018 258:1018 259:1019 260:1020 261:1021 262:1022 263:1023 264:1024 265:1024 266:1025 267:1026 268:1027 269:1028 270:1028 271:1029 272:1029 273:1030 274:1031 275:1032 276:1033 277:1034 278:1034 279:1034 280:1035 281:1036 282:1036 283:1037 284:1038 285:1039 286:1039 287:1040 288:1041 289:1042 290:1043 291:1044 292:1045 293:1046 294:1046 295:1047 296:1047 297:1047 298:1047 299:1048 300:1048 301:1049 302:1050 303:1051 304:1052 305:1053 306:1054 307:1054 308:1055 309:1056 310:1057 311:1057 312:1058 313:1059 314:1060 315:1061 316:1062 317:1063 318:1064 319:1065 320:1066 321:1066 322:1067 323:1067 324:1068 325:1069 326:1070 327:1071 328:1071 329:1072 330:1072 331:1073 332:1074 333:1075 334:1076 335:1077 336:1078 337:1079 338:1080 339:1080 340:1081 341:1081 342:1081 343:1082 344:1083 345:1084 346:1085 347:1086 348:1087 349:1088 350:1089 351:1090 352:1090 353:1091 354:1091 355:1092 356:1093 357:1093 358:1094 359:1095 360:1096 361:1097 362:1097 363:1097 364:1098 365:1099 366:1100 367:1100 368:1101 369:1101 370:1102 371:1103 372:1104 373:1105 374:1105 375:1106 376:1107 377:1108 378:1108 379:1108 380:1109 381:1110 382:1111\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.108853 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 102\n",
            "I0703 18:12:06.110859 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.113788 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.114091 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.119155 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000052\n",
            "I0703 18:12:06.119340 139789930788736 set_essential_params.py:432] unique_id: 1000000052\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:06.119436 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 10\n",
            "I0703 18:12:06.119512 139789930788736 set_essential_params.py:434] doc_span_index: 10\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , [SEP]\n",
            "I0703 18:12:06.119780 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:938 12:939 13:940 14:941 15:942 16:943 17:943 18:943 19:944 20:944 21:945 22:946 23:947 24:947 25:948 26:949 27:950 28:951 29:952 30:953 31:954 32:954 33:955 34:955 35:956 36:957 37:958 38:959 39:960 40:961 41:962 42:963 43:964 44:965 45:966 46:967 47:968 48:968 49:968 50:969 51:970 52:970 53:971 54:971 55:971 56:971 57:971 58:971 59:972 60:973 61:973 62:974 63:975 64:976 65:976 66:976 67:976 68:976 69:977 70:978 71:979 72:980 73:981 74:982 75:982 76:982 77:982 78:983 79:983 80:984 81:984 82:985 83:986 84:987 85:988 86:989 87:989 88:990 89:991 90:992 91:993 92:994 93:994 94:995 95:996 96:997 97:998 98:998 99:999 100:1000 101:1000 102:1001 103:1002 104:1002 105:1002 106:1002 107:1003 108:1003 109:1004 110:1004 111:1005 112:1006 113:1007 114:1008 115:1009 116:1010 117:1010 118:1011 119:1012 120:1012 121:1013 122:1014 123:1015 124:1016 125:1017 126:1017 127:1017 128:1017 129:1018 130:1018 131:1019 132:1020 133:1021 134:1022 135:1023 136:1024 137:1024 138:1025 139:1026 140:1027 141:1028 142:1028 143:1029 144:1029 145:1030 146:1031 147:1032 148:1033 149:1034 150:1034 151:1034 152:1035 153:1036 154:1036 155:1037 156:1038 157:1039 158:1039 159:1040 160:1041 161:1042 162:1043 163:1044 164:1045 165:1046 166:1046 167:1047 168:1047 169:1047 170:1047 171:1048 172:1048 173:1049 174:1050 175:1051 176:1052 177:1053 178:1054 179:1054 180:1055 181:1056 182:1057 183:1057 184:1058 185:1059 186:1060 187:1061 188:1062 189:1063 190:1064 191:1065 192:1066 193:1066 194:1067 195:1067 196:1068 197:1069 198:1070 199:1071 200:1071 201:1072 202:1072 203:1073 204:1074 205:1075 206:1076 207:1077 208:1078 209:1079 210:1080 211:1080 212:1081 213:1081 214:1081 215:1082 216:1083 217:1084 218:1085 219:1086 220:1087 221:1088 222:1089 223:1090 224:1090 225:1091 226:1091 227:1092 228:1093 229:1093 230:1094 231:1095 232:1096 233:1097 234:1097 235:1097 236:1098 237:1099 238:1100 239:1100 240:1101 241:1101 242:1102 243:1103 244:1104 245:1105 246:1105 247:1106 248:1107 249:1108 250:1108 251:1108 252:1109 253:1110 254:1111 255:1111 256:1111 257:1112 258:1112 259:1113 260:1114 261:1115 262:1115 263:1116 264:1117 265:1118 266:1119 267:1120 268:1121 269:1122 270:1122 271:1123 272:1124 273:1124 274:1124 275:1124 276:1125 277:1126 278:1126 279:1126 280:1127 281:1128 282:1129 283:1130 284:1130 285:1130 286:1131 287:1132 288:1133 289:1134 290:1134 291:1134 292:1134 293:1135 294:1136 295:1137 296:1138 297:1139 298:1139 299:1140 300:1141 301:1141 302:1142 303:1143 304:1144 305:1145 306:1146 307:1147 308:1148 309:1149 310:1150 311:1151 312:1151 313:1151 314:1152 315:1153 316:1154 317:1155 318:1155 319:1155 320:1156 321:1157 322:1158 323:1159 324:1160 325:1160 326:1161 327:1161 328:1161 329:1161 330:1161 331:1162 332:1162 333:1163 334:1164 335:1165 336:1165 337:1166 338:1167 339:1168 340:1169 341:1170 342:1171 343:1172 344:1173 345:1174 346:1175 347:1175 348:1176 349:1177 350:1178 351:1178 352:1179 353:1180 354:1181 355:1182 356:1182 357:1182 358:1182 359:1183 360:1184 361:1185 362:1186 363:1187 364:1188 365:1189 366:1190 367:1191 368:1192 369:1193 370:1194 371:1195 372:1196 373:1197 374:1198 375:1199 376:1200 377:1201 378:1202 379:1202 380:1203 381:1204 382:1204\n",
            "I0703 18:12:06.120136 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:938 12:939 13:940 14:941 15:942 16:943 17:943 18:943 19:944 20:944 21:945 22:946 23:947 24:947 25:948 26:949 27:950 28:951 29:952 30:953 31:954 32:954 33:955 34:955 35:956 36:957 37:958 38:959 39:960 40:961 41:962 42:963 43:964 44:965 45:966 46:967 47:968 48:968 49:968 50:969 51:970 52:970 53:971 54:971 55:971 56:971 57:971 58:971 59:972 60:973 61:973 62:974 63:975 64:976 65:976 66:976 67:976 68:976 69:977 70:978 71:979 72:980 73:981 74:982 75:982 76:982 77:982 78:983 79:983 80:984 81:984 82:985 83:986 84:987 85:988 86:989 87:989 88:990 89:991 90:992 91:993 92:994 93:994 94:995 95:996 96:997 97:998 98:998 99:999 100:1000 101:1000 102:1001 103:1002 104:1002 105:1002 106:1002 107:1003 108:1003 109:1004 110:1004 111:1005 112:1006 113:1007 114:1008 115:1009 116:1010 117:1010 118:1011 119:1012 120:1012 121:1013 122:1014 123:1015 124:1016 125:1017 126:1017 127:1017 128:1017 129:1018 130:1018 131:1019 132:1020 133:1021 134:1022 135:1023 136:1024 137:1024 138:1025 139:1026 140:1027 141:1028 142:1028 143:1029 144:1029 145:1030 146:1031 147:1032 148:1033 149:1034 150:1034 151:1034 152:1035 153:1036 154:1036 155:1037 156:1038 157:1039 158:1039 159:1040 160:1041 161:1042 162:1043 163:1044 164:1045 165:1046 166:1046 167:1047 168:1047 169:1047 170:1047 171:1048 172:1048 173:1049 174:1050 175:1051 176:1052 177:1053 178:1054 179:1054 180:1055 181:1056 182:1057 183:1057 184:1058 185:1059 186:1060 187:1061 188:1062 189:1063 190:1064 191:1065 192:1066 193:1066 194:1067 195:1067 196:1068 197:1069 198:1070 199:1071 200:1071 201:1072 202:1072 203:1073 204:1074 205:1075 206:1076 207:1077 208:1078 209:1079 210:1080 211:1080 212:1081 213:1081 214:1081 215:1082 216:1083 217:1084 218:1085 219:1086 220:1087 221:1088 222:1089 223:1090 224:1090 225:1091 226:1091 227:1092 228:1093 229:1093 230:1094 231:1095 232:1096 233:1097 234:1097 235:1097 236:1098 237:1099 238:1100 239:1100 240:1101 241:1101 242:1102 243:1103 244:1104 245:1105 246:1105 247:1106 248:1107 249:1108 250:1108 251:1108 252:1109 253:1110 254:1111 255:1111 256:1111 257:1112 258:1112 259:1113 260:1114 261:1115 262:1115 263:1116 264:1117 265:1118 266:1119 267:1120 268:1121 269:1122 270:1122 271:1123 272:1124 273:1124 274:1124 275:1124 276:1125 277:1126 278:1126 279:1126 280:1127 281:1128 282:1129 283:1130 284:1130 285:1130 286:1131 287:1132 288:1133 289:1134 290:1134 291:1134 292:1134 293:1135 294:1136 295:1137 296:1138 297:1139 298:1139 299:1140 300:1141 301:1141 302:1142 303:1143 304:1144 305:1145 306:1146 307:1147 308:1148 309:1149 310:1150 311:1151 312:1151 313:1151 314:1152 315:1153 316:1154 317:1155 318:1155 319:1155 320:1156 321:1157 322:1158 323:1159 324:1160 325:1160 326:1161 327:1161 328:1161 329:1161 330:1161 331:1162 332:1162 333:1163 334:1164 335:1165 336:1165 337:1166 338:1167 339:1168 340:1169 341:1170 342:1171 343:1172 344:1173 345:1174 346:1175 347:1175 348:1176 349:1177 350:1178 351:1178 352:1179 353:1180 354:1181 355:1182 356:1182 357:1182 358:1182 359:1183 360:1184 361:1185 362:1186 363:1187 364:1188 365:1189 366:1190 367:1191 368:1192 369:1193 370:1194 371:1195 372:1196 373:1197 374:1198 375:1199 376:1200 377:1201 378:1202 379:1202 380:1203 381:1204 382:1204\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.217611 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 102\n",
            "I0703 18:12:06.219235 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.219633 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.220393 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.225251 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000053\n",
            "I0703 18:12:06.225420 139789930788736 set_essential_params.py:432] unique_id: 1000000053\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:06.225529 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 11\n",
            "I0703 18:12:06.225616 139789930788736 set_essential_params.py:434] doc_span_index: 11\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking [SEP]\n",
            "I0703 18:12:06.225834 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:1026 12:1027 13:1028 14:1028 15:1029 16:1029 17:1030 18:1031 19:1032 20:1033 21:1034 22:1034 23:1034 24:1035 25:1036 26:1036 27:1037 28:1038 29:1039 30:1039 31:1040 32:1041 33:1042 34:1043 35:1044 36:1045 37:1046 38:1046 39:1047 40:1047 41:1047 42:1047 43:1048 44:1048 45:1049 46:1050 47:1051 48:1052 49:1053 50:1054 51:1054 52:1055 53:1056 54:1057 55:1057 56:1058 57:1059 58:1060 59:1061 60:1062 61:1063 62:1064 63:1065 64:1066 65:1066 66:1067 67:1067 68:1068 69:1069 70:1070 71:1071 72:1071 73:1072 74:1072 75:1073 76:1074 77:1075 78:1076 79:1077 80:1078 81:1079 82:1080 83:1080 84:1081 85:1081 86:1081 87:1082 88:1083 89:1084 90:1085 91:1086 92:1087 93:1088 94:1089 95:1090 96:1090 97:1091 98:1091 99:1092 100:1093 101:1093 102:1094 103:1095 104:1096 105:1097 106:1097 107:1097 108:1098 109:1099 110:1100 111:1100 112:1101 113:1101 114:1102 115:1103 116:1104 117:1105 118:1105 119:1106 120:1107 121:1108 122:1108 123:1108 124:1109 125:1110 126:1111 127:1111 128:1111 129:1112 130:1112 131:1113 132:1114 133:1115 134:1115 135:1116 136:1117 137:1118 138:1119 139:1120 140:1121 141:1122 142:1122 143:1123 144:1124 145:1124 146:1124 147:1124 148:1125 149:1126 150:1126 151:1126 152:1127 153:1128 154:1129 155:1130 156:1130 157:1130 158:1131 159:1132 160:1133 161:1134 162:1134 163:1134 164:1134 165:1135 166:1136 167:1137 168:1138 169:1139 170:1139 171:1140 172:1141 173:1141 174:1142 175:1143 176:1144 177:1145 178:1146 179:1147 180:1148 181:1149 182:1150 183:1151 184:1151 185:1151 186:1152 187:1153 188:1154 189:1155 190:1155 191:1155 192:1156 193:1157 194:1158 195:1159 196:1160 197:1160 198:1161 199:1161 200:1161 201:1161 202:1161 203:1162 204:1162 205:1163 206:1164 207:1165 208:1165 209:1166 210:1167 211:1168 212:1169 213:1170 214:1171 215:1172 216:1173 217:1174 218:1175 219:1175 220:1176 221:1177 222:1178 223:1178 224:1179 225:1180 226:1181 227:1182 228:1182 229:1182 230:1182 231:1183 232:1184 233:1185 234:1186 235:1187 236:1188 237:1189 238:1190 239:1191 240:1192 241:1193 242:1194 243:1195 244:1196 245:1197 246:1198 247:1199 248:1200 249:1201 250:1202 251:1202 252:1203 253:1204 254:1204 255:1205 256:1206 257:1207 258:1207 259:1207 260:1208 261:1209 262:1210 263:1211 264:1212 265:1213 266:1213 267:1213 268:1213 269:1214 270:1215 271:1216 272:1217 273:1218 274:1219 275:1220 276:1221 277:1222 278:1223 279:1224 280:1225 281:1226 282:1227 283:1228 284:1229 285:1230 286:1231 287:1231 288:1232 289:1233 290:1233 291:1234 292:1234 293:1235 294:1236 295:1237 296:1238 297:1239 298:1240 299:1241 300:1242 301:1243 302:1244 303:1245 304:1245 305:1245 306:1246 307:1246 308:1247 309:1248 310:1248 311:1248 312:1248 313:1249 314:1250 315:1251 316:1252 317:1253 318:1254 319:1255 320:1256 321:1257 322:1257 323:1258 324:1259 325:1259 326:1259 327:1259 328:1260 329:1261 330:1262 331:1263 332:1263 333:1264 334:1264 335:1265 336:1265 337:1265 338:1266 339:1267 340:1268 341:1268 342:1269 343:1270 344:1271 345:1272 346:1272 347:1273 348:1274 349:1275 350:1276 351:1277 352:1277 353:1277 354:1277 355:1278 356:1278 357:1279 358:1280 359:1281 360:1282 361:1282 362:1283 363:1284 364:1284 365:1285 366:1285 367:1285 368:1285 369:1286 370:1287 371:1288 372:1289 373:1290 374:1290 375:1291 376:1292 377:1293 378:1293 379:1294 380:1295 381:1296 382:1297\n",
            "I0703 18:12:06.226134 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:1026 12:1027 13:1028 14:1028 15:1029 16:1029 17:1030 18:1031 19:1032 20:1033 21:1034 22:1034 23:1034 24:1035 25:1036 26:1036 27:1037 28:1038 29:1039 30:1039 31:1040 32:1041 33:1042 34:1043 35:1044 36:1045 37:1046 38:1046 39:1047 40:1047 41:1047 42:1047 43:1048 44:1048 45:1049 46:1050 47:1051 48:1052 49:1053 50:1054 51:1054 52:1055 53:1056 54:1057 55:1057 56:1058 57:1059 58:1060 59:1061 60:1062 61:1063 62:1064 63:1065 64:1066 65:1066 66:1067 67:1067 68:1068 69:1069 70:1070 71:1071 72:1071 73:1072 74:1072 75:1073 76:1074 77:1075 78:1076 79:1077 80:1078 81:1079 82:1080 83:1080 84:1081 85:1081 86:1081 87:1082 88:1083 89:1084 90:1085 91:1086 92:1087 93:1088 94:1089 95:1090 96:1090 97:1091 98:1091 99:1092 100:1093 101:1093 102:1094 103:1095 104:1096 105:1097 106:1097 107:1097 108:1098 109:1099 110:1100 111:1100 112:1101 113:1101 114:1102 115:1103 116:1104 117:1105 118:1105 119:1106 120:1107 121:1108 122:1108 123:1108 124:1109 125:1110 126:1111 127:1111 128:1111 129:1112 130:1112 131:1113 132:1114 133:1115 134:1115 135:1116 136:1117 137:1118 138:1119 139:1120 140:1121 141:1122 142:1122 143:1123 144:1124 145:1124 146:1124 147:1124 148:1125 149:1126 150:1126 151:1126 152:1127 153:1128 154:1129 155:1130 156:1130 157:1130 158:1131 159:1132 160:1133 161:1134 162:1134 163:1134 164:1134 165:1135 166:1136 167:1137 168:1138 169:1139 170:1139 171:1140 172:1141 173:1141 174:1142 175:1143 176:1144 177:1145 178:1146 179:1147 180:1148 181:1149 182:1150 183:1151 184:1151 185:1151 186:1152 187:1153 188:1154 189:1155 190:1155 191:1155 192:1156 193:1157 194:1158 195:1159 196:1160 197:1160 198:1161 199:1161 200:1161 201:1161 202:1161 203:1162 204:1162 205:1163 206:1164 207:1165 208:1165 209:1166 210:1167 211:1168 212:1169 213:1170 214:1171 215:1172 216:1173 217:1174 218:1175 219:1175 220:1176 221:1177 222:1178 223:1178 224:1179 225:1180 226:1181 227:1182 228:1182 229:1182 230:1182 231:1183 232:1184 233:1185 234:1186 235:1187 236:1188 237:1189 238:1190 239:1191 240:1192 241:1193 242:1194 243:1195 244:1196 245:1197 246:1198 247:1199 248:1200 249:1201 250:1202 251:1202 252:1203 253:1204 254:1204 255:1205 256:1206 257:1207 258:1207 259:1207 260:1208 261:1209 262:1210 263:1211 264:1212 265:1213 266:1213 267:1213 268:1213 269:1214 270:1215 271:1216 272:1217 273:1218 274:1219 275:1220 276:1221 277:1222 278:1223 279:1224 280:1225 281:1226 282:1227 283:1228 284:1229 285:1230 286:1231 287:1231 288:1232 289:1233 290:1233 291:1234 292:1234 293:1235 294:1236 295:1237 296:1238 297:1239 298:1240 299:1241 300:1242 301:1243 302:1244 303:1245 304:1245 305:1245 306:1246 307:1246 308:1247 309:1248 310:1248 311:1248 312:1248 313:1249 314:1250 315:1251 316:1252 317:1253 318:1254 319:1255 320:1256 321:1257 322:1257 323:1258 324:1259 325:1259 326:1259 327:1259 328:1260 329:1261 330:1262 331:1263 332:1263 333:1264 334:1264 335:1265 336:1265 337:1265 338:1266 339:1267 340:1268 341:1268 342:1269 343:1270 344:1271 345:1272 346:1272 347:1273 348:1274 349:1275 350:1276 351:1277 352:1277 353:1277 354:1277 355:1278 356:1278 357:1279 358:1280 359:1281 360:1282 361:1282 362:1283 363:1284 364:1284 365:1285 366:1285 367:1285 368:1285 369:1286 370:1287 371:1288 372:1289 373:1290 374:1290 375:1291 376:1292 377:1293 378:1293 379:1294 380:1295 381:1296 382:1297\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.226437 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 102\n",
            "I0703 18:12:06.325882 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.326684 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.327000 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.330900 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000054\n",
            "I0703 18:12:06.331090 139789930788736 set_essential_params.py:432] unique_id: 1000000054\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:06.331192 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 12\n",
            "I0703 18:12:06.331280 139789930788736 set_essential_params.py:434] doc_span_index: 12\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired [SEP]\n",
            "I0703 18:12:06.331508 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:1120 12:1121 13:1122 14:1122 15:1123 16:1124 17:1124 18:1124 19:1124 20:1125 21:1126 22:1126 23:1126 24:1127 25:1128 26:1129 27:1130 28:1130 29:1130 30:1131 31:1132 32:1133 33:1134 34:1134 35:1134 36:1134 37:1135 38:1136 39:1137 40:1138 41:1139 42:1139 43:1140 44:1141 45:1141 46:1142 47:1143 48:1144 49:1145 50:1146 51:1147 52:1148 53:1149 54:1150 55:1151 56:1151 57:1151 58:1152 59:1153 60:1154 61:1155 62:1155 63:1155 64:1156 65:1157 66:1158 67:1159 68:1160 69:1160 70:1161 71:1161 72:1161 73:1161 74:1161 75:1162 76:1162 77:1163 78:1164 79:1165 80:1165 81:1166 82:1167 83:1168 84:1169 85:1170 86:1171 87:1172 88:1173 89:1174 90:1175 91:1175 92:1176 93:1177 94:1178 95:1178 96:1179 97:1180 98:1181 99:1182 100:1182 101:1182 102:1182 103:1183 104:1184 105:1185 106:1186 107:1187 108:1188 109:1189 110:1190 111:1191 112:1192 113:1193 114:1194 115:1195 116:1196 117:1197 118:1198 119:1199 120:1200 121:1201 122:1202 123:1202 124:1203 125:1204 126:1204 127:1205 128:1206 129:1207 130:1207 131:1207 132:1208 133:1209 134:1210 135:1211 136:1212 137:1213 138:1213 139:1213 140:1213 141:1214 142:1215 143:1216 144:1217 145:1218 146:1219 147:1220 148:1221 149:1222 150:1223 151:1224 152:1225 153:1226 154:1227 155:1228 156:1229 157:1230 158:1231 159:1231 160:1232 161:1233 162:1233 163:1234 164:1234 165:1235 166:1236 167:1237 168:1238 169:1239 170:1240 171:1241 172:1242 173:1243 174:1244 175:1245 176:1245 177:1245 178:1246 179:1246 180:1247 181:1248 182:1248 183:1248 184:1248 185:1249 186:1250 187:1251 188:1252 189:1253 190:1254 191:1255 192:1256 193:1257 194:1257 195:1258 196:1259 197:1259 198:1259 199:1259 200:1260 201:1261 202:1262 203:1263 204:1263 205:1264 206:1264 207:1265 208:1265 209:1265 210:1266 211:1267 212:1268 213:1268 214:1269 215:1270 216:1271 217:1272 218:1272 219:1273 220:1274 221:1275 222:1276 223:1277 224:1277 225:1277 226:1277 227:1278 228:1278 229:1279 230:1280 231:1281 232:1282 233:1282 234:1283 235:1284 236:1284 237:1285 238:1285 239:1285 240:1285 241:1286 242:1287 243:1288 244:1289 245:1290 246:1290 247:1291 248:1292 249:1293 250:1293 251:1294 252:1295 253:1296 254:1297 255:1298 256:1299 257:1300 258:1301 259:1301 260:1302 261:1302 262:1302 263:1303 264:1304 265:1304 266:1305 267:1306 268:1307 269:1308 270:1309 271:1310 272:1311 273:1312 274:1313 275:1313 276:1314 277:1315 278:1316 279:1316 280:1317 281:1318 282:1319 283:1320 284:1321 285:1322 286:1323 287:1323 288:1324 289:1325 290:1326 291:1326 292:1327 293:1327 294:1327 295:1327 296:1327 297:1327 298:1328 299:1329 300:1330 301:1331 302:1331 303:1332 304:1333 305:1334 306:1335 307:1335 308:1336 309:1337 310:1338 311:1339 312:1340 313:1340 314:1341 315:1342 316:1343 317:1344 318:1344 319:1345 320:1345 321:1346 322:1346 323:1346 324:1347 325:1347 326:1348 327:1349 328:1350 329:1351 330:1352 331:1353 332:1354 333:1355 334:1355 335:1356 336:1357 337:1357 338:1358 339:1358 340:1359 341:1359 342:1359 343:1360 344:1360 345:1361 346:1362 347:1363 348:1364 349:1365 350:1366 351:1367 352:1368 353:1369 354:1370 355:1370 356:1371 357:1371 358:1372 359:1372 360:1372 361:1373 362:1373 363:1374 364:1374 365:1374 366:1375 367:1376 368:1377 369:1378 370:1379 371:1380 372:1381 373:1382 374:1383 375:1383 376:1384 377:1385 378:1386 379:1387 380:1388 381:1389 382:1390\n",
            "I0703 18:12:06.331750 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:1120 12:1121 13:1122 14:1122 15:1123 16:1124 17:1124 18:1124 19:1124 20:1125 21:1126 22:1126 23:1126 24:1127 25:1128 26:1129 27:1130 28:1130 29:1130 30:1131 31:1132 32:1133 33:1134 34:1134 35:1134 36:1134 37:1135 38:1136 39:1137 40:1138 41:1139 42:1139 43:1140 44:1141 45:1141 46:1142 47:1143 48:1144 49:1145 50:1146 51:1147 52:1148 53:1149 54:1150 55:1151 56:1151 57:1151 58:1152 59:1153 60:1154 61:1155 62:1155 63:1155 64:1156 65:1157 66:1158 67:1159 68:1160 69:1160 70:1161 71:1161 72:1161 73:1161 74:1161 75:1162 76:1162 77:1163 78:1164 79:1165 80:1165 81:1166 82:1167 83:1168 84:1169 85:1170 86:1171 87:1172 88:1173 89:1174 90:1175 91:1175 92:1176 93:1177 94:1178 95:1178 96:1179 97:1180 98:1181 99:1182 100:1182 101:1182 102:1182 103:1183 104:1184 105:1185 106:1186 107:1187 108:1188 109:1189 110:1190 111:1191 112:1192 113:1193 114:1194 115:1195 116:1196 117:1197 118:1198 119:1199 120:1200 121:1201 122:1202 123:1202 124:1203 125:1204 126:1204 127:1205 128:1206 129:1207 130:1207 131:1207 132:1208 133:1209 134:1210 135:1211 136:1212 137:1213 138:1213 139:1213 140:1213 141:1214 142:1215 143:1216 144:1217 145:1218 146:1219 147:1220 148:1221 149:1222 150:1223 151:1224 152:1225 153:1226 154:1227 155:1228 156:1229 157:1230 158:1231 159:1231 160:1232 161:1233 162:1233 163:1234 164:1234 165:1235 166:1236 167:1237 168:1238 169:1239 170:1240 171:1241 172:1242 173:1243 174:1244 175:1245 176:1245 177:1245 178:1246 179:1246 180:1247 181:1248 182:1248 183:1248 184:1248 185:1249 186:1250 187:1251 188:1252 189:1253 190:1254 191:1255 192:1256 193:1257 194:1257 195:1258 196:1259 197:1259 198:1259 199:1259 200:1260 201:1261 202:1262 203:1263 204:1263 205:1264 206:1264 207:1265 208:1265 209:1265 210:1266 211:1267 212:1268 213:1268 214:1269 215:1270 216:1271 217:1272 218:1272 219:1273 220:1274 221:1275 222:1276 223:1277 224:1277 225:1277 226:1277 227:1278 228:1278 229:1279 230:1280 231:1281 232:1282 233:1282 234:1283 235:1284 236:1284 237:1285 238:1285 239:1285 240:1285 241:1286 242:1287 243:1288 244:1289 245:1290 246:1290 247:1291 248:1292 249:1293 250:1293 251:1294 252:1295 253:1296 254:1297 255:1298 256:1299 257:1300 258:1301 259:1301 260:1302 261:1302 262:1302 263:1303 264:1304 265:1304 266:1305 267:1306 268:1307 269:1308 270:1309 271:1310 272:1311 273:1312 274:1313 275:1313 276:1314 277:1315 278:1316 279:1316 280:1317 281:1318 282:1319 283:1320 284:1321 285:1322 286:1323 287:1323 288:1324 289:1325 290:1326 291:1326 292:1327 293:1327 294:1327 295:1327 296:1327 297:1327 298:1328 299:1329 300:1330 301:1331 302:1331 303:1332 304:1333 305:1334 306:1335 307:1335 308:1336 309:1337 310:1338 311:1339 312:1340 313:1340 314:1341 315:1342 316:1343 317:1344 318:1344 319:1345 320:1345 321:1346 322:1346 323:1346 324:1347 325:1347 326:1348 327:1349 328:1350 329:1351 330:1352 331:1353 332:1354 333:1355 334:1355 335:1356 336:1357 337:1357 338:1358 339:1358 340:1359 341:1359 342:1359 343:1360 344:1360 345:1361 346:1362 347:1363 348:1364 349:1365 350:1366 351:1367 352:1368 353:1369 354:1370 355:1370 356:1371 357:1371 358:1372 359:1372 360:1372 361:1373 362:1373 363:1374 364:1374 365:1374 366:1375 367:1376 368:1377 369:1378 370:1379 371:1380 372:1381 373:1382 374:1383 375:1383 376:1384 377:1385 378:1386 379:1387 380:1388 381:1389 382:1390\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.331985 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 102\n",
            "I0703 18:12:06.430149 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.430622 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.430916 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.434792 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000055\n",
            "I0703 18:12:06.435003 139789930788736 set_essential_params.py:432] unique_id: 1000000055\n",
            "INFO:tensorflow:example_index: 3\n",
            "I0703 18:12:06.435142 139789930788736 set_essential_params.py:433] example_index: 3\n",
            "INFO:tensorflow:doc_span_index: 13\n",
            "I0703 18:12:06.437580 139789930788736 set_essential_params.py:434] doc_span_index: 13\n",
            "INFO:tensorflow:tokens: [CLS] when did siemens opened up its first workshop ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "I0703 18:12:06.437852 139789930788736 set_essential_params.py:436] tokens: [CLS] when did siemens opened up its first workshop ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:1213 12:1213 13:1214 14:1215 15:1216 16:1217 17:1218 18:1219 19:1220 20:1221 21:1222 22:1223 23:1224 24:1225 25:1226 26:1227 27:1228 28:1229 29:1230 30:1231 31:1231 32:1232 33:1233 34:1233 35:1234 36:1234 37:1235 38:1236 39:1237 40:1238 41:1239 42:1240 43:1241 44:1242 45:1243 46:1244 47:1245 48:1245 49:1245 50:1246 51:1246 52:1247 53:1248 54:1248 55:1248 56:1248 57:1249 58:1250 59:1251 60:1252 61:1253 62:1254 63:1255 64:1256 65:1257 66:1257 67:1258 68:1259 69:1259 70:1259 71:1259 72:1260 73:1261 74:1262 75:1263 76:1263 77:1264 78:1264 79:1265 80:1265 81:1265 82:1266 83:1267 84:1268 85:1268 86:1269 87:1270 88:1271 89:1272 90:1272 91:1273 92:1274 93:1275 94:1276 95:1277 96:1277 97:1277 98:1277 99:1278 100:1278 101:1279 102:1280 103:1281 104:1282 105:1282 106:1283 107:1284 108:1284 109:1285 110:1285 111:1285 112:1285 113:1286 114:1287 115:1288 116:1289 117:1290 118:1290 119:1291 120:1292 121:1293 122:1293 123:1294 124:1295 125:1296 126:1297 127:1298 128:1299 129:1300 130:1301 131:1301 132:1302 133:1302 134:1302 135:1303 136:1304 137:1304 138:1305 139:1306 140:1307 141:1308 142:1309 143:1310 144:1311 145:1312 146:1313 147:1313 148:1314 149:1315 150:1316 151:1316 152:1317 153:1318 154:1319 155:1320 156:1321 157:1322 158:1323 159:1323 160:1324 161:1325 162:1326 163:1326 164:1327 165:1327 166:1327 167:1327 168:1327 169:1327 170:1328 171:1329 172:1330 173:1331 174:1331 175:1332 176:1333 177:1334 178:1335 179:1335 180:1336 181:1337 182:1338 183:1339 184:1340 185:1340 186:1341 187:1342 188:1343 189:1344 190:1344 191:1345 192:1345 193:1346 194:1346 195:1346 196:1347 197:1347 198:1348 199:1349 200:1350 201:1351 202:1352 203:1353 204:1354 205:1355 206:1355 207:1356 208:1357 209:1357 210:1358 211:1358 212:1359 213:1359 214:1359 215:1360 216:1360 217:1361 218:1362 219:1363 220:1364 221:1365 222:1366 223:1367 224:1368 225:1369 226:1370 227:1370 228:1371 229:1371 230:1372 231:1372 232:1372 233:1373 234:1373 235:1374 236:1374 237:1374 238:1375 239:1376 240:1377 241:1378 242:1379 243:1380 244:1381 245:1382 246:1383 247:1383 248:1384 249:1385 250:1386 251:1387 252:1388 253:1389 254:1390 255:1391 256:1392 257:1393 258:1394 259:1395 260:1396 261:1397 262:1398 263:1398 264:1399 265:1399 266:1400 267:1401 268:1402 269:1402 270:1403 271:1404 272:1405 273:1405 274:1406 275:1407 276:1408 277:1409 278:1410 279:1411 280:1412 281:1413 282:1414 283:1414 284:1415 285:1415\n",
            "I0703 18:12:06.438129 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:1213 12:1213 13:1214 14:1215 15:1216 16:1217 17:1218 18:1219 19:1220 20:1221 21:1222 22:1223 23:1224 24:1225 25:1226 26:1227 27:1228 28:1229 29:1230 30:1231 31:1231 32:1232 33:1233 34:1233 35:1234 36:1234 37:1235 38:1236 39:1237 40:1238 41:1239 42:1240 43:1241 44:1242 45:1243 46:1244 47:1245 48:1245 49:1245 50:1246 51:1246 52:1247 53:1248 54:1248 55:1248 56:1248 57:1249 58:1250 59:1251 60:1252 61:1253 62:1254 63:1255 64:1256 65:1257 66:1257 67:1258 68:1259 69:1259 70:1259 71:1259 72:1260 73:1261 74:1262 75:1263 76:1263 77:1264 78:1264 79:1265 80:1265 81:1265 82:1266 83:1267 84:1268 85:1268 86:1269 87:1270 88:1271 89:1272 90:1272 91:1273 92:1274 93:1275 94:1276 95:1277 96:1277 97:1277 98:1277 99:1278 100:1278 101:1279 102:1280 103:1281 104:1282 105:1282 106:1283 107:1284 108:1284 109:1285 110:1285 111:1285 112:1285 113:1286 114:1287 115:1288 116:1289 117:1290 118:1290 119:1291 120:1292 121:1293 122:1293 123:1294 124:1295 125:1296 126:1297 127:1298 128:1299 129:1300 130:1301 131:1301 132:1302 133:1302 134:1302 135:1303 136:1304 137:1304 138:1305 139:1306 140:1307 141:1308 142:1309 143:1310 144:1311 145:1312 146:1313 147:1313 148:1314 149:1315 150:1316 151:1316 152:1317 153:1318 154:1319 155:1320 156:1321 157:1322 158:1323 159:1323 160:1324 161:1325 162:1326 163:1326 164:1327 165:1327 166:1327 167:1327 168:1327 169:1327 170:1328 171:1329 172:1330 173:1331 174:1331 175:1332 176:1333 177:1334 178:1335 179:1335 180:1336 181:1337 182:1338 183:1339 184:1340 185:1340 186:1341 187:1342 188:1343 189:1344 190:1344 191:1345 192:1345 193:1346 194:1346 195:1346 196:1347 197:1347 198:1348 199:1349 200:1350 201:1351 202:1352 203:1353 204:1354 205:1355 206:1355 207:1356 208:1357 209:1357 210:1358 211:1358 212:1359 213:1359 214:1359 215:1360 216:1360 217:1361 218:1362 219:1363 220:1364 221:1365 222:1366 223:1367 224:1368 225:1369 226:1370 227:1370 228:1371 229:1371 230:1372 231:1372 232:1372 233:1373 234:1373 235:1374 236:1374 237:1374 238:1375 239:1376 240:1377 241:1378 242:1379 243:1380 244:1381 245:1382 246:1383 247:1383 248:1384 249:1385 250:1386 251:1387 252:1388 253:1389 254:1390 255:1391 256:1392 257:1393 258:1394 259:1395 260:1396 261:1397 262:1398 263:1398 264:1399 265:1399 266:1400 267:1401 268:1402 269:1402 270:1403 271:1404 272:1405 273:1405 274:1406 275:1407 276:1408 277:1409 278:1410 279:1411 280:1412 281:1413 282:1414 283:1414 284:1415 285:1415\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True\n",
            "I0703 18:12:06.438380 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:06.438689 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2106 22108 2441 2039 2049 2034 8395 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:06.536210 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:06.537606 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.571162 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000056\n",
            "I0703 18:12:06.571465 139789930788736 set_essential_params.py:432] unique_id: 1000000056\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:06.571595 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 0\n",
            "I0703 18:12:06.571692 139789930788736 set_essential_params.py:434] doc_span_index: 0\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to [SEP]\n",
            "I0703 18:12:06.571911 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens & hal ##ske was founded by werner von siemens and johann georg hal ##ske on 1 october 1847 . based on the telegraph , their invention used a needle to point to the sequence of letters , instead of using morse code . the company , then called telegraph ##en - ba ##uan ##sta ##lt von siemens & hal ##ske , opened its first workshop on 12 october 1847 . roland busch was appointed ceo of siemens on february 3 , 2021 . in 1848 , the company built the first long - distance telegraph line in europe ; 500 km from berlin to frankfurt am main . in 1850 , the founder ' s younger brother , carl wilhelm siemens , later sir william siemens , started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:12 26:13 27:14 28:15 29:16 30:16 31:17 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:39 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:42 65:42 66:42 67:43 68:44 69:45 70:46 71:46 72:46 73:47 74:48 75:49 76:50 77:51 78:52 79:53 80:54 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:64 93:65 94:65 95:66 96:67 97:67 98:68 99:69 100:70 101:71 102:72 103:73 104:73 105:73 106:74 107:75 108:76 109:77 110:77 111:78 112:79 113:80 114:81 115:82 116:83 117:84 118:85 119:85 120:86 121:87 122:87 123:88 124:89 125:89 126:89 127:90 128:91 129:91 130:92 131:93 132:94 133:94 134:95 135:96 136:97 137:98 138:98 139:99 140:100 141:101 142:102 143:103 144:104 145:105 146:105 147:106 148:107 149:108 150:109 151:110 152:111 153:112 154:113 155:114 156:114 157:115 158:116 159:117 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:124 169:124 170:125 171:126 172:127 173:128 174:128 175:129 176:130 177:130 178:131 179:132 180:133 181:134 182:135 183:136 184:137 185:137 186:138 187:139 188:140 189:141 190:141 191:142 192:143 193:144 194:145 195:145 196:146 197:146 198:147 199:148 200:148 201:149 202:150 203:151 204:152 205:153 206:153 207:153 208:154 209:155 210:156 211:157 212:158 213:158 214:158 215:159 216:160 217:161 218:162 219:163 220:163 221:164 222:165 223:166 224:166 225:167 226:168 227:169 228:170 229:171 230:172 231:173 232:174 233:175 234:175 235:176 236:177 237:177 238:178 239:179 240:180 241:181 242:182 243:183 244:184 245:185 246:186 247:186 248:186 249:187 250:188 251:189 252:190 253:191 254:192 255:193 256:194 257:195 258:195 259:196 260:196 261:197 262:198 263:199 264:199 265:199 266:200 267:201 268:202 269:203 270:204 271:205 272:206 273:207 274:208 275:209 276:209 277:210 278:211 279:211 280:212 281:213 282:214 283:215 284:215 285:216 286:217 287:218 288:219 289:219 290:220 291:221 292:222 293:223 294:224 295:225 296:225 297:225 298:226 299:227 300:228 301:229 302:230 303:231 304:232 305:233 306:234 307:234 308:234 309:234 310:235 311:236 312:236 313:237 314:238 315:239 316:240 317:241 318:242 319:243 320:244 321:245 322:246 323:247 324:248 325:249 326:249 327:250 328:251 329:251 330:252 331:253 332:254 333:255 334:256 335:257 336:258 337:259 338:260 339:260 340:260 341:260 342:261 343:262 344:263 345:263 346:263 347:264 348:265 349:266 350:267 351:268 352:269 353:270 354:271 355:271 356:272 357:272 358:273 359:274 360:274 361:275 362:276 363:277 364:278 365:279 366:280 367:281 368:281 369:282 370:283 371:283 372:284 373:285 374:286 375:287 376:288 377:289 378:290 379:291 380:292 381:293 382:294\n",
            "I0703 18:12:06.572167 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:0 12:1 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:12 26:13 27:14 28:15 29:16 30:16 31:17 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:39 57:39 58:40 59:41 60:42 61:42 62:42 63:42 64:42 65:42 66:42 67:43 68:44 69:45 70:46 71:46 72:46 73:47 74:48 75:49 76:50 77:51 78:52 79:53 80:54 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:64 93:65 94:65 95:66 96:67 97:67 98:68 99:69 100:70 101:71 102:72 103:73 104:73 105:73 106:74 107:75 108:76 109:77 110:77 111:78 112:79 113:80 114:81 115:82 116:83 117:84 118:85 119:85 120:86 121:87 122:87 123:88 124:89 125:89 126:89 127:90 128:91 129:91 130:92 131:93 132:94 133:94 134:95 135:96 136:97 137:98 138:98 139:99 140:100 141:101 142:102 143:103 144:104 145:105 146:105 147:106 148:107 149:108 150:109 151:110 152:111 153:112 154:113 155:114 156:114 157:115 158:116 159:117 160:117 161:118 162:119 163:120 164:121 165:122 166:123 167:124 168:124 169:124 170:125 171:126 172:127 173:128 174:128 175:129 176:130 177:130 178:131 179:132 180:133 181:134 182:135 183:136 184:137 185:137 186:138 187:139 188:140 189:141 190:141 191:142 192:143 193:144 194:145 195:145 196:146 197:146 198:147 199:148 200:148 201:149 202:150 203:151 204:152 205:153 206:153 207:153 208:154 209:155 210:156 211:157 212:158 213:158 214:158 215:159 216:160 217:161 218:162 219:163 220:163 221:164 222:165 223:166 224:166 225:167 226:168 227:169 228:170 229:171 230:172 231:173 232:174 233:175 234:175 235:176 236:177 237:177 238:178 239:179 240:180 241:181 242:182 243:183 244:184 245:185 246:186 247:186 248:186 249:187 250:188 251:189 252:190 253:191 254:192 255:193 256:194 257:195 258:195 259:196 260:196 261:197 262:198 263:199 264:199 265:199 266:200 267:201 268:202 269:203 270:204 271:205 272:206 273:207 274:208 275:209 276:209 277:210 278:211 279:211 280:212 281:213 282:214 283:215 284:215 285:216 286:217 287:218 288:219 289:219 290:220 291:221 292:222 293:223 294:224 295:225 296:225 297:225 298:226 299:227 300:228 301:229 302:230 303:231 304:232 305:233 306:234 307:234 308:234 309:234 310:235 311:236 312:236 313:237 314:238 315:239 316:240 317:241 318:242 319:243 320:244 321:245 322:246 323:247 324:248 325:249 326:249 327:250 328:251 329:251 330:252 331:253 332:254 333:255 334:256 335:257 336:258 337:259 338:260 339:260 340:260 341:260 342:261 343:262 344:263 345:263 346:263 347:264 348:265 349:266 350:267 351:268 352:269 353:270 354:271 355:271 356:272 357:272 358:273 359:274 360:274 361:275 362:276 363:277 364:278 365:279 366:280 367:281 368:281 369:282 370:283 371:283 372:284 373:285 374:286 375:287 376:288 377:289 378:290 379:291 380:292 381:293 382:294\n",
            "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.572417 139789930788736 set_essential_params.py:440] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 102\n",
            "I0703 18:12:06.642504 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 1004 11085 17140 2001 2631 2011 14121 3854 22108 1998 8968 12062 11085 17140 2006 1015 2255 9176 1012 2241 2006 1996 10013 1010 2037 11028 2109 1037 12201 2000 2391 2000 1996 5537 1997 4144 1010 2612 1997 2478 17107 3642 1012 1996 2194 1010 2059 2170 10013 2368 1011 8670 13860 9153 7096 3854 22108 1004 11085 17140 1010 2441 2049 2034 8395 2006 2260 2255 9176 1012 8262 15840 2001 2805 5766 1997 22108 2006 2337 1017 1010 25682 1012 1999 7993 1010 1996 2194 2328 1996 2034 2146 1011 3292 10013 2240 1999 2885 1025 3156 2463 2013 4068 2000 9780 2572 2364 1012 1999 7973 1010 1996 3910 1005 1055 3920 2567 1010 5529 9070 22108 1010 2101 2909 2520 22108 1010 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.643677 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.644278 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.649126 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000057\n",
            "I0703 18:12:06.649326 139789930788736 set_essential_params.py:432] unique_id: 1000000057\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:06.649433 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 1\n",
            "I0703 18:12:06.649520 139789930788736 set_essential_params.py:434] doc_span_index: 1\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees [SEP]\n",
            "I0703 18:12:06.650417 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] started to represent the company in london . the london agency became a branch office in 1858 . in the 1850s , the company was involved in building long - distance telegraph networks in russia . in 1855 , a company branch headed by another brother , carl heinrich von siemens , opened in st petersburg , russia . in 1867 , siemens completed the monumental indo - european telegraph line stretching over 11 , 000 km from london to calcutta . first electric locomotive , built in 1879 by company founder werner von siemens . in 1867 , werner von siemens described a dynamo without permanent magnet ##s . a similar system was also independently invented by any ##os jed ##lik and charles wheat ##stone , but siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:99 12:100 13:101 14:102 15:103 16:104 17:105 18:105 19:106 20:107 21:108 22:109 23:110 24:111 25:112 26:113 27:114 28:114 29:115 30:116 31:117 32:117 33:118 34:119 35:120 36:121 37:122 38:123 39:124 40:124 41:124 42:125 43:126 44:127 45:128 46:128 47:129 48:130 49:130 50:131 51:132 52:133 53:134 54:135 55:136 56:137 57:137 58:138 59:139 60:140 61:141 62:141 63:142 64:143 65:144 66:145 67:145 68:146 69:146 70:147 71:148 72:148 73:149 74:150 75:151 76:152 77:153 78:153 79:153 80:154 81:155 82:156 83:157 84:158 85:158 86:158 87:159 88:160 89:161 90:162 91:163 92:163 93:164 94:165 95:166 96:166 97:167 98:168 99:169 100:170 101:171 102:172 103:173 104:174 105:175 106:175 107:176 108:177 109:177 110:178 111:179 112:180 113:181 114:182 115:183 116:184 117:185 118:186 119:186 120:186 121:187 122:188 123:189 124:190 125:191 126:192 127:193 128:194 129:195 130:195 131:196 132:196 133:197 134:198 135:199 136:199 137:199 138:200 139:201 140:202 141:203 142:204 143:205 144:206 145:207 146:208 147:209 148:209 149:210 150:211 151:211 152:212 153:213 154:214 155:215 156:215 157:216 158:217 159:218 160:219 161:219 162:220 163:221 164:222 165:223 166:224 167:225 168:225 169:225 170:226 171:227 172:228 173:229 174:230 175:231 176:232 177:233 178:234 179:234 180:234 181:234 182:235 183:236 184:236 185:237 186:238 187:239 188:240 189:241 190:242 191:243 192:244 193:245 194:246 195:247 196:248 197:249 198:249 199:250 200:251 201:251 202:252 203:253 204:254 205:255 206:256 207:257 208:258 209:259 210:260 211:260 212:260 213:260 214:261 215:262 216:263 217:263 218:263 219:264 220:265 221:266 222:267 223:268 224:269 225:270 226:271 227:271 228:272 229:272 230:273 231:274 232:274 233:275 234:276 235:277 236:278 237:279 238:280 239:281 240:281 241:282 242:283 243:283 244:284 245:285 246:286 247:287 248:288 249:289 250:290 251:291 252:292 253:293 254:294 255:295 256:296 257:297 258:298 259:299 260:300 261:301 262:302 263:302 264:303 265:304 266:304 267:305 268:306 269:307 270:308 271:309 272:310 273:311 274:312 275:313 276:314 277:315 278:315 279:316 280:317 281:318 282:319 283:320 284:321 285:321 286:322 287:323 288:324 289:325 290:326 291:327 292:328 293:329 294:330 295:331 296:332 297:333 298:334 299:335 300:336 301:337 302:338 303:338 304:339 305:340 306:341 307:341 308:342 309:342 310:343 311:344 312:344 313:345 314:346 315:347 316:348 317:348 318:349 319:350 320:351 321:352 322:353 323:354 324:355 325:356 326:357 327:357 328:357 329:357 330:358 331:359 332:359 333:359 334:360 335:361 336:362 337:363 338:364 339:365 340:365 341:365 342:365 343:365 344:365 345:365 346:366 347:367 348:367 349:368 350:369 351:369 352:370 353:371 354:371 355:372 356:373 357:373 358:373 359:373 360:373 361:373 362:373 363:374 364:375 365:375 366:375 367:376 368:377 369:378 370:379 371:380 372:380 373:380 374:381 375:382 376:383 377:384 378:385 379:386 380:387 381:388 382:389\n",
            "I0703 18:12:06.650882 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:99 12:100 13:101 14:102 15:103 16:104 17:105 18:105 19:106 20:107 21:108 22:109 23:110 24:111 25:112 26:113 27:114 28:114 29:115 30:116 31:117 32:117 33:118 34:119 35:120 36:121 37:122 38:123 39:124 40:124 41:124 42:125 43:126 44:127 45:128 46:128 47:129 48:130 49:130 50:131 51:132 52:133 53:134 54:135 55:136 56:137 57:137 58:138 59:139 60:140 61:141 62:141 63:142 64:143 65:144 66:145 67:145 68:146 69:146 70:147 71:148 72:148 73:149 74:150 75:151 76:152 77:153 78:153 79:153 80:154 81:155 82:156 83:157 84:158 85:158 86:158 87:159 88:160 89:161 90:162 91:163 92:163 93:164 94:165 95:166 96:166 97:167 98:168 99:169 100:170 101:171 102:172 103:173 104:174 105:175 106:175 107:176 108:177 109:177 110:178 111:179 112:180 113:181 114:182 115:183 116:184 117:185 118:186 119:186 120:186 121:187 122:188 123:189 124:190 125:191 126:192 127:193 128:194 129:195 130:195 131:196 132:196 133:197 134:198 135:199 136:199 137:199 138:200 139:201 140:202 141:203 142:204 143:205 144:206 145:207 146:208 147:209 148:209 149:210 150:211 151:211 152:212 153:213 154:214 155:215 156:215 157:216 158:217 159:218 160:219 161:219 162:220 163:221 164:222 165:223 166:224 167:225 168:225 169:225 170:226 171:227 172:228 173:229 174:230 175:231 176:232 177:233 178:234 179:234 180:234 181:234 182:235 183:236 184:236 185:237 186:238 187:239 188:240 189:241 190:242 191:243 192:244 193:245 194:246 195:247 196:248 197:249 198:249 199:250 200:251 201:251 202:252 203:253 204:254 205:255 206:256 207:257 208:258 209:259 210:260 211:260 212:260 213:260 214:261 215:262 216:263 217:263 218:263 219:264 220:265 221:266 222:267 223:268 224:269 225:270 226:271 227:271 228:272 229:272 230:273 231:274 232:274 233:275 234:276 235:277 236:278 237:279 238:280 239:281 240:281 241:282 242:283 243:283 244:284 245:285 246:286 247:287 248:288 249:289 250:290 251:291 252:292 253:293 254:294 255:295 256:296 257:297 258:298 259:299 260:300 261:301 262:302 263:302 264:303 265:304 266:304 267:305 268:306 269:307 270:308 271:309 272:310 273:311 274:312 275:313 276:314 277:315 278:315 279:316 280:317 281:318 282:319 283:320 284:321 285:321 286:322 287:323 288:324 289:325 290:326 291:327 292:328 293:329 294:330 295:331 296:332 297:333 298:334 299:335 300:336 301:337 302:338 303:338 304:339 305:340 306:341 307:341 308:342 309:342 310:343 311:344 312:344 313:345 314:346 315:347 316:348 317:348 318:349 319:350 320:351 321:352 322:353 323:354 324:355 325:356 326:357 327:357 328:357 329:357 330:358 331:359 332:359 333:359 334:360 335:361 336:362 337:363 338:364 339:365 340:365 341:365 342:365 343:365 344:365 345:365 346:366 347:367 348:367 349:368 350:369 351:369 352:370 353:371 354:371 355:372 356:373 357:373 358:373 359:373 360:373 361:373 362:373 363:374 364:375 365:375 366:375 367:376 368:377 369:378 370:379 371:380 372:380 373:380 374:381 375:382 376:383 377:384 378:385 379:386 380:387 381:388 382:389\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.651182 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 102\n",
            "I0703 18:12:06.747658 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 2318 2000 5050 1996 2194 1999 2414 1012 1996 2414 4034 2150 1037 3589 2436 1999 8517 1012 1999 1996 16488 1010 1996 2194 2001 2920 1999 2311 2146 1011 3292 10013 6125 1999 3607 1012 1999 8492 1010 1037 2194 3589 3753 2011 2178 2567 1010 5529 10952 3854 22108 1010 2441 1999 2358 8062 1010 3607 1012 1999 7517 1010 22108 2949 1996 15447 11424 1011 2647 10013 2240 10917 2058 2340 1010 2199 2463 2013 2414 2000 13419 1012 2034 3751 8098 1010 2328 1999 7449 2011 2194 3910 14121 3854 22108 1012 1999 7517 1010 14121 3854 22108 2649 1037 17205 2302 4568 16853 2015 1012 1037 2714 2291 2001 2036 9174 8826 2011 2151 2891 24401 18393 1998 2798 10500 9221 1010 2021 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.748070 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.748356 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.752168 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000058\n",
            "I0703 18:12:06.752347 139789930788736 set_essential_params.py:432] unique_id: 1000000058\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:06.752470 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 2\n",
            "I0703 18:12:06.752588 139789930788736 set_essential_params.py:434] doc_span_index: 2\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - [SEP]\n",
            "I0703 18:12:06.752815 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens became the first company to build such devices . in 1881 , a siemens ac alter ##nator driven by a water ##mill was used to power the world ' s first electric street lighting in the town of god ##al ##ming , united kingdom . the company continued to grow and diversified into electric trains and light bulbs . in 1885 , siemens sold one of its generators to george west ##ing ##house , thereby enabling west ##ing ##house to begin experimenting with ac networks in pittsburgh , pennsylvania . in 1887 , siemens opened its first office in japan . in 1890 , the founder retired and left the running of the company to his brother carl and sons arnold and wilhelm . in 1892 , siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:201 12:202 13:203 14:204 15:205 16:206 17:207 18:208 19:209 20:209 21:210 22:211 23:211 24:212 25:213 26:214 27:215 28:215 29:216 30:217 31:218 32:219 33:219 34:220 35:221 36:222 37:223 38:224 39:225 40:225 41:225 42:226 43:227 44:228 45:229 46:230 47:231 48:232 49:233 50:234 51:234 52:234 53:234 54:235 55:236 56:236 57:237 58:238 59:239 60:240 61:241 62:242 63:243 64:244 65:245 66:246 67:247 68:248 69:249 70:249 71:250 72:251 73:251 74:252 75:253 76:254 77:255 78:256 79:257 80:258 81:259 82:260 83:260 84:260 85:260 86:261 87:262 88:263 89:263 90:263 91:264 92:265 93:266 94:267 95:268 96:269 97:270 98:271 99:271 100:272 101:272 102:273 103:274 104:274 105:275 106:276 107:277 108:278 109:279 110:280 111:281 112:281 113:282 114:283 115:283 116:284 117:285 118:286 119:287 120:288 121:289 122:290 123:291 124:292 125:293 126:294 127:295 128:296 129:297 130:298 131:299 132:300 133:301 134:302 135:302 136:303 137:304 138:304 139:305 140:306 141:307 142:308 143:309 144:310 145:311 146:312 147:313 148:314 149:315 150:315 151:316 152:317 153:318 154:319 155:320 156:321 157:321 158:322 159:323 160:324 161:325 162:326 163:327 164:328 165:329 166:330 167:331 168:332 169:333 170:334 171:335 172:336 173:337 174:338 175:338 176:339 177:340 178:341 179:341 180:342 181:342 182:343 183:344 184:344 185:345 186:346 187:347 188:348 189:348 190:349 191:350 192:351 193:352 194:353 195:354 196:355 197:356 198:357 199:357 200:357 201:357 202:358 203:359 204:359 205:359 206:360 207:361 208:362 209:363 210:364 211:365 212:365 213:365 214:365 215:365 216:365 217:365 218:366 219:367 220:367 221:368 222:369 223:369 224:370 225:371 226:371 227:372 228:373 229:373 230:373 231:373 232:373 233:373 234:373 235:374 236:375 237:375 238:375 239:376 240:377 241:378 242:379 243:380 244:380 245:380 246:381 247:382 248:383 249:384 250:385 251:386 252:387 253:388 254:389 255:389 256:390 257:391 258:391 259:392 260:393 261:394 262:395 263:396 264:397 265:398 266:399 267:400 268:401 269:402 270:402 271:403 272:403 273:403 274:404 275:404 276:405 277:406 278:407 279:408 280:409 281:410 282:411 283:411 284:412 285:413 286:414 287:415 288:416 289:416 290:417 291:418 292:419 293:420 294:421 295:422 296:423 297:423 298:424 299:425 300:425 301:426 302:427 303:428 304:428 305:428 306:429 307:430 308:430 309:431 310:431 311:431 312:432 313:432 314:432 315:433 316:434 317:434 318:435 319:435 320:435 321:435 322:435 323:435 324:436 325:436 326:436 327:437 328:438 329:438 330:438 331:438 332:438 333:438 334:439 335:440 336:440 337:440 338:440 339:440 340:440 341:440 342:440 343:441 344:441 345:442 346:442 347:442 348:443 349:444 350:445 351:446 352:447 353:447 354:447 355:447 356:447 357:447 358:447 359:448 360:449 361:449 362:449 363:449 364:449 365:450 366:451 367:452 368:453 369:454 370:454 371:454 372:455 373:456 374:457 375:458 376:459 377:460 378:461 379:462 380:463 381:464 382:464\n",
            "I0703 18:12:06.753087 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:201 12:202 13:203 14:204 15:205 16:206 17:207 18:208 19:209 20:209 21:210 22:211 23:211 24:212 25:213 26:214 27:215 28:215 29:216 30:217 31:218 32:219 33:219 34:220 35:221 36:222 37:223 38:224 39:225 40:225 41:225 42:226 43:227 44:228 45:229 46:230 47:231 48:232 49:233 50:234 51:234 52:234 53:234 54:235 55:236 56:236 57:237 58:238 59:239 60:240 61:241 62:242 63:243 64:244 65:245 66:246 67:247 68:248 69:249 70:249 71:250 72:251 73:251 74:252 75:253 76:254 77:255 78:256 79:257 80:258 81:259 82:260 83:260 84:260 85:260 86:261 87:262 88:263 89:263 90:263 91:264 92:265 93:266 94:267 95:268 96:269 97:270 98:271 99:271 100:272 101:272 102:273 103:274 104:274 105:275 106:276 107:277 108:278 109:279 110:280 111:281 112:281 113:282 114:283 115:283 116:284 117:285 118:286 119:287 120:288 121:289 122:290 123:291 124:292 125:293 126:294 127:295 128:296 129:297 130:298 131:299 132:300 133:301 134:302 135:302 136:303 137:304 138:304 139:305 140:306 141:307 142:308 143:309 144:310 145:311 146:312 147:313 148:314 149:315 150:315 151:316 152:317 153:318 154:319 155:320 156:321 157:321 158:322 159:323 160:324 161:325 162:326 163:327 164:328 165:329 166:330 167:331 168:332 169:333 170:334 171:335 172:336 173:337 174:338 175:338 176:339 177:340 178:341 179:341 180:342 181:342 182:343 183:344 184:344 185:345 186:346 187:347 188:348 189:348 190:349 191:350 192:351 193:352 194:353 195:354 196:355 197:356 198:357 199:357 200:357 201:357 202:358 203:359 204:359 205:359 206:360 207:361 208:362 209:363 210:364 211:365 212:365 213:365 214:365 215:365 216:365 217:365 218:366 219:367 220:367 221:368 222:369 223:369 224:370 225:371 226:371 227:372 228:373 229:373 230:373 231:373 232:373 233:373 234:373 235:374 236:375 237:375 238:375 239:376 240:377 241:378 242:379 243:380 244:380 245:380 246:381 247:382 248:383 249:384 250:385 251:386 252:387 253:388 254:389 255:389 256:390 257:391 258:391 259:392 260:393 261:394 262:395 263:396 264:397 265:398 266:399 267:400 268:401 269:402 270:402 271:403 272:403 273:403 274:404 275:404 276:405 277:406 278:407 279:408 280:409 281:410 282:411 283:411 284:412 285:413 286:414 287:415 288:416 289:416 290:417 291:418 292:419 293:420 294:421 295:422 296:423 297:423 298:424 299:425 300:425 301:426 302:427 303:428 304:428 305:428 306:429 307:430 308:430 309:431 310:431 311:431 312:432 313:432 314:432 315:433 316:434 317:434 318:435 319:435 320:435 321:435 322:435 323:435 324:436 325:436 326:436 327:437 328:438 329:438 330:438 331:438 332:438 333:438 334:439 335:440 336:440 337:440 338:440 339:440 340:440 341:440 342:440 343:441 344:441 345:442 346:442 347:442 348:443 349:444 350:445 351:446 352:447 353:447 354:447 355:447 356:447 357:447 358:447 359:448 360:449 361:449 362:449 363:449 364:449 365:450 366:451 367:452 368:453 369:454 370:454 371:454 372:455 373:456 374:457 375:458 376:459 377:460 378:461 379:462 380:463 381:464 382:464\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.753308 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 102\n",
            "I0703 18:12:06.851300 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 2150 1996 2034 2194 2000 3857 2107 5733 1012 1999 7005 1010 1037 22108 9353 11477 27413 5533 2011 1037 2300 19912 2001 2109 2000 2373 1996 2088 1005 1055 2034 3751 2395 7497 1999 1996 2237 1997 2643 2389 6562 1010 2142 2983 1012 1996 2194 2506 2000 4982 1998 24908 2046 3751 4499 1998 2422 25548 1012 1999 6571 1010 22108 2853 2028 1997 2049 16937 2000 2577 2225 2075 4580 1010 8558 12067 2225 2075 4580 2000 4088 23781 2007 9353 6125 1999 6278 1010 3552 1012 1999 6837 1010 22108 2441 2049 2034 2436 1999 2900 1012 1999 6193 1010 1996 3910 3394 1998 2187 1996 2770 1997 1996 2194 2000 2010 2567 5529 1998 4124 7779 1998 9070 1012 1999 6527 1010 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.851646 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.851918 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:06.856602 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000059\n",
            "I0703 18:12:06.856801 139789930788736 set_essential_params.py:432] unique_id: 1000000059\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:06.856878 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 3\n",
            "I0703 18:12:06.856946 139789930788736 set_essential_params.py:434] doc_span_index: 3\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the [SEP]\n",
            "I0703 18:12:06.857168 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens were contracted to construct the hobart electric tramway in tasmania , australia as they increased their markets . the system opened in 1893 and became the first complete electric tram network in the southern hemisphere . siemens & hal ##ske ( s & h ) was incorporated in 1897 , and then merged parts of its activities with sc ##hu ##cker ##t & co . , nuremberg in 1903 to become siemens - sc ##hu ##cker ##t . in 1907 , siemens ( siemens & hal ##ske and siemens - sc ##hu ##cker ##t ) had 34 , 324 employees and was the seventh - largest company in the german empire by number of employees . in 1919 , s & h and two other companies jointly formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:305 12:306 13:307 14:308 15:309 16:310 17:311 18:312 19:313 20:314 21:315 22:315 23:316 24:317 25:318 26:319 27:320 28:321 29:321 30:322 31:323 32:324 33:325 34:326 35:327 36:328 37:329 38:330 39:331 40:332 41:333 42:334 43:335 44:336 45:337 46:338 47:338 48:339 49:340 50:341 51:341 52:342 53:342 54:343 55:344 56:344 57:345 58:346 59:347 60:348 61:348 62:349 63:350 64:351 65:352 66:353 67:354 68:355 69:356 70:357 71:357 72:357 73:357 74:358 75:359 76:359 77:359 78:360 79:361 80:362 81:363 82:364 83:365 84:365 85:365 86:365 87:365 88:365 89:365 90:366 91:367 92:367 93:368 94:369 95:369 96:370 97:371 98:371 99:372 100:373 101:373 102:373 103:373 104:373 105:373 106:373 107:374 108:375 109:375 110:375 111:376 112:377 113:378 114:379 115:380 116:380 117:380 118:381 119:382 120:383 121:384 122:385 123:386 124:387 125:388 126:389 127:389 128:390 129:391 130:391 131:392 132:393 133:394 134:395 135:396 136:397 137:398 138:399 139:400 140:401 141:402 142:402 143:403 144:403 145:403 146:404 147:404 148:405 149:406 150:407 151:408 152:409 153:410 154:411 155:411 156:412 157:413 158:414 159:415 160:416 161:416 162:417 163:418 164:419 165:420 166:421 167:422 168:423 169:423 170:424 171:425 172:425 173:426 174:427 175:428 176:428 177:428 178:429 179:430 180:430 181:431 182:431 183:431 184:432 185:432 186:432 187:433 188:434 189:434 190:435 191:435 192:435 193:435 194:435 195:435 196:436 197:436 198:436 199:437 200:438 201:438 202:438 203:438 204:438 205:438 206:439 207:440 208:440 209:440 210:440 211:440 212:440 213:440 214:440 215:441 216:441 217:442 218:442 219:442 220:443 221:444 222:445 223:446 224:447 225:447 226:447 227:447 228:447 229:447 230:447 231:448 232:449 233:449 234:449 235:449 236:449 237:450 238:451 239:452 240:453 241:454 242:454 243:454 244:455 245:456 246:457 247:458 248:459 249:460 250:461 251:462 252:463 253:464 254:464 255:464 256:465 257:466 258:466 259:467 260:468 261:469 262:469 263:470 264:471 265:472 266:473 267:473 268:473 269:473 270:473 271:474 272:475 273:476 274:477 275:478 276:479 277:480 278:481 279:482 280:483 281:484 282:485 283:486 284:486 285:487 286:488 287:489 288:490 289:491 290:492 291:493 292:494 293:495 294:495 295:496 296:497 297:498 298:499 299:500 300:501 301:502 302:503 303:504 304:505 305:506 306:507 307:508 308:509 309:509 310:509 311:510 312:511 313:512 314:513 315:514 316:514 317:514 318:515 319:516 320:517 321:517 322:518 323:519 324:519 325:519 326:519 327:520 328:520 329:521 330:522 331:522 332:523 333:524 334:524 335:525 336:525 337:525 338:525 339:525 340:525 341:525 342:526 343:527 344:528 345:529 346:530 347:531 348:532 349:533 350:534 351:534 352:534 353:534 354:535 355:535 356:536 357:537 358:538 359:539 360:540 361:541 362:542 363:543 364:544 365:544 366:545 367:546 368:547 369:548 370:548 371:549 372:550 373:550 374:551 375:552 376:553 377:554 378:555 379:556 380:557 381:558 382:559\n",
            "I0703 18:12:06.950664 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:305 12:306 13:307 14:308 15:309 16:310 17:311 18:312 19:313 20:314 21:315 22:315 23:316 24:317 25:318 26:319 27:320 28:321 29:321 30:322 31:323 32:324 33:325 34:326 35:327 36:328 37:329 38:330 39:331 40:332 41:333 42:334 43:335 44:336 45:337 46:338 47:338 48:339 49:340 50:341 51:341 52:342 53:342 54:343 55:344 56:344 57:345 58:346 59:347 60:348 61:348 62:349 63:350 64:351 65:352 66:353 67:354 68:355 69:356 70:357 71:357 72:357 73:357 74:358 75:359 76:359 77:359 78:360 79:361 80:362 81:363 82:364 83:365 84:365 85:365 86:365 87:365 88:365 89:365 90:366 91:367 92:367 93:368 94:369 95:369 96:370 97:371 98:371 99:372 100:373 101:373 102:373 103:373 104:373 105:373 106:373 107:374 108:375 109:375 110:375 111:376 112:377 113:378 114:379 115:380 116:380 117:380 118:381 119:382 120:383 121:384 122:385 123:386 124:387 125:388 126:389 127:389 128:390 129:391 130:391 131:392 132:393 133:394 134:395 135:396 136:397 137:398 138:399 139:400 140:401 141:402 142:402 143:403 144:403 145:403 146:404 147:404 148:405 149:406 150:407 151:408 152:409 153:410 154:411 155:411 156:412 157:413 158:414 159:415 160:416 161:416 162:417 163:418 164:419 165:420 166:421 167:422 168:423 169:423 170:424 171:425 172:425 173:426 174:427 175:428 176:428 177:428 178:429 179:430 180:430 181:431 182:431 183:431 184:432 185:432 186:432 187:433 188:434 189:434 190:435 191:435 192:435 193:435 194:435 195:435 196:436 197:436 198:436 199:437 200:438 201:438 202:438 203:438 204:438 205:438 206:439 207:440 208:440 209:440 210:440 211:440 212:440 213:440 214:440 215:441 216:441 217:442 218:442 219:442 220:443 221:444 222:445 223:446 224:447 225:447 226:447 227:447 228:447 229:447 230:447 231:448 232:449 233:449 234:449 235:449 236:449 237:450 238:451 239:452 240:453 241:454 242:454 243:454 244:455 245:456 246:457 247:458 248:459 249:460 250:461 251:462 252:463 253:464 254:464 255:464 256:465 257:466 258:466 259:467 260:468 261:469 262:469 263:470 264:471 265:472 266:473 267:473 268:473 269:473 270:473 271:474 272:475 273:476 274:477 275:478 276:479 277:480 278:481 279:482 280:483 281:484 282:485 283:486 284:486 285:487 286:488 287:489 288:490 289:491 290:492 291:493 292:494 293:495 294:495 295:496 296:497 297:498 298:499 299:500 300:501 301:502 302:503 303:504 304:505 305:506 306:507 307:508 308:509 309:509 310:509 311:510 312:511 313:512 314:513 315:514 316:514 317:514 318:515 319:516 320:517 321:517 322:518 323:519 324:519 325:519 326:519 327:520 328:520 329:521 330:522 331:522 332:523 333:524 334:524 335:525 336:525 337:525 338:525 339:525 340:525 341:525 342:526 343:527 344:528 345:529 346:530 347:531 348:532 349:533 350:534 351:534 352:534 353:534 354:535 355:535 356:536 357:537 358:538 359:539 360:540 361:541 362:542 363:543 364:544 365:544 366:545 367:546 368:547 369:548 370:548 371:549 372:550 373:550 374:551 375:552 376:553 377:554 378:555 379:556 380:557 381:558 382:559\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:06.952157 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 102\n",
            "I0703 18:12:06.952411 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 2020 11016 2000 9570 1996 14005 3751 17050 1999 12343 1010 2660 2004 2027 3445 2037 6089 1012 1996 2291 2441 1999 6489 1998 2150 1996 2034 3143 3751 12517 2897 1999 1996 2670 14130 1012 22108 1004 11085 17140 1006 1055 1004 1044 1007 2001 5100 1999 6347 1010 1998 2059 5314 3033 1997 2049 3450 2007 8040 6979 9102 2102 1004 2522 1012 1010 19346 1999 5778 2000 2468 22108 1011 8040 6979 9102 2102 1012 1999 5528 1010 22108 1006 22108 1004 11085 17140 1998 22108 1011 8040 6979 9102 2102 1007 2018 4090 1010 27234 5126 1998 2001 1996 5066 1011 2922 2194 1999 1996 2446 3400 2011 2193 1997 5126 1012 1999 4529 1010 1055 1004 1044 1998 2048 2060 3316 10776 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.952576 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:06.952710 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.059182 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000060\n",
            "I0703 18:12:07.060968 139789930788736 set_essential_params.py:432] unique_id: 1000000060\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.061150 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 4\n",
            "I0703 18:12:07.061249 139789930788736 set_essential_params.py:434] doc_span_index: 4\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser [SEP]\n",
            "I0703 18:12:07.061575 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] formed the os ##ram light ##bu ##lb company . british siemens advertisement from the 1920s era . during the 1920s and 1930s , s & h started to manufacture radios , television sets , and electron microscope ##s . in 1932 , rein ##iger , ge ##bber ##t & sc ##hall ( er ##lang ##en ) , ph ##oni ##x ag ( ru ##do ##ls ##tadt ) and siemens - rein ##iger - ve ##if ##a mb ##h ( berlin ) merged to form the siemens - rein ##iger - we ##rke ag ( sr ##w ) , the third of the so - called parent companies that merged in 1966 to form the present - day siemens ag . in the 1920s , siemens constructed the ar ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:400 12:401 13:402 14:402 15:403 16:403 17:403 18:404 19:404 20:405 21:406 22:407 23:408 24:409 25:410 26:411 27:411 28:412 29:413 30:414 31:415 32:416 33:416 34:417 35:418 36:419 37:420 38:421 39:422 40:423 41:423 42:424 43:425 44:425 45:426 46:427 47:428 48:428 49:428 50:429 51:430 52:430 53:431 54:431 55:431 56:432 57:432 58:432 59:433 60:434 61:434 62:435 63:435 64:435 65:435 66:435 67:435 68:436 69:436 70:436 71:437 72:438 73:438 74:438 75:438 76:438 77:438 78:439 79:440 80:440 81:440 82:440 83:440 84:440 85:440 86:440 87:441 88:441 89:442 90:442 91:442 92:443 93:444 94:445 95:446 96:447 97:447 98:447 99:447 100:447 101:447 102:447 103:448 104:449 105:449 106:449 107:449 108:449 109:450 110:451 111:452 112:453 113:454 114:454 115:454 116:455 117:456 118:457 119:458 120:459 121:460 122:461 123:462 124:463 125:464 126:464 127:464 128:465 129:466 130:466 131:467 132:468 133:469 134:469 135:470 136:471 137:472 138:473 139:473 140:473 141:473 142:473 143:474 144:475 145:476 146:477 147:478 148:479 149:480 150:481 151:482 152:483 153:484 154:485 155:486 156:486 157:487 158:488 159:489 160:490 161:491 162:492 163:493 164:494 165:495 166:495 167:496 168:497 169:498 170:499 171:500 172:501 173:502 174:503 175:504 176:505 177:506 178:507 179:508 180:509 181:509 182:509 183:510 184:511 185:512 186:513 187:514 188:514 189:514 190:515 191:516 192:517 193:517 194:518 195:519 196:519 197:519 198:519 199:520 200:520 201:521 202:522 203:522 204:523 205:524 206:524 207:525 208:525 209:525 210:525 211:525 212:525 213:525 214:526 215:527 216:528 217:529 218:530 219:531 220:532 221:533 222:534 223:534 224:534 225:534 226:535 227:535 228:536 229:537 230:538 231:539 232:540 233:541 234:542 235:543 236:544 237:544 238:545 239:546 240:547 241:548 242:548 243:549 244:550 245:550 246:551 247:552 248:553 249:554 250:555 251:556 252:557 253:558 254:559 255:560 256:561 257:562 258:563 259:563 260:563 261:564 262:565 263:566 264:567 265:568 266:569 267:570 268:571 269:572 270:572 271:573 272:574 273:575 274:576 275:577 276:578 277:579 278:580 279:580 280:581 281:582 282:583 283:584 284:585 285:586 286:587 287:588 288:589 289:590 290:591 291:592 292:593 293:594 294:595 295:596 296:596 297:597 298:598 299:599 300:600 301:600 302:601 303:602 304:603 305:604 306:605 307:606 308:607 309:608 310:609 311:610 312:611 313:612 314:613 315:614 316:615 317:615 318:616 319:617 320:618 321:619 322:620 323:621 324:622 325:623 326:624 327:625 328:625 329:625 330:626 331:627 332:628 333:628 334:629 335:630 336:631 337:631 338:632 339:633 340:634 341:635 342:636 343:637 344:638 345:639 346:640 347:641 348:642 349:643 350:644 351:645 352:646 353:647 354:648 355:649 356:650 357:650 358:651 359:652 360:652 361:653 362:654 363:655 364:656 365:656 366:656 367:657 368:657 369:657 370:657 371:658 372:658 373:659 374:660 375:661 376:662 377:663 378:664 379:665 380:665 381:666 382:666\n",
            "I0703 18:12:07.061995 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:400 12:401 13:402 14:402 15:403 16:403 17:403 18:404 19:404 20:405 21:406 22:407 23:408 24:409 25:410 26:411 27:411 28:412 29:413 30:414 31:415 32:416 33:416 34:417 35:418 36:419 37:420 38:421 39:422 40:423 41:423 42:424 43:425 44:425 45:426 46:427 47:428 48:428 49:428 50:429 51:430 52:430 53:431 54:431 55:431 56:432 57:432 58:432 59:433 60:434 61:434 62:435 63:435 64:435 65:435 66:435 67:435 68:436 69:436 70:436 71:437 72:438 73:438 74:438 75:438 76:438 77:438 78:439 79:440 80:440 81:440 82:440 83:440 84:440 85:440 86:440 87:441 88:441 89:442 90:442 91:442 92:443 93:444 94:445 95:446 96:447 97:447 98:447 99:447 100:447 101:447 102:447 103:448 104:449 105:449 106:449 107:449 108:449 109:450 110:451 111:452 112:453 113:454 114:454 115:454 116:455 117:456 118:457 119:458 120:459 121:460 122:461 123:462 124:463 125:464 126:464 127:464 128:465 129:466 130:466 131:467 132:468 133:469 134:469 135:470 136:471 137:472 138:473 139:473 140:473 141:473 142:473 143:474 144:475 145:476 146:477 147:478 148:479 149:480 150:481 151:482 152:483 153:484 154:485 155:486 156:486 157:487 158:488 159:489 160:490 161:491 162:492 163:493 164:494 165:495 166:495 167:496 168:497 169:498 170:499 171:500 172:501 173:502 174:503 175:504 176:505 177:506 178:507 179:508 180:509 181:509 182:509 183:510 184:511 185:512 186:513 187:514 188:514 189:514 190:515 191:516 192:517 193:517 194:518 195:519 196:519 197:519 198:519 199:520 200:520 201:521 202:522 203:522 204:523 205:524 206:524 207:525 208:525 209:525 210:525 211:525 212:525 213:525 214:526 215:527 216:528 217:529 218:530 219:531 220:532 221:533 222:534 223:534 224:534 225:534 226:535 227:535 228:536 229:537 230:538 231:539 232:540 233:541 234:542 235:543 236:544 237:544 238:545 239:546 240:547 241:548 242:548 243:549 244:550 245:550 246:551 247:552 248:553 249:554 250:555 251:556 252:557 253:558 254:559 255:560 256:561 257:562 258:563 259:563 260:563 261:564 262:565 263:566 264:567 265:568 266:569 267:570 268:571 269:572 270:572 271:573 272:574 273:575 274:576 275:577 276:578 277:579 278:580 279:580 280:581 281:582 282:583 283:584 284:585 285:586 286:587 287:588 288:589 289:590 290:591 291:592 292:593 293:594 294:595 295:596 296:596 297:597 298:598 299:599 300:600 301:600 302:601 303:602 304:603 305:604 306:605 307:606 308:607 309:608 310:609 311:610 312:611 313:612 314:613 315:614 316:615 317:615 318:616 319:617 320:618 321:619 322:620 323:621 324:622 325:623 326:624 327:625 328:625 329:625 330:626 331:627 332:628 333:628 334:629 335:630 336:631 337:631 338:632 339:633 340:634 341:635 342:636 343:637 344:638 345:639 346:640 347:641 348:642 349:643 350:644 351:645 352:646 353:647 354:648 355:649 356:650 357:650 358:651 359:652 360:652 361:653 362:654 363:655 364:656 365:656 366:656 367:657 368:657 369:657 370:657 371:658 372:658 373:659 374:660 375:661 376:662 377:663 378:664 379:665 380:665 381:666 382:666\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.062430 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 102\n",
            "I0703 18:12:07.153236 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 2719 1996 9808 6444 2422 8569 20850 2194 1012 2329 22108 15147 2013 1996 6641 3690 1012 2076 1996 6641 1998 5687 1010 1055 1004 1044 2318 2000 9922 22229 1010 2547 4520 1010 1998 10496 24635 2015 1012 1999 4673 1010 27788 17071 1010 16216 29325 2102 1004 8040 9892 1006 9413 25023 2368 1007 1010 6887 10698 2595 12943 1006 21766 3527 4877 18808 1007 1998 22108 1011 27788 17071 1011 2310 10128 2050 16914 2232 1006 4068 1007 5314 2000 2433 1996 22108 1011 27788 17071 1011 2057 25074 12943 1006 5034 2860 1007 1010 1996 2353 1997 1996 2061 1011 2170 6687 3316 2008 5314 1999 3547 2000 2433 1996 2556 1011 2154 22108 12943 1012 1999 1996 6641 1010 22108 3833 1996 12098 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.154593 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.155250 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.159377 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000061\n",
            "I0703 18:12:07.159561 139789930788736 set_essential_params.py:432] unique_id: 1000000061\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.159659 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 5\n",
            "I0703 18:12:07.159744 139789930788736 set_essential_params.py:434] doc_span_index: 5\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & [SEP]\n",
            "I0703 18:12:07.160056 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] ##dna ##cr ##ush ##a hydro power station on the river shannon in the then irish free state , and it was a world first for its design . the company is remembered for its desire to raise the wages of its under - paid workers only to be over ##ru ##led by the cum ##ann na ng ##ae ##dh ##eal government . siemens ( at the time : siemens - sc ##hu ##cker ##t ) exploited the forced labour of deported people in ex ##ter ##mina ##tion camps . the company owned a plant in auschwitz concentration camp . siemens factory and ravens ##bruck concentration camp . siemens exploited the forced labour of women in the concentration camp of ravens ##bruck . the factory was located in front of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:473 12:473 13:473 14:473 15:474 16:475 17:476 18:477 19:478 20:479 21:480 22:481 23:482 24:483 25:484 26:485 27:486 28:486 29:487 30:488 31:489 32:490 33:491 34:492 35:493 36:494 37:495 38:495 39:496 40:497 41:498 42:499 43:500 44:501 45:502 46:503 47:504 48:505 49:506 50:507 51:508 52:509 53:509 54:509 55:510 56:511 57:512 58:513 59:514 60:514 61:514 62:515 63:516 64:517 65:517 66:518 67:519 68:519 69:519 70:519 71:520 72:520 73:521 74:522 75:522 76:523 77:524 78:524 79:525 80:525 81:525 82:525 83:525 84:525 85:525 86:526 87:527 88:528 89:529 90:530 91:531 92:532 93:533 94:534 95:534 96:534 97:534 98:535 99:535 100:536 101:537 102:538 103:539 104:540 105:541 106:542 107:543 108:544 109:544 110:545 111:546 112:547 113:548 114:548 115:549 116:550 117:550 118:551 119:552 120:553 121:554 122:555 123:556 124:557 125:558 126:559 127:560 128:561 129:562 130:563 131:563 132:563 133:564 134:565 135:566 136:567 137:568 138:569 139:570 140:571 141:572 142:572 143:573 144:574 145:575 146:576 147:577 148:578 149:579 150:580 151:580 152:581 153:582 154:583 155:584 156:585 157:586 158:587 159:588 160:589 161:590 162:591 163:592 164:593 165:594 166:595 167:596 168:596 169:597 170:598 171:599 172:600 173:600 174:601 175:602 176:603 177:604 178:605 179:606 180:607 181:608 182:609 183:610 184:611 185:612 186:613 187:614 188:615 189:615 190:616 191:617 192:618 193:619 194:620 195:621 196:622 197:623 198:624 199:625 200:625 201:625 202:626 203:627 204:628 205:628 206:629 207:630 208:631 209:631 210:632 211:633 212:634 213:635 214:636 215:637 216:638 217:639 218:640 219:641 220:642 221:643 222:644 223:645 224:646 225:647 226:648 227:649 228:650 229:650 230:651 231:652 232:652 233:653 234:654 235:655 236:656 237:656 238:656 239:657 240:657 241:657 242:657 243:658 244:658 245:659 246:660 247:661 248:662 249:663 250:664 251:665 252:665 253:666 254:666 255:666 256:667 257:667 258:667 259:668 260:668 261:668 262:669 263:670 264:671 265:672 266:673 267:674 268:675 269:676 270:677 271:678 272:679 273:680 274:681 275:682 276:683 277:684 278:685 279:685 280:686 281:687 282:688 283:689 284:689 285:690 286:691 287:692 288:693 289:694 290:695 291:696 292:697 293:698 294:699 295:700 296:701 297:701 298:702 299:703 300:704 301:705 302:706 303:707 304:707 305:708 306:709 307:709 308:709 309:709 310:710 311:711 312:712 313:713 314:713 315:714 316:714 317:715 318:716 319:717 320:718 321:719 322:720 323:721 324:722 325:723 326:724 327:724 328:725 329:725 330:726 331:727 332:728 333:729 334:730 335:730 336:731 337:732 338:733 339:734 340:735 341:735 342:736 343:737 344:737 345:737 346:738 347:738 348:739 349:740 350:741 351:741 352:742 353:743 354:744 355:745 356:746 357:747 358:748 359:748 360:749 361:749 362:749 363:750 364:751 365:752 366:753 367:753 368:754 369:755 370:755 371:756 372:757 373:757 374:758 375:759 376:759 377:759 378:760 379:761 380:761 381:762 382:763\n",
            "I0703 18:12:07.160444 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:473 12:473 13:473 14:473 15:474 16:475 17:476 18:477 19:478 20:479 21:480 22:481 23:482 24:483 25:484 26:485 27:486 28:486 29:487 30:488 31:489 32:490 33:491 34:492 35:493 36:494 37:495 38:495 39:496 40:497 41:498 42:499 43:500 44:501 45:502 46:503 47:504 48:505 49:506 50:507 51:508 52:509 53:509 54:509 55:510 56:511 57:512 58:513 59:514 60:514 61:514 62:515 63:516 64:517 65:517 66:518 67:519 68:519 69:519 70:519 71:520 72:520 73:521 74:522 75:522 76:523 77:524 78:524 79:525 80:525 81:525 82:525 83:525 84:525 85:525 86:526 87:527 88:528 89:529 90:530 91:531 92:532 93:533 94:534 95:534 96:534 97:534 98:535 99:535 100:536 101:537 102:538 103:539 104:540 105:541 106:542 107:543 108:544 109:544 110:545 111:546 112:547 113:548 114:548 115:549 116:550 117:550 118:551 119:552 120:553 121:554 122:555 123:556 124:557 125:558 126:559 127:560 128:561 129:562 130:563 131:563 132:563 133:564 134:565 135:566 136:567 137:568 138:569 139:570 140:571 141:572 142:572 143:573 144:574 145:575 146:576 147:577 148:578 149:579 150:580 151:580 152:581 153:582 154:583 155:584 156:585 157:586 158:587 159:588 160:589 161:590 162:591 163:592 164:593 165:594 166:595 167:596 168:596 169:597 170:598 171:599 172:600 173:600 174:601 175:602 176:603 177:604 178:605 179:606 180:607 181:608 182:609 183:610 184:611 185:612 186:613 187:614 188:615 189:615 190:616 191:617 192:618 193:619 194:620 195:621 196:622 197:623 198:624 199:625 200:625 201:625 202:626 203:627 204:628 205:628 206:629 207:630 208:631 209:631 210:632 211:633 212:634 213:635 214:636 215:637 216:638 217:639 218:640 219:641 220:642 221:643 222:644 223:645 224:646 225:647 226:648 227:649 228:650 229:650 230:651 231:652 232:652 233:653 234:654 235:655 236:656 237:656 238:656 239:657 240:657 241:657 242:657 243:658 244:658 245:659 246:660 247:661 248:662 249:663 250:664 251:665 252:665 253:666 254:666 255:666 256:667 257:667 258:667 259:668 260:668 261:668 262:669 263:670 264:671 265:672 266:673 267:674 268:675 269:676 270:677 271:678 272:679 273:680 274:681 275:682 276:683 277:684 278:685 279:685 280:686 281:687 282:688 283:689 284:689 285:690 286:691 287:692 288:693 289:694 290:695 291:696 292:697 293:698 294:699 295:700 296:701 297:701 298:702 299:703 300:704 301:705 302:706 303:707 304:707 305:708 306:709 307:709 308:709 309:709 310:710 311:711 312:712 313:713 314:713 315:714 316:714 317:715 318:716 319:717 320:718 321:719 322:720 323:721 324:722 325:723 326:724 327:724 328:725 329:725 330:726 331:727 332:728 333:729 334:730 335:730 336:731 337:732 338:733 339:734 340:735 341:735 342:736 343:737 344:737 345:737 346:738 347:738 348:739 349:740 350:741 351:741 352:742 353:743 354:744 355:745 356:746 357:747 358:748 359:748 360:749 361:749 362:749 363:750 364:751 365:752 366:753 367:753 368:754 369:755 370:755 371:756 372:757 373:757 374:758 375:759 376:759 377:759 378:760 379:761 380:761 381:762 382:763\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.160716 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 102\n",
            "I0703 18:12:07.257721 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 28911 26775 20668 2050 18479 2373 2276 2006 1996 2314 10881 1999 1996 2059 3493 2489 2110 1010 1998 2009 2001 1037 2088 2034 2005 2049 2640 1012 1996 2194 2003 4622 2005 2049 4792 2000 5333 1996 12678 1997 2049 2104 1011 3825 3667 2069 2000 2022 2058 6820 3709 2011 1996 13988 11639 6583 12835 6679 16425 15879 2231 1012 22108 1006 2012 1996 2051 1024 22108 1011 8040 6979 9102 2102 1007 18516 1996 3140 4428 1997 17929 2111 1999 4654 3334 22311 3508 7958 1012 1996 2194 3079 1037 3269 1999 24363 6693 3409 1012 22108 4713 1998 17272 28985 6693 3409 1012 22108 18516 1996 3140 4428 1997 2308 1999 1996 6693 3409 1997 17272 28985 1012 1996 4713 2001 2284 1999 2392 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.260861 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.261208 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.266359 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000062\n",
            "I0703 18:12:07.266580 139789930788736 set_essential_params.py:432] unique_id: 1000000062\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.266680 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 6\n",
            "I0703 18:12:07.266762 139789930788736 set_essential_params.py:434] doc_span_index: 6\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and [SEP]\n",
            "I0703 18:12:07.267039 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] of the camp . during the final years of world war ii , numerous plants and factories in berlin and other major cities were destroyed by allied air raids . to prevent further losses , manufacturing was therefore moved to alternative places and regions not affected by the air war . the goal was to secure continued production of important war - related and everyday goods . according to records , siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945 . in 1972 , siemens sued german sat ##iri ##st f . c . del ##ius for his satirical history of the company , un ##ser ##e si ##eme ##n sw ##elt , and it was determined much of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:570 12:571 13:572 14:572 15:573 16:574 17:575 18:576 19:577 20:578 21:579 22:580 23:580 24:581 25:582 26:583 27:584 28:585 29:586 30:587 31:588 32:589 33:590 34:591 35:592 36:593 37:594 38:595 39:596 40:596 41:597 42:598 43:599 44:600 45:600 46:601 47:602 48:603 49:604 50:605 51:606 52:607 53:608 54:609 55:610 56:611 57:612 58:613 59:614 60:615 61:615 62:616 63:617 64:618 65:619 66:620 67:621 68:622 69:623 70:624 71:625 72:625 73:625 74:626 75:627 76:628 77:628 78:629 79:630 80:631 81:631 82:632 83:633 84:634 85:635 86:636 87:637 88:638 89:639 90:640 91:641 92:642 93:643 94:644 95:645 96:646 97:647 98:648 99:649 100:650 101:650 102:651 103:652 104:652 105:653 106:654 107:655 108:656 109:656 110:656 111:657 112:657 113:657 114:657 115:658 116:658 117:659 118:660 119:661 120:662 121:663 122:664 123:665 124:665 125:666 126:666 127:666 128:667 129:667 130:667 131:668 132:668 133:668 134:669 135:670 136:671 137:672 138:673 139:674 140:675 141:676 142:677 143:678 144:679 145:680 146:681 147:682 148:683 149:684 150:685 151:685 152:686 153:687 154:688 155:689 156:689 157:690 158:691 159:692 160:693 161:694 162:695 163:696 164:697 165:698 166:699 167:700 168:701 169:701 170:702 171:703 172:704 173:705 174:706 175:707 176:707 177:708 178:709 179:709 180:709 181:709 182:710 183:711 184:712 185:713 186:713 187:714 188:714 189:715 190:716 191:717 192:718 193:719 194:720 195:721 196:722 197:723 198:724 199:724 200:725 201:725 202:726 203:727 204:728 205:729 206:730 207:730 208:731 209:732 210:733 211:734 212:735 213:735 214:736 215:737 216:737 217:737 218:738 219:738 220:739 221:740 222:741 223:741 224:742 225:743 226:744 227:745 228:746 229:747 230:748 231:748 232:749 233:749 234:749 235:750 236:751 237:752 238:753 239:753 240:754 241:755 242:755 243:756 244:757 245:757 246:758 247:759 248:759 249:759 250:760 251:761 252:761 253:762 254:763 255:764 256:764 257:765 258:765 259:765 260:765 261:765 262:766 263:767 264:768 265:768 266:768 267:769 268:769 269:769 270:769 271:769 272:769 273:769 274:769 275:770 276:770 277:770 278:770 279:771 280:772 281:773 282:773 283:774 284:775 285:775 286:775 287:775 288:775 289:775 290:775 291:776 292:776 293:776 294:776 295:777 296:778 297:779 298:779 299:780 300:781 301:782 302:783 303:784 304:784 305:785 306:786 307:786 308:787 309:788 310:789 311:789 312:790 313:791 314:792 315:792 316:793 317:794 318:794 319:795 320:796 321:797 322:798 323:798 324:799 325:800 326:801 327:802 328:803 329:804 330:805 331:806 332:807 333:808 334:809 335:810 336:811 337:812 338:812 339:813 340:814 341:814 342:815 343:816 344:816 345:816 346:817 347:818 348:819 349:820 350:821 351:822 352:823 353:824 354:824 355:825 356:826 357:826 358:827 359:828 360:829 361:829 362:830 363:831 364:832 365:833 366:834 367:835 368:836 369:837 370:837 371:837 372:837 373:838 374:838 375:838 376:838 377:838 378:839 379:840 380:841 381:841 382:842\n",
            "I0703 18:12:07.267374 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:570 12:571 13:572 14:572 15:573 16:574 17:575 18:576 19:577 20:578 21:579 22:580 23:580 24:581 25:582 26:583 27:584 28:585 29:586 30:587 31:588 32:589 33:590 34:591 35:592 36:593 37:594 38:595 39:596 40:596 41:597 42:598 43:599 44:600 45:600 46:601 47:602 48:603 49:604 50:605 51:606 52:607 53:608 54:609 55:610 56:611 57:612 58:613 59:614 60:615 61:615 62:616 63:617 64:618 65:619 66:620 67:621 68:622 69:623 70:624 71:625 72:625 73:625 74:626 75:627 76:628 77:628 78:629 79:630 80:631 81:631 82:632 83:633 84:634 85:635 86:636 87:637 88:638 89:639 90:640 91:641 92:642 93:643 94:644 95:645 96:646 97:647 98:648 99:649 100:650 101:650 102:651 103:652 104:652 105:653 106:654 107:655 108:656 109:656 110:656 111:657 112:657 113:657 114:657 115:658 116:658 117:659 118:660 119:661 120:662 121:663 122:664 123:665 124:665 125:666 126:666 127:666 128:667 129:667 130:667 131:668 132:668 133:668 134:669 135:670 136:671 137:672 138:673 139:674 140:675 141:676 142:677 143:678 144:679 145:680 146:681 147:682 148:683 149:684 150:685 151:685 152:686 153:687 154:688 155:689 156:689 157:690 158:691 159:692 160:693 161:694 162:695 163:696 164:697 165:698 166:699 167:700 168:701 169:701 170:702 171:703 172:704 173:705 174:706 175:707 176:707 177:708 178:709 179:709 180:709 181:709 182:710 183:711 184:712 185:713 186:713 187:714 188:714 189:715 190:716 191:717 192:718 193:719 194:720 195:721 196:722 197:723 198:724 199:724 200:725 201:725 202:726 203:727 204:728 205:729 206:730 207:730 208:731 209:732 210:733 211:734 212:735 213:735 214:736 215:737 216:737 217:737 218:738 219:738 220:739 221:740 222:741 223:741 224:742 225:743 226:744 227:745 228:746 229:747 230:748 231:748 232:749 233:749 234:749 235:750 236:751 237:752 238:753 239:753 240:754 241:755 242:755 243:756 244:757 245:757 246:758 247:759 248:759 249:759 250:760 251:761 252:761 253:762 254:763 255:764 256:764 257:765 258:765 259:765 260:765 261:765 262:766 263:767 264:768 265:768 266:768 267:769 268:769 269:769 270:769 271:769 272:769 273:769 274:769 275:770 276:770 277:770 278:770 279:771 280:772 281:773 282:773 283:774 284:775 285:775 286:775 287:775 288:775 289:775 290:775 291:776 292:776 293:776 294:776 295:777 296:778 297:779 298:779 299:780 300:781 301:782 302:783 303:784 304:784 305:785 306:786 307:786 308:787 309:788 310:789 311:789 312:790 313:791 314:792 315:792 316:793 317:794 318:794 319:795 320:796 321:797 322:798 323:798 324:799 325:800 326:801 327:802 328:803 329:804 330:805 331:806 332:807 333:808 334:809 335:810 336:811 337:812 338:812 339:813 340:814 341:814 342:815 343:816 344:816 345:816 346:817 347:818 348:819 349:820 350:821 351:822 352:823 353:824 354:824 355:825 356:826 357:826 358:827 359:828 360:829 361:829 362:830 363:831 364:832 365:833 366:834 367:835 368:836 369:837 370:837 371:837 372:837 373:838 374:838 375:838 376:838 377:838 378:839 379:840 380:841 381:841 382:842\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.359735 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 102\n",
            "I0703 18:12:07.361997 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1997 1996 3409 1012 2076 1996 2345 2086 1997 2088 2162 2462 1010 3365 4264 1998 11123 1999 4068 1998 2060 2350 3655 2020 3908 2011 6035 2250 11217 1012 2000 4652 2582 6409 1010 5814 2001 3568 2333 2000 4522 3182 1998 4655 2025 5360 2011 1996 2250 2162 1012 1996 3125 2001 2000 5851 2506 2537 1997 2590 2162 1011 3141 1998 10126 5350 1012 2429 2000 2636 1010 22108 2001 4082 2471 4278 4522 2030 7448 5814 4264 2012 1996 2203 1997 3646 1998 1999 2220 3386 1012 1999 3285 1010 22108 12923 2446 2938 15735 3367 1042 1012 1039 1012 3972 4173 2005 2010 17251 2381 1997 1996 2194 1010 4895 8043 2063 9033 21382 2078 25430 20042 1010 1998 2009 2001 4340 2172 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.362700 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.362925 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.365951 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000063\n",
            "I0703 18:12:07.366120 139789930788736 set_essential_params.py:432] unique_id: 1000000063\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.366214 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 7\n",
            "I0703 18:12:07.366301 139789930788736 set_essential_params.py:434] doc_span_index: 7\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 [SEP]\n",
            "I0703 18:12:07.366535 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] of the book contained false claims although the trial itself publicized siemens ' history in nazi germany . the company supplied electrical parts to nazi concentration camps and death camps . the factories had poor working conditions , where mal ##nut ##rit ##ion and death were common . also , the scholarship has shown that the camp factories were created , run , and supplied by the ss , in conjunction with company officials , sometimes high - level officials . in the 1950s , and from their new base in bavaria , s & h started to manufacture computers , semiconductor devices , washing machines , and pace ##makers . in 1966 , siemens & hal ##ske ( s & h , founded in 1847 ) , siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:674 12:675 13:676 14:677 15:678 16:679 17:680 18:681 19:682 20:683 21:684 22:685 23:685 24:686 25:687 26:688 27:689 28:689 29:690 30:691 31:692 32:693 33:694 34:695 35:696 36:697 37:698 38:699 39:700 40:701 41:701 42:702 43:703 44:704 45:705 46:706 47:707 48:707 49:708 50:709 51:709 52:709 53:709 54:710 55:711 56:712 57:713 58:713 59:714 60:714 61:715 62:716 63:717 64:718 65:719 66:720 67:721 68:722 69:723 70:724 71:724 72:725 73:725 74:726 75:727 76:728 77:729 78:730 79:730 80:731 81:732 82:733 83:734 84:735 85:735 86:736 87:737 88:737 89:737 90:738 91:738 92:739 93:740 94:741 95:741 96:742 97:743 98:744 99:745 100:746 101:747 102:748 103:748 104:749 105:749 106:749 107:750 108:751 109:752 110:753 111:753 112:754 113:755 114:755 115:756 116:757 117:757 118:758 119:759 120:759 121:759 122:760 123:761 124:761 125:762 126:763 127:764 128:764 129:765 130:765 131:765 132:765 133:765 134:766 135:767 136:768 137:768 138:768 139:769 140:769 141:769 142:769 143:769 144:769 145:769 146:769 147:770 148:770 149:770 150:770 151:771 152:772 153:773 154:773 155:774 156:775 157:775 158:775 159:775 160:775 161:775 162:775 163:776 164:776 165:776 166:776 167:777 168:778 169:779 170:779 171:780 172:781 173:782 174:783 175:784 176:784 177:785 178:786 179:786 180:787 181:788 182:789 183:789 184:790 185:791 186:792 187:792 188:793 189:794 190:794 191:795 192:796 193:797 194:798 195:798 196:799 197:800 198:801 199:802 200:803 201:804 202:805 203:806 204:807 205:808 206:809 207:810 208:811 209:812 210:812 211:813 212:814 213:814 214:815 215:816 216:816 217:816 218:817 219:818 220:819 221:820 222:821 223:822 224:823 225:824 226:824 227:825 228:826 229:826 230:827 231:828 232:829 233:829 234:830 235:831 236:832 237:833 238:834 239:835 240:836 241:837 242:837 243:837 244:837 245:838 246:838 247:838 248:838 249:838 250:839 251:840 252:841 253:841 254:842 255:843 256:844 257:845 258:846 259:847 260:847 261:847 262:847 263:848 264:849 265:850 266:851 267:852 268:852 269:852 270:853 271:854 272:854 273:854 274:854 275:855 276:856 277:856 278:857 279:858 280:859 281:860 282:860 283:860 284:860 285:861 286:862 287:863 288:864 289:865 290:866 291:867 292:867 293:868 294:869 295:870 296:871 297:872 298:873 299:874 300:875 301:876 302:877 303:878 304:879 305:879 306:880 307:881 308:882 309:882 310:883 311:884 312:884 313:884 314:884 315:885 316:885 317:886 318:887 319:888 320:889 321:890 322:890 323:891 324:892 325:893 326:894 327:895 328:896 329:897 330:897 331:898 332:899 333:900 334:901 335:902 336:903 337:904 338:905 339:906 340:907 341:907 342:907 343:907 344:908 345:909 346:910 347:911 348:912 349:913 350:914 351:914 352:915 353:916 354:916 355:917 356:918 357:919 358:920 359:920 360:920 361:920 362:921 363:922 364:923 365:924 366:924 367:925 368:926 369:927 370:928 371:929 372:929 373:929 374:929 375:930 376:930 377:930 378:931 379:931 380:931 381:932 382:932\n",
            "I0703 18:12:07.366800 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:674 12:675 13:676 14:677 15:678 16:679 17:680 18:681 19:682 20:683 21:684 22:685 23:685 24:686 25:687 26:688 27:689 28:689 29:690 30:691 31:692 32:693 33:694 34:695 35:696 36:697 37:698 38:699 39:700 40:701 41:701 42:702 43:703 44:704 45:705 46:706 47:707 48:707 49:708 50:709 51:709 52:709 53:709 54:710 55:711 56:712 57:713 58:713 59:714 60:714 61:715 62:716 63:717 64:718 65:719 66:720 67:721 68:722 69:723 70:724 71:724 72:725 73:725 74:726 75:727 76:728 77:729 78:730 79:730 80:731 81:732 82:733 83:734 84:735 85:735 86:736 87:737 88:737 89:737 90:738 91:738 92:739 93:740 94:741 95:741 96:742 97:743 98:744 99:745 100:746 101:747 102:748 103:748 104:749 105:749 106:749 107:750 108:751 109:752 110:753 111:753 112:754 113:755 114:755 115:756 116:757 117:757 118:758 119:759 120:759 121:759 122:760 123:761 124:761 125:762 126:763 127:764 128:764 129:765 130:765 131:765 132:765 133:765 134:766 135:767 136:768 137:768 138:768 139:769 140:769 141:769 142:769 143:769 144:769 145:769 146:769 147:770 148:770 149:770 150:770 151:771 152:772 153:773 154:773 155:774 156:775 157:775 158:775 159:775 160:775 161:775 162:775 163:776 164:776 165:776 166:776 167:777 168:778 169:779 170:779 171:780 172:781 173:782 174:783 175:784 176:784 177:785 178:786 179:786 180:787 181:788 182:789 183:789 184:790 185:791 186:792 187:792 188:793 189:794 190:794 191:795 192:796 193:797 194:798 195:798 196:799 197:800 198:801 199:802 200:803 201:804 202:805 203:806 204:807 205:808 206:809 207:810 208:811 209:812 210:812 211:813 212:814 213:814 214:815 215:816 216:816 217:816 218:817 219:818 220:819 221:820 222:821 223:822 224:823 225:824 226:824 227:825 228:826 229:826 230:827 231:828 232:829 233:829 234:830 235:831 236:832 237:833 238:834 239:835 240:836 241:837 242:837 243:837 244:837 245:838 246:838 247:838 248:838 249:838 250:839 251:840 252:841 253:841 254:842 255:843 256:844 257:845 258:846 259:847 260:847 261:847 262:847 263:848 264:849 265:850 266:851 267:852 268:852 269:852 270:853 271:854 272:854 273:854 274:854 275:855 276:856 277:856 278:857 279:858 280:859 281:860 282:860 283:860 284:860 285:861 286:862 287:863 288:864 289:865 290:866 291:867 292:867 293:868 294:869 295:870 296:871 297:872 298:873 299:874 300:875 301:876 302:877 303:878 304:879 305:879 306:880 307:881 308:882 309:882 310:883 311:884 312:884 313:884 314:884 315:885 316:885 317:886 318:887 319:888 320:889 321:890 322:890 323:891 324:892 325:893 326:894 327:895 328:896 329:897 330:897 331:898 332:899 333:900 334:901 335:902 336:903 337:904 338:905 339:906 340:907 341:907 342:907 343:907 344:908 345:909 346:910 347:911 348:912 349:913 350:914 351:914 352:915 353:916 354:916 355:917 356:918 357:919 358:920 359:920 360:920 361:920 362:921 363:922 364:923 365:924 366:924 367:925 368:926 369:927 370:928 371:929 372:929 373:929 374:929 375:930 376:930 377:930 378:931 379:931 380:931 381:932 382:932\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.465694 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 102\n",
            "I0703 18:12:07.466563 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1997 1996 2338 4838 6270 4447 2348 1996 3979 2993 24928 22108 1005 2381 1999 6394 2762 1012 1996 2194 8127 5992 3033 2000 6394 6693 7958 1998 2331 7958 1012 1996 11123 2018 3532 2551 3785 1010 2073 15451 24072 14778 3258 1998 2331 2020 2691 1012 2036 1010 1996 6566 2038 3491 2008 1996 3409 11123 2020 2580 1010 2448 1010 1998 8127 2011 1996 7020 1010 1999 9595 2007 2194 4584 1010 2823 2152 1011 2504 4584 1012 1999 1996 4856 1010 1998 2013 2037 2047 2918 1999 11606 1010 1055 1004 1044 2318 2000 9922 7588 1010 20681 5733 1010 12699 6681 1010 1998 6393 12088 1012 1999 3547 1010 22108 1004 11085 17140 1006 1055 1004 1044 1010 2631 1999 9176 1007 1010 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.466903 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.467147 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.473549 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000064\n",
            "I0703 18:12:07.473717 139789930788736 set_essential_params.py:432] unique_id: 1000000064\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.473799 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 8\n",
            "I0703 18:12:07.473872 139789930788736 set_essential_params.py:434] doc_span_index: 8\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo [SEP]\n",
            "I0703 18:12:07.474104 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] siemens - sc ##hu ##cker ##t ##werk ##e ( ss ##w , founded in 1903 ) and siemens - rein ##iger - we ##rke ( sr ##w , founded in 1932 ) merged to form siemens ag . in 1969 , siemens formed kraft ##werk union with ae ##g by pool ##ing their nuclear power businesses . a 1973 siemens electron microscope on display at the musee des arts et met ##iers in paris . the company ' s first digital telephone exchange was produced in 1980 . in 1988 , siemens and ge ##c acquired the uk defence and technology company pl ##ess ##ey . pl ##ess ##ey ' s holdings were split , and siemens took over the av ##ion ##ics , radar and traffic control businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:769 12:769 13:769 14:769 15:769 16:769 17:769 18:769 19:770 20:770 21:770 22:770 23:771 24:772 25:773 26:773 27:774 28:775 29:775 30:775 31:775 32:775 33:775 34:775 35:776 36:776 37:776 38:776 39:777 40:778 41:779 42:779 43:780 44:781 45:782 46:783 47:784 48:784 49:785 50:786 51:786 52:787 53:788 54:789 55:789 56:790 57:791 58:792 59:792 60:793 61:794 62:794 63:795 64:796 65:797 66:798 67:798 68:799 69:800 70:801 71:802 72:803 73:804 74:805 75:806 76:807 77:808 78:809 79:810 80:811 81:812 82:812 83:813 84:814 85:814 86:815 87:816 88:816 89:816 90:817 91:818 92:819 93:820 94:821 95:822 96:823 97:824 98:824 99:825 100:826 101:826 102:827 103:828 104:829 105:829 106:830 107:831 108:832 109:833 110:834 111:835 112:836 113:837 114:837 115:837 116:837 117:838 118:838 119:838 120:838 121:838 122:839 123:840 124:841 125:841 126:842 127:843 128:844 129:845 130:846 131:847 132:847 133:847 134:847 135:848 136:849 137:850 138:851 139:852 140:852 141:852 142:853 143:854 144:854 145:854 146:854 147:855 148:856 149:856 150:857 151:858 152:859 153:860 154:860 155:860 156:860 157:861 158:862 159:863 160:864 161:865 162:866 163:867 164:867 165:868 166:869 167:870 168:871 169:872 170:873 171:874 172:875 173:876 174:877 175:878 176:879 177:879 178:880 179:881 180:882 181:882 182:883 183:884 184:884 185:884 186:884 187:885 188:885 189:886 190:887 191:888 192:889 193:890 194:890 195:891 196:892 197:893 198:894 199:895 200:896 201:897 202:897 203:898 204:899 205:900 206:901 207:902 208:903 209:904 210:905 211:906 212:907 213:907 214:907 215:907 216:908 217:909 218:910 219:911 220:912 221:913 222:914 223:914 224:915 225:916 226:916 227:917 228:918 229:919 230:920 231:920 232:920 233:920 234:921 235:922 236:923 237:924 238:924 239:925 240:926 241:927 242:928 243:929 244:929 245:929 246:929 247:930 248:930 249:930 250:931 251:931 252:931 253:932 254:932 255:932 256:933 257:933 258:933 259:933 260:933 261:933 262:934 263:935 264:936 265:937 266:937 267:938 268:939 269:940 270:941 271:942 272:943 273:943 274:943 275:944 276:944 277:945 278:946 279:947 280:947 281:948 282:949 283:950 284:951 285:952 286:953 287:954 288:954 289:955 290:955 291:956 292:957 293:958 294:959 295:960 296:961 297:962 298:963 299:964 300:965 301:966 302:967 303:968 304:968 305:968 306:969 307:970 308:970 309:971 310:971 311:971 312:971 313:971 314:971 315:972 316:973 317:973 318:974 319:975 320:976 321:976 322:976 323:976 324:976 325:977 326:978 327:979 328:980 329:981 330:982 331:982 332:982 333:982 334:983 335:983 336:984 337:984 338:985 339:986 340:987 341:988 342:989 343:989 344:990 345:991 346:992 347:993 348:994 349:994 350:995 351:996 352:997 353:998 354:998 355:999 356:1000 357:1000 358:1001 359:1002 360:1002 361:1002 362:1002 363:1003 364:1003 365:1004 366:1004 367:1005 368:1006 369:1007 370:1008 371:1009 372:1010 373:1010 374:1011 375:1012 376:1012 377:1013 378:1014 379:1015 380:1016 381:1017 382:1017\n",
            "I0703 18:12:07.474526 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:769 12:769 13:769 14:769 15:769 16:769 17:769 18:769 19:770 20:770 21:770 22:770 23:771 24:772 25:773 26:773 27:774 28:775 29:775 30:775 31:775 32:775 33:775 34:775 35:776 36:776 37:776 38:776 39:777 40:778 41:779 42:779 43:780 44:781 45:782 46:783 47:784 48:784 49:785 50:786 51:786 52:787 53:788 54:789 55:789 56:790 57:791 58:792 59:792 60:793 61:794 62:794 63:795 64:796 65:797 66:798 67:798 68:799 69:800 70:801 71:802 72:803 73:804 74:805 75:806 76:807 77:808 78:809 79:810 80:811 81:812 82:812 83:813 84:814 85:814 86:815 87:816 88:816 89:816 90:817 91:818 92:819 93:820 94:821 95:822 96:823 97:824 98:824 99:825 100:826 101:826 102:827 103:828 104:829 105:829 106:830 107:831 108:832 109:833 110:834 111:835 112:836 113:837 114:837 115:837 116:837 117:838 118:838 119:838 120:838 121:838 122:839 123:840 124:841 125:841 126:842 127:843 128:844 129:845 130:846 131:847 132:847 133:847 134:847 135:848 136:849 137:850 138:851 139:852 140:852 141:852 142:853 143:854 144:854 145:854 146:854 147:855 148:856 149:856 150:857 151:858 152:859 153:860 154:860 155:860 156:860 157:861 158:862 159:863 160:864 161:865 162:866 163:867 164:867 165:868 166:869 167:870 168:871 169:872 170:873 171:874 172:875 173:876 174:877 175:878 176:879 177:879 178:880 179:881 180:882 181:882 182:883 183:884 184:884 185:884 186:884 187:885 188:885 189:886 190:887 191:888 192:889 193:890 194:890 195:891 196:892 197:893 198:894 199:895 200:896 201:897 202:897 203:898 204:899 205:900 206:901 207:902 208:903 209:904 210:905 211:906 212:907 213:907 214:907 215:907 216:908 217:909 218:910 219:911 220:912 221:913 222:914 223:914 224:915 225:916 226:916 227:917 228:918 229:919 230:920 231:920 232:920 233:920 234:921 235:922 236:923 237:924 238:924 239:925 240:926 241:927 242:928 243:929 244:929 245:929 246:929 247:930 248:930 249:930 250:931 251:931 252:931 253:932 254:932 255:932 256:933 257:933 258:933 259:933 260:933 261:933 262:934 263:935 264:936 265:937 266:937 267:938 268:939 269:940 270:941 271:942 272:943 273:943 274:943 275:944 276:944 277:945 278:946 279:947 280:947 281:948 282:949 283:950 284:951 285:952 286:953 287:954 288:954 289:955 290:955 291:956 292:957 293:958 294:959 295:960 296:961 297:962 298:963 299:964 300:965 301:966 302:967 303:968 304:968 305:968 306:969 307:970 308:970 309:971 310:971 311:971 312:971 313:971 314:971 315:972 316:973 317:973 318:974 319:975 320:976 321:976 322:976 323:976 324:976 325:977 326:978 327:979 328:980 329:981 330:982 331:982 332:982 333:982 334:983 335:983 336:984 337:984 338:985 339:986 340:987 341:988 342:989 343:989 344:990 345:991 346:992 347:993 348:994 349:994 350:995 351:996 352:997 353:998 354:998 355:999 356:1000 357:1000 358:1001 359:1002 360:1002 361:1002 362:1002 363:1003 364:1003 365:1004 366:1004 367:1005 368:1006 369:1007 370:1008 371:1009 372:1010 373:1010 374:1011 375:1012 376:1012 377:1013 378:1014 379:1015 380:1016 381:1017 382:1017\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.568348 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 102\n",
            "I0703 18:12:07.570008 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 22108 1011 8040 6979 9102 2102 29548 2063 1006 7020 2860 1010 2631 1999 5778 1007 1998 22108 1011 27788 17071 1011 2057 25074 1006 5034 2860 1010 2631 1999 4673 1007 5314 2000 2433 22108 12943 1012 1999 3440 1010 22108 2719 26680 29548 2586 2007 29347 2290 2011 4770 2075 2037 4517 2373 5661 1012 1037 3381 22108 10496 24635 2006 4653 2012 1996 18070 4078 2840 3802 2777 10136 1999 3000 1012 1996 2194 1005 1055 2034 3617 7026 3863 2001 2550 1999 3150 1012 1999 2997 1010 22108 1998 16216 2278 3734 1996 2866 4721 1998 2974 2194 20228 7971 3240 1012 20228 7971 3240 1005 1055 9583 2020 3975 1010 1998 22108 2165 2058 1996 20704 3258 6558 1010 7217 1998 4026 2491 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.571327 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.571615 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.574661 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000065\n",
            "I0703 18:12:07.574814 139789930788736 set_essential_params.py:432] unique_id: 1000000065\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.574912 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 9\n",
            "I0703 18:12:07.575001 139789930788736 set_essential_params.py:434] doc_span_index: 9\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens [SEP]\n",
            "I0703 18:12:07.575235 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] businesses — as siemens pl ##ess ##ey . in 1977 , advanced micro devices ( am ##d ) entered into a joint venture with siemens , which wanted to enhance its technology expertise and enter the american market . siemens purchased 20 % of am ##d ' s stock , giving the company an in ##fusion of cash to increase its product lines . the two companies also jointly established advanced micro computers ( amc ) , located in silicon valley and in germany , allowing am ##d to enter the micro ##com ##put ##er development and manufacturing field , in particular based on am ##d ' s second - source z ##ilo ##g z ##80 ##00 micro ##pro ##ces ##sor ##s . when the two companies ' vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:852 12:852 13:852 14:853 15:854 16:854 17:854 18:854 19:855 20:856 21:856 22:857 23:858 24:859 25:860 26:860 27:860 28:860 29:861 30:862 31:863 32:864 33:865 34:866 35:867 36:867 37:868 38:869 39:870 40:871 41:872 42:873 43:874 44:875 45:876 46:877 47:878 48:879 49:879 50:880 51:881 52:882 53:882 54:883 55:884 56:884 57:884 58:884 59:885 60:885 61:886 62:887 63:888 64:889 65:890 66:890 67:891 68:892 69:893 70:894 71:895 72:896 73:897 74:897 75:898 76:899 77:900 78:901 79:902 80:903 81:904 82:905 83:906 84:907 85:907 86:907 87:907 88:908 89:909 90:910 91:911 92:912 93:913 94:914 95:914 96:915 97:916 98:916 99:917 100:918 101:919 102:920 103:920 104:920 105:920 106:921 107:922 108:923 109:924 110:924 111:925 112:926 113:927 114:928 115:929 116:929 117:929 118:929 119:930 120:930 121:930 122:931 123:931 124:931 125:932 126:932 127:932 128:933 129:933 130:933 131:933 132:933 133:933 134:934 135:935 136:936 137:937 138:937 139:938 140:939 141:940 142:941 143:942 144:943 145:943 146:943 147:944 148:944 149:945 150:946 151:947 152:947 153:948 154:949 155:950 156:951 157:952 158:953 159:954 160:954 161:955 162:955 163:956 164:957 165:958 166:959 167:960 168:961 169:962 170:963 171:964 172:965 173:966 174:967 175:968 176:968 177:968 178:969 179:970 180:970 181:971 182:971 183:971 184:971 185:971 186:971 187:972 188:973 189:973 190:974 191:975 192:976 193:976 194:976 195:976 196:976 197:977 198:978 199:979 200:980 201:981 202:982 203:982 204:982 205:982 206:983 207:983 208:984 209:984 210:985 211:986 212:987 213:988 214:989 215:989 216:990 217:991 218:992 219:993 220:994 221:994 222:995 223:996 224:997 225:998 226:998 227:999 228:1000 229:1000 230:1001 231:1002 232:1002 233:1002 234:1002 235:1003 236:1003 237:1004 238:1004 239:1005 240:1006 241:1007 242:1008 243:1009 244:1010 245:1010 246:1011 247:1012 248:1012 249:1013 250:1014 251:1015 252:1016 253:1017 254:1017 255:1017 256:1017 257:1018 258:1018 259:1019 260:1020 261:1021 262:1022 263:1023 264:1024 265:1024 266:1025 267:1026 268:1027 269:1028 270:1028 271:1029 272:1029 273:1030 274:1031 275:1032 276:1033 277:1034 278:1034 279:1034 280:1035 281:1036 282:1036 283:1037 284:1038 285:1039 286:1039 287:1040 288:1041 289:1042 290:1043 291:1044 292:1045 293:1046 294:1046 295:1047 296:1047 297:1047 298:1047 299:1048 300:1048 301:1049 302:1050 303:1051 304:1052 305:1053 306:1054 307:1054 308:1055 309:1056 310:1057 311:1057 312:1058 313:1059 314:1060 315:1061 316:1062 317:1063 318:1064 319:1065 320:1066 321:1066 322:1067 323:1067 324:1068 325:1069 326:1070 327:1071 328:1071 329:1072 330:1072 331:1073 332:1074 333:1075 334:1076 335:1077 336:1078 337:1079 338:1080 339:1080 340:1081 341:1081 342:1081 343:1082 344:1083 345:1084 346:1085 347:1086 348:1087 349:1088 350:1089 351:1090 352:1090 353:1091 354:1091 355:1092 356:1093 357:1093 358:1094 359:1095 360:1096 361:1097 362:1097 363:1097 364:1098 365:1099 366:1100 367:1100 368:1101 369:1101 370:1102 371:1103 372:1104 373:1105 374:1105 375:1106 376:1107 377:1108 378:1108 379:1108 380:1109 381:1110 382:1111\n",
            "I0703 18:12:07.575485 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:852 12:852 13:852 14:853 15:854 16:854 17:854 18:854 19:855 20:856 21:856 22:857 23:858 24:859 25:860 26:860 27:860 28:860 29:861 30:862 31:863 32:864 33:865 34:866 35:867 36:867 37:868 38:869 39:870 40:871 41:872 42:873 43:874 44:875 45:876 46:877 47:878 48:879 49:879 50:880 51:881 52:882 53:882 54:883 55:884 56:884 57:884 58:884 59:885 60:885 61:886 62:887 63:888 64:889 65:890 66:890 67:891 68:892 69:893 70:894 71:895 72:896 73:897 74:897 75:898 76:899 77:900 78:901 79:902 80:903 81:904 82:905 83:906 84:907 85:907 86:907 87:907 88:908 89:909 90:910 91:911 92:912 93:913 94:914 95:914 96:915 97:916 98:916 99:917 100:918 101:919 102:920 103:920 104:920 105:920 106:921 107:922 108:923 109:924 110:924 111:925 112:926 113:927 114:928 115:929 116:929 117:929 118:929 119:930 120:930 121:930 122:931 123:931 124:931 125:932 126:932 127:932 128:933 129:933 130:933 131:933 132:933 133:933 134:934 135:935 136:936 137:937 138:937 139:938 140:939 141:940 142:941 143:942 144:943 145:943 146:943 147:944 148:944 149:945 150:946 151:947 152:947 153:948 154:949 155:950 156:951 157:952 158:953 159:954 160:954 161:955 162:955 163:956 164:957 165:958 166:959 167:960 168:961 169:962 170:963 171:964 172:965 173:966 174:967 175:968 176:968 177:968 178:969 179:970 180:970 181:971 182:971 183:971 184:971 185:971 186:971 187:972 188:973 189:973 190:974 191:975 192:976 193:976 194:976 195:976 196:976 197:977 198:978 199:979 200:980 201:981 202:982 203:982 204:982 205:982 206:983 207:983 208:984 209:984 210:985 211:986 212:987 213:988 214:989 215:989 216:990 217:991 218:992 219:993 220:994 221:994 222:995 223:996 224:997 225:998 226:998 227:999 228:1000 229:1000 230:1001 231:1002 232:1002 233:1002 234:1002 235:1003 236:1003 237:1004 238:1004 239:1005 240:1006 241:1007 242:1008 243:1009 244:1010 245:1010 246:1011 247:1012 248:1012 249:1013 250:1014 251:1015 252:1016 253:1017 254:1017 255:1017 256:1017 257:1018 258:1018 259:1019 260:1020 261:1021 262:1022 263:1023 264:1024 265:1024 266:1025 267:1026 268:1027 269:1028 270:1028 271:1029 272:1029 273:1030 274:1031 275:1032 276:1033 277:1034 278:1034 279:1034 280:1035 281:1036 282:1036 283:1037 284:1038 285:1039 286:1039 287:1040 288:1041 289:1042 290:1043 291:1044 292:1045 293:1046 294:1046 295:1047 296:1047 297:1047 298:1047 299:1048 300:1048 301:1049 302:1050 303:1051 304:1052 305:1053 306:1054 307:1054 308:1055 309:1056 310:1057 311:1057 312:1058 313:1059 314:1060 315:1061 316:1062 317:1063 318:1064 319:1065 320:1066 321:1066 322:1067 323:1067 324:1068 325:1069 326:1070 327:1071 328:1071 329:1072 330:1072 331:1073 332:1074 333:1075 334:1076 335:1077 336:1078 337:1079 338:1080 339:1080 340:1081 341:1081 342:1081 343:1082 344:1083 345:1084 346:1085 347:1086 348:1087 349:1088 350:1089 351:1090 352:1090 353:1091 354:1091 355:1092 356:1093 357:1093 358:1094 359:1095 360:1096 361:1097 362:1097 363:1097 364:1098 365:1099 366:1100 367:1100 368:1101 369:1101 370:1102 371:1103 372:1104 373:1105 374:1105 375:1106 376:1107 377:1108 378:1108 379:1108 380:1109 381:1110 382:1111\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.575727 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 102\n",
            "I0703 18:12:07.675601 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 5661 1517 2004 22108 20228 7971 3240 1012 1999 3355 1010 3935 12702 5733 1006 2572 2094 1007 3133 2046 1037 4101 6957 2007 22108 1010 2029 2359 2000 11598 2049 2974 11532 1998 4607 1996 2137 3006 1012 22108 4156 2322 1003 1997 2572 2094 1005 1055 4518 1010 3228 1996 2194 2019 1999 20523 1997 5356 2000 3623 2049 4031 3210 1012 1996 2048 3316 2036 10776 2511 3935 12702 7588 1006 21962 1007 1010 2284 1999 13773 3028 1998 1999 2762 1010 4352 2572 2094 2000 4607 1996 12702 9006 18780 2121 2458 1998 5814 2492 1010 1999 3327 2241 2006 2572 2094 1005 1055 2117 1011 3120 1062 22360 2290 1062 17914 8889 12702 21572 9623 21748 2015 1012 2043 1996 2048 3316 1005 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.676506 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.677471 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.684655 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000066\n",
            "I0703 18:12:07.684883 139789930788736 set_essential_params.py:432] unique_id: 1000000066\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.685014 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 10\n",
            "I0703 18:12:07.685117 139789930788736 set_essential_params.py:434] doc_span_index: 10\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , [SEP]\n",
            "I0703 18:12:07.685428 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] vision for advanced micro computers diver ##ged , am ##d bought out siemens ' stake in the american division in 1979 . am ##d closed advanced micro computers in late 1981 after switching focus to manufacturing second - source intel x ##86 micro ##pro ##ces ##sor ##s . in 1985 , siemens bought all ##is - chalmers ' interest in the partnership company siemens - all ##is ( formed 1978 ) which supplied electrical control equipment . it was incorporated into siemens ' energy and automation division . in 1987 , siemens rein ##te ##grate ##d kraft ##werk union , the unit overseeing nuclear power business . in 1989 , siemens bought the solar photo ##vo ##lta ##ic business , including 3 solar module manufacturing plants , from industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:938 12:939 13:940 14:941 15:942 16:943 17:943 18:943 19:944 20:944 21:945 22:946 23:947 24:947 25:948 26:949 27:950 28:951 29:952 30:953 31:954 32:954 33:955 34:955 35:956 36:957 37:958 38:959 39:960 40:961 41:962 42:963 43:964 44:965 45:966 46:967 47:968 48:968 49:968 50:969 51:970 52:970 53:971 54:971 55:971 56:971 57:971 58:971 59:972 60:973 61:973 62:974 63:975 64:976 65:976 66:976 67:976 68:976 69:977 70:978 71:979 72:980 73:981 74:982 75:982 76:982 77:982 78:983 79:983 80:984 81:984 82:985 83:986 84:987 85:988 86:989 87:989 88:990 89:991 90:992 91:993 92:994 93:994 94:995 95:996 96:997 97:998 98:998 99:999 100:1000 101:1000 102:1001 103:1002 104:1002 105:1002 106:1002 107:1003 108:1003 109:1004 110:1004 111:1005 112:1006 113:1007 114:1008 115:1009 116:1010 117:1010 118:1011 119:1012 120:1012 121:1013 122:1014 123:1015 124:1016 125:1017 126:1017 127:1017 128:1017 129:1018 130:1018 131:1019 132:1020 133:1021 134:1022 135:1023 136:1024 137:1024 138:1025 139:1026 140:1027 141:1028 142:1028 143:1029 144:1029 145:1030 146:1031 147:1032 148:1033 149:1034 150:1034 151:1034 152:1035 153:1036 154:1036 155:1037 156:1038 157:1039 158:1039 159:1040 160:1041 161:1042 162:1043 163:1044 164:1045 165:1046 166:1046 167:1047 168:1047 169:1047 170:1047 171:1048 172:1048 173:1049 174:1050 175:1051 176:1052 177:1053 178:1054 179:1054 180:1055 181:1056 182:1057 183:1057 184:1058 185:1059 186:1060 187:1061 188:1062 189:1063 190:1064 191:1065 192:1066 193:1066 194:1067 195:1067 196:1068 197:1069 198:1070 199:1071 200:1071 201:1072 202:1072 203:1073 204:1074 205:1075 206:1076 207:1077 208:1078 209:1079 210:1080 211:1080 212:1081 213:1081 214:1081 215:1082 216:1083 217:1084 218:1085 219:1086 220:1087 221:1088 222:1089 223:1090 224:1090 225:1091 226:1091 227:1092 228:1093 229:1093 230:1094 231:1095 232:1096 233:1097 234:1097 235:1097 236:1098 237:1099 238:1100 239:1100 240:1101 241:1101 242:1102 243:1103 244:1104 245:1105 246:1105 247:1106 248:1107 249:1108 250:1108 251:1108 252:1109 253:1110 254:1111 255:1111 256:1111 257:1112 258:1112 259:1113 260:1114 261:1115 262:1115 263:1116 264:1117 265:1118 266:1119 267:1120 268:1121 269:1122 270:1122 271:1123 272:1124 273:1124 274:1124 275:1124 276:1125 277:1126 278:1126 279:1126 280:1127 281:1128 282:1129 283:1130 284:1130 285:1130 286:1131 287:1132 288:1133 289:1134 290:1134 291:1134 292:1134 293:1135 294:1136 295:1137 296:1138 297:1139 298:1139 299:1140 300:1141 301:1141 302:1142 303:1143 304:1144 305:1145 306:1146 307:1147 308:1148 309:1149 310:1150 311:1151 312:1151 313:1151 314:1152 315:1153 316:1154 317:1155 318:1155 319:1155 320:1156 321:1157 322:1158 323:1159 324:1160 325:1160 326:1161 327:1161 328:1161 329:1161 330:1161 331:1162 332:1162 333:1163 334:1164 335:1165 336:1165 337:1166 338:1167 339:1168 340:1169 341:1170 342:1171 343:1172 344:1173 345:1174 346:1175 347:1175 348:1176 349:1177 350:1178 351:1178 352:1179 353:1180 354:1181 355:1182 356:1182 357:1182 358:1182 359:1183 360:1184 361:1185 362:1186 363:1187 364:1188 365:1189 366:1190 367:1191 368:1192 369:1193 370:1194 371:1195 372:1196 373:1197 374:1198 375:1199 376:1200 377:1201 378:1202 379:1202 380:1203 381:1204 382:1204\n",
            "I0703 18:12:07.685837 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:938 12:939 13:940 14:941 15:942 16:943 17:943 18:943 19:944 20:944 21:945 22:946 23:947 24:947 25:948 26:949 27:950 28:951 29:952 30:953 31:954 32:954 33:955 34:955 35:956 36:957 37:958 38:959 39:960 40:961 41:962 42:963 43:964 44:965 45:966 46:967 47:968 48:968 49:968 50:969 51:970 52:970 53:971 54:971 55:971 56:971 57:971 58:971 59:972 60:973 61:973 62:974 63:975 64:976 65:976 66:976 67:976 68:976 69:977 70:978 71:979 72:980 73:981 74:982 75:982 76:982 77:982 78:983 79:983 80:984 81:984 82:985 83:986 84:987 85:988 86:989 87:989 88:990 89:991 90:992 91:993 92:994 93:994 94:995 95:996 96:997 97:998 98:998 99:999 100:1000 101:1000 102:1001 103:1002 104:1002 105:1002 106:1002 107:1003 108:1003 109:1004 110:1004 111:1005 112:1006 113:1007 114:1008 115:1009 116:1010 117:1010 118:1011 119:1012 120:1012 121:1013 122:1014 123:1015 124:1016 125:1017 126:1017 127:1017 128:1017 129:1018 130:1018 131:1019 132:1020 133:1021 134:1022 135:1023 136:1024 137:1024 138:1025 139:1026 140:1027 141:1028 142:1028 143:1029 144:1029 145:1030 146:1031 147:1032 148:1033 149:1034 150:1034 151:1034 152:1035 153:1036 154:1036 155:1037 156:1038 157:1039 158:1039 159:1040 160:1041 161:1042 162:1043 163:1044 164:1045 165:1046 166:1046 167:1047 168:1047 169:1047 170:1047 171:1048 172:1048 173:1049 174:1050 175:1051 176:1052 177:1053 178:1054 179:1054 180:1055 181:1056 182:1057 183:1057 184:1058 185:1059 186:1060 187:1061 188:1062 189:1063 190:1064 191:1065 192:1066 193:1066 194:1067 195:1067 196:1068 197:1069 198:1070 199:1071 200:1071 201:1072 202:1072 203:1073 204:1074 205:1075 206:1076 207:1077 208:1078 209:1079 210:1080 211:1080 212:1081 213:1081 214:1081 215:1082 216:1083 217:1084 218:1085 219:1086 220:1087 221:1088 222:1089 223:1090 224:1090 225:1091 226:1091 227:1092 228:1093 229:1093 230:1094 231:1095 232:1096 233:1097 234:1097 235:1097 236:1098 237:1099 238:1100 239:1100 240:1101 241:1101 242:1102 243:1103 244:1104 245:1105 246:1105 247:1106 248:1107 249:1108 250:1108 251:1108 252:1109 253:1110 254:1111 255:1111 256:1111 257:1112 258:1112 259:1113 260:1114 261:1115 262:1115 263:1116 264:1117 265:1118 266:1119 267:1120 268:1121 269:1122 270:1122 271:1123 272:1124 273:1124 274:1124 275:1124 276:1125 277:1126 278:1126 279:1126 280:1127 281:1128 282:1129 283:1130 284:1130 285:1130 286:1131 287:1132 288:1133 289:1134 290:1134 291:1134 292:1134 293:1135 294:1136 295:1137 296:1138 297:1139 298:1139 299:1140 300:1141 301:1141 302:1142 303:1143 304:1144 305:1145 306:1146 307:1147 308:1148 309:1149 310:1150 311:1151 312:1151 313:1151 314:1152 315:1153 316:1154 317:1155 318:1155 319:1155 320:1156 321:1157 322:1158 323:1159 324:1160 325:1160 326:1161 327:1161 328:1161 329:1161 330:1161 331:1162 332:1162 333:1163 334:1164 335:1165 336:1165 337:1166 338:1167 339:1168 340:1169 341:1170 342:1171 343:1172 344:1173 345:1174 346:1175 347:1175 348:1176 349:1177 350:1178 351:1178 352:1179 353:1180 354:1181 355:1182 356:1182 357:1182 358:1182 359:1183 360:1184 361:1185 362:1186 363:1187 364:1188 365:1189 366:1190 367:1191 368:1192 369:1193 370:1194 371:1195 372:1196 373:1197 374:1198 375:1199 376:1200 377:1201 378:1202 379:1202 380:1203 381:1204 382:1204\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.686164 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 102\n",
            "I0703 18:12:07.778773 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 4432 2005 3935 12702 7588 17856 5999 1010 2572 2094 4149 2041 22108 1005 8406 1999 1996 2137 2407 1999 3245 1012 2572 2094 2701 3935 12702 7588 1999 2397 3261 2044 11991 3579 2000 5814 2117 1011 3120 13420 1060 20842 12702 21572 9623 21748 2015 1012 1999 3106 1010 22108 4149 2035 2483 1011 29069 1005 3037 1999 1996 5386 2194 22108 1011 2035 2483 1006 2719 3301 1007 2029 8127 5992 2491 3941 1012 2009 2001 5100 2046 22108 1005 2943 1998 19309 2407 1012 1999 3055 1010 22108 27788 2618 22780 2094 26680 29548 2586 1010 1996 3131 19642 4517 2373 2449 1012 1999 2960 1010 22108 4149 1996 5943 6302 6767 24458 2594 2449 1010 2164 1017 5943 11336 5814 4264 1010 2013 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.780119 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.781153 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.785449 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000067\n",
            "I0703 18:12:07.785605 139789930788736 set_essential_params.py:432] unique_id: 1000000067\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.785703 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 11\n",
            "I0703 18:12:07.785789 139789930788736 set_essential_params.py:434] doc_span_index: 11\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking [SEP]\n",
            "I0703 18:12:07.786016 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] industry pioneer arc ##o solar , owned by oil firm arc ##o . in 1991 , siemens acquired nix ##dorf computer ag and renamed it siemens nix ##dorf information ##ss ##yst ##eme ag , in order to produce personal computers . in october 1991 , siemens acquired the industrial systems division of texas instruments , inc , based in johnson city , tennessee . this division was organized as siemens industrial automation , inc . , and was later absorbed by siemens energy and automation , inc . in 1992 , siemens bought out ibm ' s half of ro ##lm ( siemens had bought into ro ##lm five years earlier ) , thus creating siemens ##rol ##m communications ; eventually dropping ro ##lm from the name later in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:1026 12:1027 13:1028 14:1028 15:1029 16:1029 17:1030 18:1031 19:1032 20:1033 21:1034 22:1034 23:1034 24:1035 25:1036 26:1036 27:1037 28:1038 29:1039 30:1039 31:1040 32:1041 33:1042 34:1043 35:1044 36:1045 37:1046 38:1046 39:1047 40:1047 41:1047 42:1047 43:1048 44:1048 45:1049 46:1050 47:1051 48:1052 49:1053 50:1054 51:1054 52:1055 53:1056 54:1057 55:1057 56:1058 57:1059 58:1060 59:1061 60:1062 61:1063 62:1064 63:1065 64:1066 65:1066 66:1067 67:1067 68:1068 69:1069 70:1070 71:1071 72:1071 73:1072 74:1072 75:1073 76:1074 77:1075 78:1076 79:1077 80:1078 81:1079 82:1080 83:1080 84:1081 85:1081 86:1081 87:1082 88:1083 89:1084 90:1085 91:1086 92:1087 93:1088 94:1089 95:1090 96:1090 97:1091 98:1091 99:1092 100:1093 101:1093 102:1094 103:1095 104:1096 105:1097 106:1097 107:1097 108:1098 109:1099 110:1100 111:1100 112:1101 113:1101 114:1102 115:1103 116:1104 117:1105 118:1105 119:1106 120:1107 121:1108 122:1108 123:1108 124:1109 125:1110 126:1111 127:1111 128:1111 129:1112 130:1112 131:1113 132:1114 133:1115 134:1115 135:1116 136:1117 137:1118 138:1119 139:1120 140:1121 141:1122 142:1122 143:1123 144:1124 145:1124 146:1124 147:1124 148:1125 149:1126 150:1126 151:1126 152:1127 153:1128 154:1129 155:1130 156:1130 157:1130 158:1131 159:1132 160:1133 161:1134 162:1134 163:1134 164:1134 165:1135 166:1136 167:1137 168:1138 169:1139 170:1139 171:1140 172:1141 173:1141 174:1142 175:1143 176:1144 177:1145 178:1146 179:1147 180:1148 181:1149 182:1150 183:1151 184:1151 185:1151 186:1152 187:1153 188:1154 189:1155 190:1155 191:1155 192:1156 193:1157 194:1158 195:1159 196:1160 197:1160 198:1161 199:1161 200:1161 201:1161 202:1161 203:1162 204:1162 205:1163 206:1164 207:1165 208:1165 209:1166 210:1167 211:1168 212:1169 213:1170 214:1171 215:1172 216:1173 217:1174 218:1175 219:1175 220:1176 221:1177 222:1178 223:1178 224:1179 225:1180 226:1181 227:1182 228:1182 229:1182 230:1182 231:1183 232:1184 233:1185 234:1186 235:1187 236:1188 237:1189 238:1190 239:1191 240:1192 241:1193 242:1194 243:1195 244:1196 245:1197 246:1198 247:1199 248:1200 249:1201 250:1202 251:1202 252:1203 253:1204 254:1204 255:1205 256:1206 257:1207 258:1207 259:1207 260:1208 261:1209 262:1210 263:1211 264:1212 265:1213 266:1213 267:1213 268:1213 269:1214 270:1215 271:1216 272:1217 273:1218 274:1219 275:1220 276:1221 277:1222 278:1223 279:1224 280:1225 281:1226 282:1227 283:1228 284:1229 285:1230 286:1231 287:1231 288:1232 289:1233 290:1233 291:1234 292:1234 293:1235 294:1236 295:1237 296:1238 297:1239 298:1240 299:1241 300:1242 301:1243 302:1244 303:1245 304:1245 305:1245 306:1246 307:1246 308:1247 309:1248 310:1248 311:1248 312:1248 313:1249 314:1250 315:1251 316:1252 317:1253 318:1254 319:1255 320:1256 321:1257 322:1257 323:1258 324:1259 325:1259 326:1259 327:1259 328:1260 329:1261 330:1262 331:1263 332:1263 333:1264 334:1264 335:1265 336:1265 337:1265 338:1266 339:1267 340:1268 341:1268 342:1269 343:1270 344:1271 345:1272 346:1272 347:1273 348:1274 349:1275 350:1276 351:1277 352:1277 353:1277 354:1277 355:1278 356:1278 357:1279 358:1280 359:1281 360:1282 361:1282 362:1283 363:1284 364:1284 365:1285 366:1285 367:1285 368:1285 369:1286 370:1287 371:1288 372:1289 373:1290 374:1290 375:1291 376:1292 377:1293 378:1293 379:1294 380:1295 381:1296 382:1297\n",
            "I0703 18:12:07.786278 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:1026 12:1027 13:1028 14:1028 15:1029 16:1029 17:1030 18:1031 19:1032 20:1033 21:1034 22:1034 23:1034 24:1035 25:1036 26:1036 27:1037 28:1038 29:1039 30:1039 31:1040 32:1041 33:1042 34:1043 35:1044 36:1045 37:1046 38:1046 39:1047 40:1047 41:1047 42:1047 43:1048 44:1048 45:1049 46:1050 47:1051 48:1052 49:1053 50:1054 51:1054 52:1055 53:1056 54:1057 55:1057 56:1058 57:1059 58:1060 59:1061 60:1062 61:1063 62:1064 63:1065 64:1066 65:1066 66:1067 67:1067 68:1068 69:1069 70:1070 71:1071 72:1071 73:1072 74:1072 75:1073 76:1074 77:1075 78:1076 79:1077 80:1078 81:1079 82:1080 83:1080 84:1081 85:1081 86:1081 87:1082 88:1083 89:1084 90:1085 91:1086 92:1087 93:1088 94:1089 95:1090 96:1090 97:1091 98:1091 99:1092 100:1093 101:1093 102:1094 103:1095 104:1096 105:1097 106:1097 107:1097 108:1098 109:1099 110:1100 111:1100 112:1101 113:1101 114:1102 115:1103 116:1104 117:1105 118:1105 119:1106 120:1107 121:1108 122:1108 123:1108 124:1109 125:1110 126:1111 127:1111 128:1111 129:1112 130:1112 131:1113 132:1114 133:1115 134:1115 135:1116 136:1117 137:1118 138:1119 139:1120 140:1121 141:1122 142:1122 143:1123 144:1124 145:1124 146:1124 147:1124 148:1125 149:1126 150:1126 151:1126 152:1127 153:1128 154:1129 155:1130 156:1130 157:1130 158:1131 159:1132 160:1133 161:1134 162:1134 163:1134 164:1134 165:1135 166:1136 167:1137 168:1138 169:1139 170:1139 171:1140 172:1141 173:1141 174:1142 175:1143 176:1144 177:1145 178:1146 179:1147 180:1148 181:1149 182:1150 183:1151 184:1151 185:1151 186:1152 187:1153 188:1154 189:1155 190:1155 191:1155 192:1156 193:1157 194:1158 195:1159 196:1160 197:1160 198:1161 199:1161 200:1161 201:1161 202:1161 203:1162 204:1162 205:1163 206:1164 207:1165 208:1165 209:1166 210:1167 211:1168 212:1169 213:1170 214:1171 215:1172 216:1173 217:1174 218:1175 219:1175 220:1176 221:1177 222:1178 223:1178 224:1179 225:1180 226:1181 227:1182 228:1182 229:1182 230:1182 231:1183 232:1184 233:1185 234:1186 235:1187 236:1188 237:1189 238:1190 239:1191 240:1192 241:1193 242:1194 243:1195 244:1196 245:1197 246:1198 247:1199 248:1200 249:1201 250:1202 251:1202 252:1203 253:1204 254:1204 255:1205 256:1206 257:1207 258:1207 259:1207 260:1208 261:1209 262:1210 263:1211 264:1212 265:1213 266:1213 267:1213 268:1213 269:1214 270:1215 271:1216 272:1217 273:1218 274:1219 275:1220 276:1221 277:1222 278:1223 279:1224 280:1225 281:1226 282:1227 283:1228 284:1229 285:1230 286:1231 287:1231 288:1232 289:1233 290:1233 291:1234 292:1234 293:1235 294:1236 295:1237 296:1238 297:1239 298:1240 299:1241 300:1242 301:1243 302:1244 303:1245 304:1245 305:1245 306:1246 307:1246 308:1247 309:1248 310:1248 311:1248 312:1248 313:1249 314:1250 315:1251 316:1252 317:1253 318:1254 319:1255 320:1256 321:1257 322:1257 323:1258 324:1259 325:1259 326:1259 327:1259 328:1260 329:1261 330:1262 331:1263 332:1263 333:1264 334:1264 335:1265 336:1265 337:1265 338:1266 339:1267 340:1268 341:1268 342:1269 343:1270 344:1271 345:1272 346:1272 347:1273 348:1274 349:1275 350:1276 351:1277 352:1277 353:1277 354:1277 355:1278 356:1278 357:1279 358:1280 359:1281 360:1282 361:1282 362:1283 363:1284 364:1284 365:1285 366:1285 367:1285 368:1285 369:1286 370:1287 371:1288 372:1289 373:1290 374:1290 375:1291 376:1292 377:1293 378:1293 379:1294 380:1295 381:1296 382:1297\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.786520 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 102\n",
            "I0703 18:12:07.885327 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 3068 7156 8115 2080 5943 1010 3079 2011 3514 3813 8115 2080 1012 1999 2889 1010 22108 3734 23330 11592 3274 12943 1998 4096 2009 22108 23330 11592 2592 4757 27268 21382 12943 1010 1999 2344 2000 3965 3167 7588 1012 1999 2255 2889 1010 22108 3734 1996 3919 3001 2407 1997 3146 5693 1010 4297 1010 2241 1999 3779 2103 1010 5298 1012 2023 2407 2001 4114 2004 22108 3919 19309 1010 4297 1012 1010 1998 2001 2101 9063 2011 22108 2943 1998 19309 1010 4297 1012 1999 2826 1010 22108 4149 2041 9980 1005 1055 2431 1997 20996 13728 1006 22108 2018 4149 2046 20996 13728 2274 2086 3041 1007 1010 2947 4526 22108 13153 2213 4806 1025 2776 7510 20996 13728 2013 1996 2171 2101 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.886763 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.887450 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.890659 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000068\n",
            "I0703 18:12:07.890801 139789930788736 set_essential_params.py:432] unique_id: 1000000068\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.890891 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 12\n",
            "I0703 18:12:07.890978 139789930788736 set_essential_params.py:434] doc_span_index: 12\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired [SEP]\n",
            "I0703 18:12:07.891191 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] in the 1990s . in 1993 – 1994 , siemens c ##65 ##1 electric trains for singapore ' s mass rapid transit ( mr ##t ) system were built in austria . in 1997 , siemens agreed to sell the defence arm of siemens pl ##ess ##ey to british aerospace ( bae ) and a german aerospace company , dai ##mler ##ch ##rys ##ler aerospace . bae and das ##a acquired the british and german divisions of the operation respectively . in october 1997 , siemens financial services ( sf ##s ) was founded to act as a competence center for financing issues and as a manager of financial risks within siemens . in 1998 , siemens acquired west ##ing ##house power generation for more than $ 1 . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:1120 12:1121 13:1122 14:1122 15:1123 16:1124 17:1124 18:1124 19:1124 20:1125 21:1126 22:1126 23:1126 24:1127 25:1128 26:1129 27:1130 28:1130 29:1130 30:1131 31:1132 32:1133 33:1134 34:1134 35:1134 36:1134 37:1135 38:1136 39:1137 40:1138 41:1139 42:1139 43:1140 44:1141 45:1141 46:1142 47:1143 48:1144 49:1145 50:1146 51:1147 52:1148 53:1149 54:1150 55:1151 56:1151 57:1151 58:1152 59:1153 60:1154 61:1155 62:1155 63:1155 64:1156 65:1157 66:1158 67:1159 68:1160 69:1160 70:1161 71:1161 72:1161 73:1161 74:1161 75:1162 76:1162 77:1163 78:1164 79:1165 80:1165 81:1166 82:1167 83:1168 84:1169 85:1170 86:1171 87:1172 88:1173 89:1174 90:1175 91:1175 92:1176 93:1177 94:1178 95:1178 96:1179 97:1180 98:1181 99:1182 100:1182 101:1182 102:1182 103:1183 104:1184 105:1185 106:1186 107:1187 108:1188 109:1189 110:1190 111:1191 112:1192 113:1193 114:1194 115:1195 116:1196 117:1197 118:1198 119:1199 120:1200 121:1201 122:1202 123:1202 124:1203 125:1204 126:1204 127:1205 128:1206 129:1207 130:1207 131:1207 132:1208 133:1209 134:1210 135:1211 136:1212 137:1213 138:1213 139:1213 140:1213 141:1214 142:1215 143:1216 144:1217 145:1218 146:1219 147:1220 148:1221 149:1222 150:1223 151:1224 152:1225 153:1226 154:1227 155:1228 156:1229 157:1230 158:1231 159:1231 160:1232 161:1233 162:1233 163:1234 164:1234 165:1235 166:1236 167:1237 168:1238 169:1239 170:1240 171:1241 172:1242 173:1243 174:1244 175:1245 176:1245 177:1245 178:1246 179:1246 180:1247 181:1248 182:1248 183:1248 184:1248 185:1249 186:1250 187:1251 188:1252 189:1253 190:1254 191:1255 192:1256 193:1257 194:1257 195:1258 196:1259 197:1259 198:1259 199:1259 200:1260 201:1261 202:1262 203:1263 204:1263 205:1264 206:1264 207:1265 208:1265 209:1265 210:1266 211:1267 212:1268 213:1268 214:1269 215:1270 216:1271 217:1272 218:1272 219:1273 220:1274 221:1275 222:1276 223:1277 224:1277 225:1277 226:1277 227:1278 228:1278 229:1279 230:1280 231:1281 232:1282 233:1282 234:1283 235:1284 236:1284 237:1285 238:1285 239:1285 240:1285 241:1286 242:1287 243:1288 244:1289 245:1290 246:1290 247:1291 248:1292 249:1293 250:1293 251:1294 252:1295 253:1296 254:1297 255:1298 256:1299 257:1300 258:1301 259:1301 260:1302 261:1302 262:1302 263:1303 264:1304 265:1304 266:1305 267:1306 268:1307 269:1308 270:1309 271:1310 272:1311 273:1312 274:1313 275:1313 276:1314 277:1315 278:1316 279:1316 280:1317 281:1318 282:1319 283:1320 284:1321 285:1322 286:1323 287:1323 288:1324 289:1325 290:1326 291:1326 292:1327 293:1327 294:1327 295:1327 296:1327 297:1327 298:1328 299:1329 300:1330 301:1331 302:1331 303:1332 304:1333 305:1334 306:1335 307:1335 308:1336 309:1337 310:1338 311:1339 312:1340 313:1340 314:1341 315:1342 316:1343 317:1344 318:1344 319:1345 320:1345 321:1346 322:1346 323:1346 324:1347 325:1347 326:1348 327:1349 328:1350 329:1351 330:1352 331:1353 332:1354 333:1355 334:1355 335:1356 336:1357 337:1357 338:1358 339:1358 340:1359 341:1359 342:1359 343:1360 344:1360 345:1361 346:1362 347:1363 348:1364 349:1365 350:1366 351:1367 352:1368 353:1369 354:1370 355:1370 356:1371 357:1371 358:1372 359:1372 360:1372 361:1373 362:1373 363:1374 364:1374 365:1374 366:1375 367:1376 368:1377 369:1378 370:1379 371:1380 372:1381 373:1382 374:1383 375:1383 376:1384 377:1385 378:1386 379:1387 380:1388 381:1389 382:1390\n",
            "I0703 18:12:07.897515 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:1120 12:1121 13:1122 14:1122 15:1123 16:1124 17:1124 18:1124 19:1124 20:1125 21:1126 22:1126 23:1126 24:1127 25:1128 26:1129 27:1130 28:1130 29:1130 30:1131 31:1132 32:1133 33:1134 34:1134 35:1134 36:1134 37:1135 38:1136 39:1137 40:1138 41:1139 42:1139 43:1140 44:1141 45:1141 46:1142 47:1143 48:1144 49:1145 50:1146 51:1147 52:1148 53:1149 54:1150 55:1151 56:1151 57:1151 58:1152 59:1153 60:1154 61:1155 62:1155 63:1155 64:1156 65:1157 66:1158 67:1159 68:1160 69:1160 70:1161 71:1161 72:1161 73:1161 74:1161 75:1162 76:1162 77:1163 78:1164 79:1165 80:1165 81:1166 82:1167 83:1168 84:1169 85:1170 86:1171 87:1172 88:1173 89:1174 90:1175 91:1175 92:1176 93:1177 94:1178 95:1178 96:1179 97:1180 98:1181 99:1182 100:1182 101:1182 102:1182 103:1183 104:1184 105:1185 106:1186 107:1187 108:1188 109:1189 110:1190 111:1191 112:1192 113:1193 114:1194 115:1195 116:1196 117:1197 118:1198 119:1199 120:1200 121:1201 122:1202 123:1202 124:1203 125:1204 126:1204 127:1205 128:1206 129:1207 130:1207 131:1207 132:1208 133:1209 134:1210 135:1211 136:1212 137:1213 138:1213 139:1213 140:1213 141:1214 142:1215 143:1216 144:1217 145:1218 146:1219 147:1220 148:1221 149:1222 150:1223 151:1224 152:1225 153:1226 154:1227 155:1228 156:1229 157:1230 158:1231 159:1231 160:1232 161:1233 162:1233 163:1234 164:1234 165:1235 166:1236 167:1237 168:1238 169:1239 170:1240 171:1241 172:1242 173:1243 174:1244 175:1245 176:1245 177:1245 178:1246 179:1246 180:1247 181:1248 182:1248 183:1248 184:1248 185:1249 186:1250 187:1251 188:1252 189:1253 190:1254 191:1255 192:1256 193:1257 194:1257 195:1258 196:1259 197:1259 198:1259 199:1259 200:1260 201:1261 202:1262 203:1263 204:1263 205:1264 206:1264 207:1265 208:1265 209:1265 210:1266 211:1267 212:1268 213:1268 214:1269 215:1270 216:1271 217:1272 218:1272 219:1273 220:1274 221:1275 222:1276 223:1277 224:1277 225:1277 226:1277 227:1278 228:1278 229:1279 230:1280 231:1281 232:1282 233:1282 234:1283 235:1284 236:1284 237:1285 238:1285 239:1285 240:1285 241:1286 242:1287 243:1288 244:1289 245:1290 246:1290 247:1291 248:1292 249:1293 250:1293 251:1294 252:1295 253:1296 254:1297 255:1298 256:1299 257:1300 258:1301 259:1301 260:1302 261:1302 262:1302 263:1303 264:1304 265:1304 266:1305 267:1306 268:1307 269:1308 270:1309 271:1310 272:1311 273:1312 274:1313 275:1313 276:1314 277:1315 278:1316 279:1316 280:1317 281:1318 282:1319 283:1320 284:1321 285:1322 286:1323 287:1323 288:1324 289:1325 290:1326 291:1326 292:1327 293:1327 294:1327 295:1327 296:1327 297:1327 298:1328 299:1329 300:1330 301:1331 302:1331 303:1332 304:1333 305:1334 306:1335 307:1335 308:1336 309:1337 310:1338 311:1339 312:1340 313:1340 314:1341 315:1342 316:1343 317:1344 318:1344 319:1345 320:1345 321:1346 322:1346 323:1346 324:1347 325:1347 326:1348 327:1349 328:1350 329:1351 330:1352 331:1353 332:1354 333:1355 334:1355 335:1356 336:1357 337:1357 338:1358 339:1358 340:1359 341:1359 342:1359 343:1360 344:1360 345:1361 346:1362 347:1363 348:1364 349:1365 350:1366 351:1367 352:1368 353:1369 354:1370 355:1370 356:1371 357:1371 358:1372 359:1372 360:1372 361:1373 362:1373 363:1374 364:1374 365:1374 366:1375 367:1376 368:1377 369:1378 370:1379 371:1380 372:1381 373:1382 374:1383 375:1383 376:1384 377:1385 378:1386 379:1387 380:1388 381:1389 382:1390\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "I0703 18:12:07.897900 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 102\n",
            "I0703 18:12:07.988659 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1999 1996 4134 1012 1999 2857 1516 2807 1010 22108 1039 26187 2487 3751 4499 2005 5264 1005 1055 3742 5915 6671 1006 2720 2102 1007 2291 2020 2328 1999 5118 1012 1999 2722 1010 22108 3530 2000 5271 1996 4721 2849 1997 22108 20228 7971 3240 2000 2329 13395 1006 25818 1007 1998 1037 2446 13395 2194 1010 18765 18602 2818 24769 3917 13395 1012 25818 1998 8695 2050 3734 1996 2329 1998 2446 5908 1997 1996 3169 4414 1012 1999 2255 2722 1010 22108 3361 2578 1006 16420 2015 1007 2001 2631 2000 2552 2004 1037 22219 2415 2005 12135 3314 1998 2004 1037 3208 1997 3361 10831 2306 22108 1012 1999 2687 1010 22108 3734 2225 2075 4580 2373 4245 2005 2062 2084 1002 1015 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.990961 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0703 18:12:07.992011 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0703 18:12:07.994865 139789930788736 set_essential_params.py:431] *** Example ***\n",
            "INFO:tensorflow:unique_id: 1000000069\n",
            "I0703 18:12:07.995037 139789930788736 set_essential_params.py:432] unique_id: 1000000069\n",
            "INFO:tensorflow:example_index: 4\n",
            "I0703 18:12:07.995137 139789930788736 set_essential_params.py:433] example_index: 4\n",
            "INFO:tensorflow:doc_span_index: 13\n",
            "I0703 18:12:07.995243 139789930788736 set_essential_params.py:434] doc_span_index: 13\n",
            "INFO:tensorflow:tokens: [CLS] when was the last ceo change in siemens ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "I0703 18:12:07.995459 139789930788736 set_essential_params.py:436] tokens: [CLS] when was the last ceo change in siemens ? [SEP] . 5 billion from the cbs corporation and moving siemens from third to second in the world power generation market . in 1999 , siemens ' semiconductor operations were spun off into a new company called in ##fine ##on technologies . its electro ##me ##chan ##ical components operations were converted into a legally independent company : siemens electro ##me ##chan ##ical components gmbh & co . kg , ( which , later that year , was sold to ty ##co international ltd for approximately $ 1 . 1 billion . in the same year , siemens nix ##dorf information ##ss ##yst ##eme ag became part of fuji ##tsu siemens computers ag , with its retail banking technology group becoming win ##cor nix ##dorf . in 2000 , shared medical systems corporation was acquired by the siemens ' medical engineering group , eventually becoming part of siemens medical solutions . also in 2000 , ate ##cs - mann ##es ##man was acquired by siemens , the sale was final ##ised in april 2001 with 50 % of the shares acquired , acquisition , mann ##es ##mann v ##do ag merged into siemens automotive forming siemens v ##do automotive ag , ate ##cs mann ##es ##mann dem ##atic systems merged into siemens production and logistics forming siemens dem ##atic ag , mann ##es ##mann dem ##ag del ##ava ##l merged into the power generation division of siemens ag . other parts of the company were acquired by robert bosch gmbh at the same time . also , moore products co . of spring house , pa usa was acquired by siemens energy & automation , inc . [SEP]\n",
            "INFO:tensorflow:token_to_orig_map: 11:1213 12:1213 13:1214 14:1215 15:1216 16:1217 17:1218 18:1219 19:1220 20:1221 21:1222 22:1223 23:1224 24:1225 25:1226 26:1227 27:1228 28:1229 29:1230 30:1231 31:1231 32:1232 33:1233 34:1233 35:1234 36:1234 37:1235 38:1236 39:1237 40:1238 41:1239 42:1240 43:1241 44:1242 45:1243 46:1244 47:1245 48:1245 49:1245 50:1246 51:1246 52:1247 53:1248 54:1248 55:1248 56:1248 57:1249 58:1250 59:1251 60:1252 61:1253 62:1254 63:1255 64:1256 65:1257 66:1257 67:1258 68:1259 69:1259 70:1259 71:1259 72:1260 73:1261 74:1262 75:1263 76:1263 77:1264 78:1264 79:1265 80:1265 81:1265 82:1266 83:1267 84:1268 85:1268 86:1269 87:1270 88:1271 89:1272 90:1272 91:1273 92:1274 93:1275 94:1276 95:1277 96:1277 97:1277 98:1277 99:1278 100:1278 101:1279 102:1280 103:1281 104:1282 105:1282 106:1283 107:1284 108:1284 109:1285 110:1285 111:1285 112:1285 113:1286 114:1287 115:1288 116:1289 117:1290 118:1290 119:1291 120:1292 121:1293 122:1293 123:1294 124:1295 125:1296 126:1297 127:1298 128:1299 129:1300 130:1301 131:1301 132:1302 133:1302 134:1302 135:1303 136:1304 137:1304 138:1305 139:1306 140:1307 141:1308 142:1309 143:1310 144:1311 145:1312 146:1313 147:1313 148:1314 149:1315 150:1316 151:1316 152:1317 153:1318 154:1319 155:1320 156:1321 157:1322 158:1323 159:1323 160:1324 161:1325 162:1326 163:1326 164:1327 165:1327 166:1327 167:1327 168:1327 169:1327 170:1328 171:1329 172:1330 173:1331 174:1331 175:1332 176:1333 177:1334 178:1335 179:1335 180:1336 181:1337 182:1338 183:1339 184:1340 185:1340 186:1341 187:1342 188:1343 189:1344 190:1344 191:1345 192:1345 193:1346 194:1346 195:1346 196:1347 197:1347 198:1348 199:1349 200:1350 201:1351 202:1352 203:1353 204:1354 205:1355 206:1355 207:1356 208:1357 209:1357 210:1358 211:1358 212:1359 213:1359 214:1359 215:1360 216:1360 217:1361 218:1362 219:1363 220:1364 221:1365 222:1366 223:1367 224:1368 225:1369 226:1370 227:1370 228:1371 229:1371 230:1372 231:1372 232:1372 233:1373 234:1373 235:1374 236:1374 237:1374 238:1375 239:1376 240:1377 241:1378 242:1379 243:1380 244:1381 245:1382 246:1383 247:1383 248:1384 249:1385 250:1386 251:1387 252:1388 253:1389 254:1390 255:1391 256:1392 257:1393 258:1394 259:1395 260:1396 261:1397 262:1398 263:1398 264:1399 265:1399 266:1400 267:1401 268:1402 269:1402 270:1403 271:1404 272:1405 273:1405 274:1406 275:1407 276:1408 277:1409 278:1410 279:1411 280:1412 281:1413 282:1414 283:1414 284:1415 285:1415\n",
            "I0703 18:12:07.995666 139789930788736 set_essential_params.py:438] token_to_orig_map: 11:1213 12:1213 13:1214 14:1215 15:1216 16:1217 17:1218 18:1219 19:1220 20:1221 21:1222 22:1223 23:1224 24:1225 25:1226 26:1227 27:1228 28:1229 29:1230 30:1231 31:1231 32:1232 33:1233 34:1233 35:1234 36:1234 37:1235 38:1236 39:1237 40:1238 41:1239 42:1240 43:1241 44:1242 45:1243 46:1244 47:1245 48:1245 49:1245 50:1246 51:1246 52:1247 53:1248 54:1248 55:1248 56:1248 57:1249 58:1250 59:1251 60:1252 61:1253 62:1254 63:1255 64:1256 65:1257 66:1257 67:1258 68:1259 69:1259 70:1259 71:1259 72:1260 73:1261 74:1262 75:1263 76:1263 77:1264 78:1264 79:1265 80:1265 81:1265 82:1266 83:1267 84:1268 85:1268 86:1269 87:1270 88:1271 89:1272 90:1272 91:1273 92:1274 93:1275 94:1276 95:1277 96:1277 97:1277 98:1277 99:1278 100:1278 101:1279 102:1280 103:1281 104:1282 105:1282 106:1283 107:1284 108:1284 109:1285 110:1285 111:1285 112:1285 113:1286 114:1287 115:1288 116:1289 117:1290 118:1290 119:1291 120:1292 121:1293 122:1293 123:1294 124:1295 125:1296 126:1297 127:1298 128:1299 129:1300 130:1301 131:1301 132:1302 133:1302 134:1302 135:1303 136:1304 137:1304 138:1305 139:1306 140:1307 141:1308 142:1309 143:1310 144:1311 145:1312 146:1313 147:1313 148:1314 149:1315 150:1316 151:1316 152:1317 153:1318 154:1319 155:1320 156:1321 157:1322 158:1323 159:1323 160:1324 161:1325 162:1326 163:1326 164:1327 165:1327 166:1327 167:1327 168:1327 169:1327 170:1328 171:1329 172:1330 173:1331 174:1331 175:1332 176:1333 177:1334 178:1335 179:1335 180:1336 181:1337 182:1338 183:1339 184:1340 185:1340 186:1341 187:1342 188:1343 189:1344 190:1344 191:1345 192:1345 193:1346 194:1346 195:1346 196:1347 197:1347 198:1348 199:1349 200:1350 201:1351 202:1352 203:1353 204:1354 205:1355 206:1355 207:1356 208:1357 209:1357 210:1358 211:1358 212:1359 213:1359 214:1359 215:1360 216:1360 217:1361 218:1362 219:1363 220:1364 221:1365 222:1366 223:1367 224:1368 225:1369 226:1370 227:1370 228:1371 229:1371 230:1372 231:1372 232:1372 233:1373 234:1373 235:1374 236:1374 237:1374 238:1375 239:1376 240:1377 241:1378 242:1379 243:1380 244:1381 245:1382 246:1383 247:1383 248:1384 249:1385 250:1386 251:1387 252:1388 253:1389 254:1390 255:1391 256:1392 257:1393 258:1394 259:1395 260:1396 261:1397 262:1398 263:1398 264:1399 265:1399 266:1400 267:1401 268:1402 269:1402 270:1403 271:1404 272:1405 273:1405 274:1406 275:1407 276:1408 277:1409 278:1410 279:1411 280:1412 281:1413 282:1414 283:1414 284:1415 285:1415\n",
            "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True\n",
            "I0703 18:12:07.995867 139789930788736 set_essential_params.py:440] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True\n",
            "INFO:tensorflow:input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:08.094978 139789930788736 set_essential_params.py:442] input_ids: 101 2043 2001 1996 2197 5766 2689 1999 22108 1029 102 1012 1019 4551 2013 1996 6568 3840 1998 3048 22108 2013 2353 2000 2117 1999 1996 2088 2373 4245 3006 1012 1999 2639 1010 22108 1005 20681 3136 2020 7455 2125 2046 1037 2047 2194 2170 1999 23460 2239 6786 1012 2049 16175 4168 14856 7476 6177 3136 2020 4991 2046 1037 10142 2981 2194 1024 22108 16175 4168 14856 7476 6177 18289 1004 2522 1012 4705 1010 1006 2029 1010 2101 2008 2095 1010 2001 2853 2000 5939 3597 2248 5183 2005 3155 1002 1015 1012 1015 4551 1012 1999 1996 2168 2095 1010 22108 23330 11592 2592 4757 27268 21382 12943 2150 2112 1997 20933 10422 22108 7588 12943 1010 2007 2049 7027 8169 2974 2177 3352 2663 27108 23330 11592 1012 1999 2456 1010 4207 2966 3001 3840 2001 3734 2011 1996 22108 1005 2966 3330 2177 1010 2776 3352 2112 1997 22108 2966 7300 1012 2036 1999 2456 1010 8823 6169 1011 10856 2229 2386 2001 3734 2011 22108 1010 1996 5096 2001 2345 5084 1999 2258 2541 2007 2753 1003 1997 1996 6661 3734 1010 7654 1010 10856 2229 5804 1058 3527 12943 5314 2046 22108 12945 5716 22108 1058 3527 12945 12943 1010 8823 6169 10856 2229 5804 17183 12070 3001 5314 2046 22108 2537 1998 12708 5716 22108 17183 12070 12943 1010 10856 2229 5804 17183 8490 3972 12462 2140 5314 2046 1996 2373 4245 2407 1997 22108 12943 1012 2060 3033 1997 1996 2194 2020 3734 2011 2728 25936 18289 2012 1996 2168 2051 1012 2036 1010 5405 3688 2522 1012 1997 3500 2160 1010 6643 3915 2001 3734 2011 22108 2943 1004 19309 1010 4297 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:08.096920 139789930788736 set_essential_params.py:444] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0703 18:12:08.098209 139789930788736 set_essential_params.py:446] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "I0703 18:12:08.099308 139789930788736 set_essential_params.py:1240] ***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 5\n",
            "I0703 18:12:08.099484 139789930788736 set_essential_params.py:1241]   Num orig examples = 5\n",
            "INFO:tensorflow:  Num split examples = 70\n",
            "I0703 18:12:08.099584 139789930788736 set_essential_params.py:1242]   Num split examples = 70\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0703 18:12:08.099683 139789930788736 set_essential_params.py:1243]   Batch size = 8\n",
            "WARNING:tensorflow:From set_essential_params.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0703 18:12:08.099852 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:Could not find trained model in model_dir: output2/, running initialization to predict.\n",
            "I0703 18:12:08.100251 139789930788736 estimator.py:612] Could not find trained model in model_dir: output2/, running initialization to predict.\n",
            "WARNING:tensorflow:From set_essential_params.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0703 18:12:08.137481 139789930788736 deprecation.py:323] From set_essential_params.py:730: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0703 18:12:08.137775 139789930788736 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From set_essential_params.py:703: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0703 18:12:08.139702 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:703: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From set_essential_params.py:710: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0703 18:12:08.143822 139789930788736 deprecation.py:323] From set_essential_params.py:710: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0703 18:12:08.161003 139789930788736 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0703 18:12:08.161338 139789930788736 tpu_estimator.py:2965] Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0703 18:12:08.161767 139789930788736 set_essential_params.py:598] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 384)\n",
            "I0703 18:12:08.161957 139789930788736 set_essential_params.py:600]   name = input_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 384)\n",
            "I0703 18:12:08.162131 139789930788736 set_essential_params.py:600]   name = input_mask, shape = (?, 384)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 384)\n",
            "I0703 18:12:08.162263 139789930788736 set_essential_params.py:600]   name = segment_ids, shape = (?, 384)\n",
            "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
            "I0703 18:12:08.162379 139789930788736 set_essential_params.py:600]   name = unique_ids, shape = (?,)\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0703 18:12:08.166006 139789930788736 deprecation_wrapper.py:119] From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0703 18:12:08.167836 139789930788736 deprecation_wrapper.py:119] From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0703 18:12:08.201045 139789930788736 deprecation_wrapper.py:119] From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0703 18:12:08.268332 139789930788736 deprecation.py:323] From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.296254 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.338142 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.369800 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216cfe90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232168d190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232168d190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.423676 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232168d190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232168d190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.470875 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.523228 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.583494 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.611464 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.639276 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215b15d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321633e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321633e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.689182 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321633e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321633e50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.735638 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fedd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.769942 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321333a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321333a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.834984 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321333a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321333a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.869246 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.898114 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23215254d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:08.953088 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fea50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232147c2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232147c2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.001819 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232147c2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232147c2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232142f690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232142f690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.163549 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232142f690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232142f690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d0810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d0810>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.219338 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d0810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d0810>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.245965 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.279237 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23211d3050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.347187 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.392817 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321363050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321363050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.442140 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321363050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321363050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.498453 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.532306 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.562781 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321019110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fed50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.617394 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216fed50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210d9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210d9390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.676187 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210d9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210d9390>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.711123 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e406d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e406d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.766009 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e406d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e406d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216ae3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216ae3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.793126 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216ae3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23216ae3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e3ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e3ef50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.821529 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e3ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320e3ef50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320ee3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320ee3890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.871523 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320ee3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320ee3890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210dda50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210dda50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.922181 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210dda50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23210dda50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:09.969113 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bcc550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bcc550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.026053 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bcc550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bcc550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321643fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321643fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.054349 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321643fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321643fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321365e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321365e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.087325 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321365e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321365e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320d29550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320d29550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.154980 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320d29550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320d29550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.203198 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321369690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.238938 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.290923 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321296310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321296310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.317705 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321296310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321296310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a54ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a54ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.346047 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a54ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a54ad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bba2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bba2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.396977 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bba2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bba2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.454528 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163d2d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb52d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb52d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.491954 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb52d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb52d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320942b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320942b50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.548087 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320942b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320942b50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.579093 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.741686 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232089fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23209bef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23209bef90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.792347 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23209bef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23209bef90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a21150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a21150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.840116 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a21150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a21150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb5650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb5650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.875295 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb5650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320bb5650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.928514 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.957143 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:10.986255 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320708450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23207fd4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23207fd4d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.047953 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23207fd4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23207fd4d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320cacd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320cacd10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.101889 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320cacd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320cacd10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.139910 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232055c250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232055c250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.195772 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232055c250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232055c250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.227140 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.255879 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206207d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.312527 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.380230 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2321251cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23208c35d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23208c35d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.417030 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23208c35d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23208c35d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.471803 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.502546 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.532224 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232041bad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232040ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232040ef50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.595393 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232040ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232040ef50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.653197 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232151db10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206eead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206eead0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.691523 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206eead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23206eead0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.750300 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.778228 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320262f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.806921 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299a10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.862999 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299a10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163dd90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.909372 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232163dd90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320619c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320619c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:11.955379 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320619c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320619c90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.015825 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.043433 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f232002e310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8d890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8d890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.071153 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8d890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8d890>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a1110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a1110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.123679 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a1110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a1110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200d7310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200d7310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.172012 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200d7310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200d7310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.206827 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320a5b650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.278538 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.306723 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.334604 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff3fb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.385789 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320299d50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8fad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8fad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.431521 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8fad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ff8fad0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.466301 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.521746 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.558536 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.596784 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fc475d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd38550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd38550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.783801 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd38550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd38550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.833772 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320148750>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a13d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a13d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.883737 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a13d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f23200a13d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.935682 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.964761 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:12.992884 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fa88910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb82610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb82610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.046546 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb82610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb82610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320552490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320552490>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.096097 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320552490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2320552490>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231feec450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231feec450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.131331 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231feec450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231feec450>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f85dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f85dfd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.197597 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f85dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f85dfd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.224617 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.252616 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f946650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f947250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f947250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.309211 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f947250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f947250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb35910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb35910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.360114 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb35910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fb35910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.396668 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.457302 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.494151 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.521771 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f71a690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7905d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7905d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.574219 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7905d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7905d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.627765 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd385d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd385d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.664131 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd385d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd385d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634850>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.715924 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634850>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f568bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f568bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.743963 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f568bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f568bd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f55db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f55db10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.786387 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f55db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f55db10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f790090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f790090>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.845517 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f790090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f790090>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f5e7710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f5e7710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.898460 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f5e7710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f5e7710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.936788 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:13.997474 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.027754 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.062374 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231fd06990>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f417310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f417310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.126461 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f417310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f417310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.176314 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f7bbb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f8b4910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f8b4910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.214237 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f8b4910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f8b4910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.269298 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.298858 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1fde90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f474050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f474050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.328621 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f474050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f474050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f26f790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f26f790>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.398584 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f26f790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f26f790>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.444796 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f634ed0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4ca950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4ca950>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.485806 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4ca950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4ca950>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f08bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f08bc90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.540547 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f08bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f08bc90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.568691 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.597515 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f15b3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4c6f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4c6f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.661731 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4c6f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f4c6f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f120a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f120a50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.722771 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f120a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f120a50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.760610 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.816731 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.845362 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:14.874942 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ee10650>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231eed3310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231eed3310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:15.099918 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231eed3310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231eed3310>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:15.149123 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f6fca50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1f9d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1f9d90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:15.200140 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1f9d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231f1f9d90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ebff610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ebff610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0703 18:12:15.391429 139789930788736 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ebff610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f231ebff610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From set_essential_params.py:632: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0703 18:12:16.140455 139789930788736 deprecation_wrapper.py:119] From set_essential_params.py:632: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0703 18:12:18.088641 139789930788736 set_essential_params.py:634] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.088892 139789930788736 set_essential_params.py:640]   name = bert/embeddings/word_embeddings:0, shape = (30522, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089017 139789930788736 set_essential_params.py:640]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089128 139789930788736 set_essential_params.py:640]   name = bert/embeddings/position_embeddings:0, shape = (512, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089210 139789930788736 set_essential_params.py:640]   name = bert/embeddings/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089280 139789930788736 set_essential_params.py:640]   name = bert/embeddings/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089349 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089436 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089508 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089590 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089659 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089729 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089795 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089867 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089933 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.089998 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090063 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090132 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090197 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090268 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090334 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090408 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090478 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090557 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090626 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090697 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090764 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090833 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090899 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.090969 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091034 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091098 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091162 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091231 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091297 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091367 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091445 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091511 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091585 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091669 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091736 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091806 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091870 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.091941 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092007 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092078 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092144 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092209 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092274 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092344 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092420 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092495 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092569 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092635 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092700 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092771 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092836 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092906 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.092971 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.093041 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.093106 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.093183 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.093250 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.167554 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.167909 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.168123 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.168281 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.168453 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.168645 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.168792 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.168938 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.169115 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.169269 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.169438 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.169604 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.169772 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.169919 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.170090 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.170255 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.170425 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.170575 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.170740 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.170900 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.171062 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.171223 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.171383 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.171626 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.171810 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.171967 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.172131 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.172281 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.172448 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.172595 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.172756 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.172904 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.173055 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.173261 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.173449 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.173619 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.173792 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.173950 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.174107 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.174259 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.174430 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.174582 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.174746 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.174893 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.175050 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.175230 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.175392 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.175558 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.175708 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.175854 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.176018 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.176190 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.176362 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.176538 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.176699 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.176860 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.177032 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.177204 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.177379 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.177549 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.177704 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.177851 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178004 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178159 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178309 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178470 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178630 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178779 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.178934 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.179094 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.179243 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.179386 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.179564 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.179713 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.179868 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180018 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180185 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180334 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180504 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180655 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180815 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.180959 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.181127 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.181272 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.181442 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.181592 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.181739 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.181882 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182035 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182189 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182323 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182449 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182572 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182685 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182802 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.182916 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183027 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183145 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183261 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183373 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183502 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183616 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183726 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183839 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.183956 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184076 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184195 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184306 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184431 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184551 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184668 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184778 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184885 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.184991 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.185127 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.185256 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.185385 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.185533 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.185672 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.278069 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.278453 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.278652 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.278817 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.278961 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.279130 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.279345 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.279523 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.279672 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.279819 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.279968 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.280132 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.280283 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.280455 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.280610 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.280764 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.280907 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.281057 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.281187 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.281306 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.281431 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.281551 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.281666 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282048 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282214 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282343 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282491 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282631 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282755 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.282883 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283004 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_12/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283133 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_12/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283266 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283391 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283523 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283705 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283837 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.283959 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.284074 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.284200 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.284595 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.284765 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.284894 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285030 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285149 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285275 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285391 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_13/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285519 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_13/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285640 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285765 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.285878 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286000 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286112 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286231 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286363 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286495 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286616 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286735 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.286851 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.287205 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.287337 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.287484 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.287609 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_14/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.379755 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_14/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.380828 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381020 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381135 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381247 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381348 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381494 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381600 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381705 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.381803 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382007 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382110 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382218 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382318 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382435 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382539 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_15/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382637 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_15/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382733 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382858 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.382964 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383067 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383163 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383263 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383359 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383478 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383578 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383673 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383769 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383872 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.383975 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384078 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384173 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_16/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384265 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_16/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384359 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384491 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384619 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384753 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.384881 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.385049 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.385190 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.385341 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.385543 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.385690 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.385831 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386002 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386152 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386313 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386478 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_17/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386611 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_17/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386716 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386832 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.386959 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.387108 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.387301 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.387530 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.387696 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.387871 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.388036 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.388175 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.388317 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.388497 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.388650 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.388809 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.481708 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_18/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.482162 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_18/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.482368 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.482993 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.483175 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.483767 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.483945 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.484256 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.484451 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.484635 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.484762 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.484848 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.484928 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485013 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485101 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485184 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485271 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_19/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485349 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_19/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485450 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485538 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485617 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485697 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485774 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485854 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.485931 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486013 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486089 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486165 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486241 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486322 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486409 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486502 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486635 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_20/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486770 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_20/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.486922 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487068 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487193 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487327 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487493 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487635 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487765 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.487901 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488027 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488150 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488275 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488421 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488555 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488688 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488813 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_21/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.488940 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_21/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489068 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489203 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489341 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489501 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489630 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489764 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.489896 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490031 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490158 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490281 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490415 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490558 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490683 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490815 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.490938 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_22/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.491060 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_22/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.585909 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/query/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.586212 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/query/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.586439 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/key/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.586636 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/key/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.586767 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/value/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.586894 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/self/value/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587008 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587130 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587245 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587354 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/attention/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587482 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/intermediate/dense/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587604 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/intermediate/dense/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587714 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/output/dense/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587834 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/output/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.587952 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/output/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_23/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.588062 139789930788736 set_essential_params.py:640]   name = bert/encoder/layer_23/output/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.588172 139789930788736 set_essential_params.py:640]   name = bert/pooler/dense/kernel:0, shape = (1024, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.588293 139789930788736 set_essential_params.py:640]   name = bert/pooler/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.588408 139789930788736 set_essential_params.py:640]   name = cls/squad/output_weights:0, shape = (2, 1024), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "I0703 18:12:18.588543 139789930788736 set_essential_params.py:640]   name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0703 18:12:18.589219 139789930788736 estimator.py:1147] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0703 18:12:18.912355 139789930788736 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0703 18:12:19.744276 139789930788736 monitored_session.py:240] Graph was finalized.\n",
            "2022-07-03 18:12:19.744767: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-07-03 18:12:19.748442: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-07-03 18:12:19.748800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f281c0 executing computations on platform Host. Devices:\n",
            "2022-07-03 18:12:19.748840: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2022-07-03 18:12:20.565613: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0703 18:14:44.334734 139789930788736 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0703 18:14:44.423173 139789930788736 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Processing example: 0\n",
            "I0703 18:15:36.926977 139789930788736 set_essential_params.py:1259] Processing example: 0\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0703 18:22:08.472715 139789930788736 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0703 18:22:08.473079 139789930788736 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:Writing predictions to: output2/predictions.json\n",
            "I0703 18:22:08.473244 139789930788736 set_essential_params.py:745] Writing predictions to: output2/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: output2/nbest_predictions.json\n",
            "I0703 18:22:08.473310 139789930788736 set_essential_params.py:746] Writing nbest to: output2/nbest_predictions.json\n"
          ]
        }
      ]
    }
  ]
}